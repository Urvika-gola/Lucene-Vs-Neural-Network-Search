[
  {
    "title": "Black Rings in (Anti)-deSitter space",
    "paperAbstract": "  We construct solutions for thin black rings in Anti-deSitter and deSitter\nspacetimes using approximate methods. Black rings in AdS exist with arbitrarily\nlarge radius and satisfy a bound |J| \\leq LM, which they saturate as their\nradius becomes infinitely large. For angular momentum near the maximum, they\nhave larger area than rotating AdS black holes. Thin black rings also exist in\ndeSitter space, with rotation velocities varying between zero and a maximum,\nand with a radius that is always strictly below the Hubble radius. Our general\nanalysis allows us to include black Saturns as well, which we discuss briefly.\nWe present a simple physical argument why supersymmetric AdS black rings must\nnot be expected: they do not possess the necessary pressure to balance the AdS\npotential. We discuss the possible existence or absence of `large AdS black\nrings' and their implications for a dual hydrodynamic description. An analysis\nof the physical properties of rotating AdS black holes is also included.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 67967,
    "score": 61.882301330566406,
    "userScore": 2
  },
  {
    "title": "Maxwell's equal area law for charged Anti-deSitter black holes",
    "paperAbstract": "  In this paper we present the construction of the Maxwell equal area law in\nthe Hawking temperature graph for a charged black hole in Anti-deSitter\nbackground. We are able to find exact solution for the corresponding isotherm\nand entropies for \"gaseous\" (large) black holes and \"liquid\" (near-extremal)\nblack holes. Isothermal construction removes the unphysical, negative heat\ncapacity, regions. Furthermore, extremal black holes turn out to be dual to\n\"un-shrinkable\" molecules of Van der Waals real fluid, which may explain their\nthermodynamical stability.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 430647,
    "score": 54.47431945800781,
    "userScore": 3
  },
  {
    "title": "Phase transitions of regular Schwarzschild-Anti-deSitter black holes",
    "paperAbstract": "  We study a solution of the Einstein's equations generated by a\nself-gravitating, anisotropic, static, non-singular matter fluid. The resulting\nSchwarzschild like solution is regular and accounts for smearing effects of\nnoncommutative fluctuations of the geometry. We call this solution regular\nSchwarzschild spacetime. In the presence of an Anti-deSitter cosmological term,\nthe regularized metric offers an extension of the Hawking-Page transition into\na van der Waals-like phase diagram. Specifically the regular\nSchwarzschild-Anti-deSitter geometry undergoes a first order small/large black\nhole transition similar to the liquid/gas transition of a real fluid. In the\npresent analysis we have considered the cosmological constant as a dynamical\nquantity and its variation is included in the first law of black hole\nthermodynamics.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 595965,
    "score": 53.701515197753906,
    "userScore": 2
  },
  {
    "title": "Schottky Anomaly of deSitter Black Holes",
    "paperAbstract": "  The interplay of black hole and cosmological horizons introduces distinctive\nthermodynamic behavior for deSitter black holes, including well-known upper\nbounds for the mass and entropy. We point to a new such feature, a Schottky\npeak in the heat capacity of Schwarzschild-deSitter (SdS) black holes. With\nthis behavior in mind, we explore statistical models for the underlying quantum\ndegrees of freedom of SdS holes. While a simple two-state spin model gives\nSchottky behavior, in order to capture the non-equilibrium nature of the SdS\nsystem we consider a system with a large number of non-interacting spins. We\nexamine to what extent constrained states of this system reproduce the\nthermodynamic properties of the black hole. We also review results of a recent\nstudy of particle production in SdS spacetimes in light of the Schottky anomaly\nand our spin models.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 1144784,
    "score": 48.382667541503906,
    "userScore": 2
  },
  {
    "title": "Black Holes as Dark Matter",
    "paperAbstract": "  While the energy of the universe has been established to be about 0.04\nbaryons, 0.24 dark matter and 0.72 dark energy, the cosmological entropy is\nalmost entirely, about $(1 - 10^{-15})$, from black holes and only $10^{-15}$\nfrom everything else. This identification of all dark matter as black holes is\nnatural in statistical mechanics. Cosmological history of dark matter is\ndiscussed.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 133869,
    "score": 48.25910949707031,
    "userScore": 3
  },
  {
    "title": "Black Hole Space-time In Dark Matter Halo",
    "paperAbstract": "  For the first time, we obtain the analytical form of black hole space-time\nmetric in dark matter halo for the stationary situation. Using the relation\nbetween the rotation velocity (in the equatorial plane) and the spherical\nsymmetric space-time metric coefficient, we obtain the space-time metric for\npure dark matter. By considering the dark matter halo in spherical symmetric\nspace-time as part of the energy-momentum tensors in the Einstein field\nequation, we then obtain the spherical symmetric black hole solutions in dark\nmatter halo. Utilizing Newman-Jains method, we further generalize spherical\nsymmetric black holes to rotational black holes. As examples, we obtain the\nspace-time metric of black holes surrounded by Cold Dark Matter and Scalar\nField Dark Matter halos, respectively. Our main results regarding the\ninteraction between black hole and dark matter halo are as follows: (i) For\nboth dark matter models, the density profile always produces \"cusp\" phenomenon\nin small scale in the relativity situation; (ii) Dark matter halo makes the\nblack hole horizon to increase but the ergosphere to decrease, while the\nmagnitude is small; (iii) Dark matter does not change the singularity of black\nholes. These results are useful to study the interaction of black hole and dark\nmatter halo in stationary situation. Particularly, the \"cusp\" produced in the\n$0\\sim 1$ kpc scale would be observable in the Milky Way. Perspectives on\nfuture work regarding the applications of our results in astrophysics are also\nbriefly discussed.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 950900,
    "score": 47.775779724121094,
    "userScore": 3
  },
  {
    "title": "The Noether charge entropy in anti-deSitter space and its field theory\n  dual",
    "paperAbstract": "  We express the Noether charge entropy density of a black brane in\nanti-deSitter space in terms of local operators in the anti-deSitter space\nbulk. We find that Wald's expression for the Noether charge entropy needs to be\nmodified away from the horizon by an additional term that vanishes on the\nhorizon. We then determine the field theory dual of the Noether charge entropy\nfor theories that asymptote to Einstein theory. We do so by calculating the\nvalue of the entropy density at the anti-deSitter space boundary and applying\nthe standard rules of the AdS/CFT correspondence. We interpret the variation of\nthe entropy density operator from the horizon to the boundary as due to the\nrenormalization of the effective gravitational couplings as they flow from the\nultra-violet to the infra-red. We discuss the cases of Einstein-Hilbert theory\nand f(R) theories in detail and make general comments about more complicated\ncases.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 107769,
    "score": 46.985801696777344,
    "userScore": 1
  },
  {
    "title": "Quasi-normal modes of AdS black holes : A superpotential approach",
    "paperAbstract": "  A novel method, based on superpotentials is proposed for obtaining the\nquasi-normal modes of anti-de Sitter black holes. This is inspired by the case\nof the three-dimensional BTZ black hole, where the quasi-normal modes can be\nobtained exactly and are proportional to the surface gravity. Using this\napproach, the quasi-normal modes of the five dimensional Schwarzschild\nanti-deSitter black hole are computed numerically. The modes again seem to be\nproportional to the surface gravity for very small and very large black holes.\nThey reflect the well-known instability of small black holes in anti-deSitter\nspace.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 1982261,
    "score": 46.9412841796875,
    "userScore": 3
  },
  {
    "title": "On the Penrose inequality in anti-deSitter space",
    "paperAbstract": "  For asymptotically flat spacetimes the Penrose inequality gives an initial\ndata test for the weak cosmic censorship hypothesis. We give a formulation of\nthis inequality for asymptotically anti-deSitter (AAdS) spacetimes, and show\nthat the inequality holds for time asymmetric data in spherical symmetry. Our\nanalysis is motivated by the constant-negative-spatial-curvature form of the\nAdS black hole metric.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 887261,
    "score": 46.70798110961914,
    "userScore": 0,
    "inAnnoy": true
  },
  {
    "title": "Dark matter candidates: black holes and gravitationally bound black hole\n  atoms in n-space",
    "paperAbstract": "  A comparison is made of a range of proposals to include free and bound black\nholes as either a small component or the dominant constituent of dark matter.\nThe hypothesis that dark matter consists of atomic gravitationally bound\nprimordial black holes is closely examined in 3-space, as well as in n-space.\nIt is demonstrated that for dimensions greater than 3, stable gravitational or\nelectrostatic atoms cannot be bound by energy constraints. The total number of\ndegrees of freedom of a d-dimensional body in n-space is derived so that\nequipartition of energy may be applied in the early universe. Blackbody and\nHawking radiation are generalized to n-space. A promising new approach to black\nhole entropy is presented.\n",
    "query": "dark matter and black holes  anti-desitter space",
    "docId": 1836570,
    "score": 46.44052505493164,
    "userScore": 2
  },
  {
    "title": "Enhanced Radiation ? from (Super) Conductor by Dark Matter Axion",
    "paperAbstract": "  In our previous paper we have shown that enhanced radiations arise from\n(super) conductor by dark matter axion under strong magnetic field. We have\nrecalculated the radiation by carefully treating boundary conditions between\nvacuum and the conductor. We show that the radiation is never enhanced. We\ninterpret it such that electromagnetic field induced by axion collides the\nconductor and it is reflected by the conductor. The reflecting wave is the\nradiation from the conductor. It is reasonable that the amplitude of the\nreflection wave is identical to that of the incoming wave, i.e. radiation\ninduced by axion.\n",
    "query": "room temperature super conductor",
    "docId": 1556667,
    "score": 32.274940490722656,
    "userScore": 1
  },
  {
    "title": "Coupling two laser-cooled ions via a room-temperature conductor",
    "paperAbstract": "  We demonstrate coupling between the motions of two independently trapped ions\nwith a separation distance of 620 $\\mu$m. The ion-ion interaction is enhanced\nvia a room-temperature electrically floating metallic wire which connects two\nsurface traps. Tuning the motion of both ions into resonance, we show flow of\nenergy with a coupling rate of 11 Hz. Quantum-coherent coupling is hindered by\nstrong surface electric-field noise in our device. Our ion wire-ion system\ndemonstrates that room-temperature conductors can be used to mediate and tune\ninteractions between independently trapped charges over distances beyond those\nachievable with free-space dipole-dipole coupling. This technology may be used\nto sympathetically cool or entangle remotely trapped charges and enable\ncoupling between disparate physical systems.\n",
    "query": "room temperature super conductor",
    "docId": 1494863,
    "score": 30.389270782470703,
    "userScore": 1
  },
  {
    "title": "Room-temperature chirality switching in a helimagnetic thin film",
    "paperAbstract": "  Helimagnetic structures, in which the magnetic moments are spirally ordered,\nhost an internal degree of freedom called chirality (or helicity) corresponding\nto the handedness of the helix. The chirality seems quite robust against\ndisturbances and is therefore promising for next-generation magnetic memory.\nWhile the chirality control was recently achieved by the magnetic field sweep\nwith the application of an electric current at low temperature in a conducting\nhelimagnet, problems such as low working temperature and cumbersome control\nsequence have to be solved in practical applications. Another issue is the thin\nfilm fabrication that enables the development of spintronic devices based on\nhelimagnets. Here we show chirality switching by electric current pulses at\nroom temperature in a thin-film MnAu$_2$ helimagnetic conductor. The result\ndemonstrates the feasibility of helimagnet-based spintronics that can overcome\nall the above problems.\n",
    "query": "room temperature super conductor",
    "docId": 1657524,
    "score": 29.559791564941406,
    "userScore": 1
  },
  {
    "title": "Room-temperature detection of single 20 nm super-paramagnetic\n  nanoparticles with an imaging magnetometer",
    "paperAbstract": "  We demonstrate room temperature detection of single 20 nm super-paramagnetic\nnanoparticles (SPNs) with a wide-field optical microscope platform suitable for\nbiological integration. The particles are made of magnetite (Fe3O4) and are\nthus non-toxic and biocompatible. Detection is accomplished via optically\ndetected magnetic resonance imaging using nitrogen-vacancy defect centers in\ndiamond, resulting in a DC magnetic field detection limit of 2.3 {\\mu}T. This\nmarks a large step forward in the detection of SPNs, and we expect that it will\nallow for the development of magnetic-field-based biosensors capable of\ndetecting a single molecular binding event.\n",
    "query": "room temperature super conductor",
    "docId": 505765,
    "score": 29.533023834228516,
    "userScore": 1
  },
  {
    "title": "Room-Temperature Superconductivity",
    "paperAbstract": "  This is the first book on the subject of room-temperature superconductivity.\nThe main purpose of the book is twofold. First, to show that, under suitable\nconditions, superconductivity can occur above room temperature. Secondly, to\npresent general guidelines on how to synthesize a room temperature\nsuperconductor. The book begins with an introduction into the physics of the\nsuperconducting state and superconducting materials. The mechanisms of\nconventional, half-conventional and unconventional superconductivity are\ndiscussed in the following chapters. The last three chapters of the book are\ndevoted to room temperature superconductivity. In Chapter 2, an attempt to\nreview the basic properties of the superconducting state independently of any\nspecific mechanism is made for the first time. In addition, four principles of\nsuperconductivity valid for any type of superconductivity are introduced in\nChapter 4. The book is mainly addressed to specialists in materials science and\nin the field of superconductivity. At the same time, students will also benefit\nfrom reading the first nine chapters of the book.\n",
    "query": "room temperature super conductor",
    "docId": 1945581,
    "score": 29.481401443481445,
    "userScore": 3,
    "inAnnoy": true
  },
  {
    "title": "Design for a Room Temperature Superconductor",
    "paperAbstract": "  The vision of ``room temperature superconductivity'' has appeared\nintermittently but prominently in the literature since 1964, when W. A. Little\nand V. L. Ginzburg began working on the `problem of high temperature\nsuperconductivity' around the same time. Since that time the prospects for room\ntemperature superconductivity have varied from gloom (around 1980) to glee (the\nyears immediately after the discovery of HTS), to wait-and-see (the current\nfeeling). Recent discoveries have clarified old issues, making it possible to\nconstruct the blueprint for a viable room temperature superconductor.\n",
    "query": "room temperature super conductor",
    "docId": 1943581,
    "score": 28.838634490966797,
    "userScore": 3
  },
  {
    "title": "Proposal of room-temperature diamond maser",
    "paperAbstract": "  Lasers have revolutionized optical science and technology, but their\nmicrowave counterpart, maser, has not realized its great potential due to its\ndemanding work conditions (high-vacuum for gas maser and liquid-helium\ntemperature for solid-state maser). Room-temperature solid-state maser is\nhighly desirable, but under such conditions the lifetimes of emitters (usually\nelectron spins) are usually too short (~ns) for population inversion. The only\nroom-temperature solid-state maser is based on a pentacene-doped p-terphenyl\ncrystal, which has long spin lifetime (~0.1 ms). This maser, however, operates\nonly in the pulse mode and the material is unstable. Here we propose\nroom-temperature maser based on nitrogen-vacancy (NV) centres in diamond, which\nfeature long spin lifetimes at room temperature (~10 ms), high optical pump\nefficiency, and material stability. We demonstrate that under readily\naccessible conditions, room-temperature diamond maser is feasible.\nRoom-temperature diamond maser may facilitate a broad range of microwave\ntechnologies.\n",
    "query": "room temperature super conductor",
    "docId": 662548,
    "score": 28.34123992919922,
    "userScore": 1
  },
  {
    "title": "Novel approach to Room Temperature Superconductivity problem",
    "paperAbstract": "  A long-standing problem of observing Room Temperature Superconductivity is\nfinally solved by a novel approach. Instead of increasing the critical\ntemperature Tc of a superconductor, the temperature of the room was decreased\nto an appropriate Tc value. We consider this approach more promising for\nobtaining a large number of materials possessing Room Temperature\nSuperconductivity in the near future.\n",
    "query": "room temperature super conductor",
    "docId": 1264676,
    "score": 27.81746482849121,
    "userScore": 1,
    "inAnnoy": true
  },
  {
    "title": "Polariton condensates at room temperature",
    "paperAbstract": "  We review the recent developments of the polariton physics in microcavities\nfeaturing the exciton-photon strong coupling at room-temperature, and leading\nto the achievement of room-temperature polariton condensates. Such cavities\nembed active layers with robust excitons that present a large binding energy\nand a large oscillator strength, i.e. wide bandgap inorganic or organic\nsemiconductors, or organic molecules. These various systems are compared, in\nterms of figures of merit and of common features related to their strong\noscillator strength. The various demonstrations of polariton laser are\ncompared, as well as their condensation phase diagrams. The room-temperature\noperation indeed allows a detailed investigation of the thermodynamic and\nout-of-equilibrium regimes of the condensation process. The crucial role of the\nspatial dynamics of the condensate formation is discussed, as well as the\ndebated issue of the mechanism of stimulated relaxation from the reservoir to\nthe condensate under non-resonant excitation. Finally the prospects of\npolariton devices are presented.\n",
    "query": "room temperature super conductor",
    "docId": 714514,
    "score": 27.514728546142578,
    "userScore": 1
  },
  {
    "title": "Road to room-temperature superconductivity: A universal model",
    "paperAbstract": "  In a semiclassical view superconductivity is attributed exclusively to the\nadvance of atoms' outer s electrons through the nuclei of neighbor atoms in a\nsolid. The necessary progression of holes in the opposite direction has the\nelectric and magnetic effect as if two electrons were advancing instead of each\nactual one. Superconductivity ceases when the associated lateral oscillation of\nthe outer s electrons extends between neighbor atoms. If such overswing occurs\nalready at T = 0, then the material is a normal conductor. Otherwise, lateral\noverswing can be caused by lattice vibrations at a critical temperature Tc or\nby a critical magnetic field Bc. Lateral electron oscillations are reduced -\nand Tc is increased - when the atoms of the outer s electrons are squeezed, be\nit in the bulk crystal, in a thin film, or under external pressure on the\nsample. The model is applied to alkali metals and alkali-doped fullerenes.\nAluminum serves as an example of a simple metal with superconductivity.\nApplication of the model to transition metals, intertransitional alloys and\ncompounds of transition metals with other elements sheds light on the pattern\nof their critical temperature. More examples of the squeeze effect are provided\nby the superconductivity of PdH, MgB2, borocarbides, ferropnictides, and\norganic charge-transfer salts. The model also provides the superconduction\nmechanism in the oxide superconductors, exemplified by YBa2Cu3O7. Finally the\nmodel suggests which steps to take in order to reach superconductivity at room\ntemperature and above.\n",
    "query": "room temperature super conductor",
    "docId": 409383,
    "score": 27.36663055419922,
    "userScore": 2
  },
  {
    "title": "Quantum Computational Supremacy",
    "paperAbstract": "  The field of quantum algorithms aims to find ways to speed up the solution of\ncomputational problems by using a quantum computer. A key milestone in this\nfield will be when a universal quantum computer performs a computational task\nthat is beyond the capability of any classical computer, an event known as\nquantum supremacy. This would be easier to achieve experimentally than\nfull-scale quantum computing, but involves new theoretical challenges. Here we\npresent the leading proposals to achieve quantum supremacy, and discuss how we\ncan reliably compare the power of a classical computer to the power of a\nquantum computer.\n",
    "query": "quantum computer supremacy",
    "docId": 1027458,
    "score": 43.37648010253906,
    "userScore": 3
  },
  {
    "title": "Quantum supremacy in driven quantum many-body systems",
    "paperAbstract": "  A crucial milestone in the field of quantum simulation and computation is to\ndemonstrate that a quantum device can compute certain tasks that are impossible\nto reproduce by a classical computer with any reasonable resources. Such a\ndemonstration is referred to as quantum supremacy. One of the most important\nquestions is to identify setups that exhibit quantum supremacy and can be\nimplemented with current quantum technology. The two standard candidates are\nboson sampling and random quantum circuits. Here, we show that quantum\nsupremacy can be obtained in generic periodically-driven quantum many-body\nsystems. Our analysis is based on the eigenstate thermalization hypothesis and\nstrongly-held conjectures in complexity theory. To illustrate our work, We give\nexamples of simple disordered Ising chains driven by global magnetic fields and\nBose-Hubbard chains with modulated hoppings. Our proposal opens the way for a\nlarge class of quantum platforms to demonstrate and benchmark quantum\nsupremacy.\n",
    "query": "quantum computer supremacy",
    "docId": 1249369,
    "score": 38.72114944458008,
    "userScore": 3
  },
  {
    "title": "Quantum Sampling Problems, BosonSampling and Quantum Supremacy",
    "paperAbstract": "  There is a large body of evidence for the potential of greater computational\npower using information carriers that are quantum mechanical over those\ngoverned by the laws of classical mechanics. But the question of the exact\nnature of the power contributed by quantum mechanics remains only partially\nanswered. Furthermore, there exists doubt over the practicality of achieving a\nlarge enough quantum computation that definitively demonstrates quantum\nsupremacy. Recently the study of computational problems that produce samples\nfrom probability distributions has added to both our understanding of the power\nof quantum algorithms and lowered the requirements for demonstration of fast\nquantum algorithms. The proposed quantum sampling problems do not require a\nquantum computer capable of universal operations and also permit physically\nrealistic errors in their operation. This is an encouraging step towards an\nexperimental demonstration of quantum algorithmic supremacy. In this paper, we\nwill review sampling problems and the arguments that have been used to deduce\nwhen sampling problems are hard for classical computers to simulate. Two\nclasses of quantum sampling problems that demonstrate the supremacy of quantum\nalgorithms are BosonSampling and IQP Sampling. We will present the details of\nthese classes and recent experimental progress towards demonstrating quantum\nsupremacy in BosonSampling.\n",
    "query": "quantum computer supremacy",
    "docId": 817655,
    "score": 38.19820785522461,
    "userScore": 2
  },
  {
    "title": "Quantum supremacy and random circuits",
    "paperAbstract": "  As Moore's law reaches its limits, quantum computers are emerging with the\npromise of dramatically outperforming classical computers. We have witnessed\nthe advent of quantum processors with over $50$ quantum bits (qubits), which\nare expected to be beyond the reach of classical simulation. Quantum supremacy\nis the event at which the old Extended Church-Turing Thesis is overturned: A\nquantum computer performs a task that is practically impossible for any\nclassical (super)computer. The demonstration requires both a solid theoretical\nguarantee and an experimental realization. The lead candidate is Random Circuit\nSampling (RCS), which is the task of sampling from the output distribution of\nrandom quantum circuits. Google recently announced a $53-$qubit experimental\ndemonstration of RCS. Soon after, classical algorithms appeared that challenge\nthe supremacy of random circuits by estimating their outputs. How hard is it to\nclassically simulate the output of random quantum circuits?\n  We prove that estimating the output probabilities of random quantum circuits\nis formidably hard ($\\#P$-Hard) for any classical computer. This makes RCS the\nstrongest candidate for demonstrating quantum supremacy relative to all other\nproposals. The robustness to the estimation error that we prove may serve as a\nnew hardness criterion for the performance of classical algorithms. To achieve\nthis, we introduce the Cayley path interpolation between any two gates of a\nquantum computation and convolve recent advances in quantum complexity and\ninformation with probability and random matrices. Furthermore, we apply\nalgebraic geometry to generalize the well-known Berlekamp-Welch algorithm that\nis widely used in coding theory and cryptography. Our results imply that there\nis an exponential hardness barrier for the classical simulation of most quantum\ncircuits.\n",
    "query": "quantum computer supremacy",
    "docId": 1176248,
    "score": 38.13731002807617,
    "userScore": 1
  },
  {
    "title": "Statistical Aspects of the Quantum Supremacy Demonstration",
    "paperAbstract": "  The notable claim of quantum supremacy presented by Google's team in 2019\nconsists of demonstrating the ability of a quantum circuit to generate, albeit\nwith considerable noise, bitstrings from a distribution that is considered hard\nto simulate on classical computers. Verifying that the generated data is indeed\nfrom the claimed distribution and assessing the circuit's noise level and its\nfidelity is a purely statistical undertaking. The objective of this paper is to\nexplain the relations between quantum computing and some of the statistical\naspects involved in demonstrating quantum supremacy in terms that are\naccessible to statisticians, computer scientists, and mathematicians. Starting\nwith the statistical analysis in Google's demonstration, which we explain, we\nstudy various estimators of the fidelity, and different approaches to testing\nthe distributions generated by the quantum computer. We propose different noise\nmodels, and discuss their implications. A preliminary study of the Google data,\nfocusing mostly on circuits of 12 and 14 qubits is discussed throughout the\npaper.\n",
    "query": "quantum computer supremacy",
    "docId": 1332899,
    "score": 37.6484375,
    "userScore": 2
  },
  {
    "title": "Classical Simulation of Quantum Supremacy Circuits",
    "paperAbstract": "  It is believed that random quantum circuits are difficult to simulate\nclassically. These have been used to demonstrate quantum supremacy: the\nexecution of a computational task on a quantum computer that is infeasible for\nany classical computer. The task underlying the assertion of quantum supremacy\nby Arute et al. (Nature, 574, 505--510 (2019)) was initially estimated to\nrequire Summit, the world's most powerful supercomputer today, approximately\n10,000 years. The same task was performed on the Sycamore quantum processor in\nonly 200 seconds.\n  In this work, we present a tensor network-based classical simulation\nalgorithm. Using a Summit-comparable cluster, we estimate that our simulator\ncan perform this task in less than 20 days. On moderately-sized instances, we\nreduce the runtime from years to minutes, running several times faster than\nSycamore itself. These estimates are based on explicit simulations of parallel\nsubtasks, and leave no room for hidden costs. The simulator's key ingredient is\nidentifying and optimizing the \"stem\" of the computation: a sequence of\npairwise tensor contractions that dominates the computational cost. This\norders-of-magnitude reduction in classical simulation time, together with\nproposals for further significant improvements, indicates that achieving\nquantum supremacy may require a period of continuing quantum hardware\ndevelopments without an unequivocal first demonstration.\n",
    "query": "quantum computer supremacy",
    "docId": 1286582,
    "score": 37.379547119140625,
    "userScore": 1
  },
  {
    "title": "No imminent quantum supremacy by boson sampling",
    "paperAbstract": "  It is predicted that quantum computers will dramatically outperform their\nconventional counterparts. However, large-scale universal quantum computers are\nyet to be built. Boson sampling is a rudimentary quantum algorithm tailored to\nthe platform of photons in linear optics, which has sparked interest as a rapid\nway to demonstrate this quantum supremacy. Photon statistics are governed by\nintractable matrix functions known as permanents, which suggests that sampling\nfrom the distribution obtained by injecting photons into a linear-optical\nnetwork could be solved more quickly by a photonic experiment than by a\nclassical computer. The contrast between the apparently awesome challenge faced\nby any classical sampling algorithm and the apparently near-term experimental\nresources required for a large boson sampling experiment has raised\nexpectations that quantum supremacy by boson sampling is on the horizon. Here\nwe present classical boson sampling algorithms and theoretical analyses of\nprospects for scaling boson sampling experiments, showing that near-term\nquantum supremacy via boson sampling is unlikely. While the largest boson\nsampling experiments reported so far are with 5 photons, our classical\nalgorithm, based on Metropolised independence sampling (MIS), allowed the boson\nsampling problem to be solved for 30 photons with standard computing hardware.\nWe argue that the impact of experimental photon losses means that demonstrating\nquantum supremacy by boson sampling would require a step change in technology.\n",
    "query": "quantum computer supremacy",
    "docId": 844227,
    "score": 36.73841857910156,
    "userScore": 0
  },
  {
    "title": "Comment on the Quantum Supremacy Claim by Google",
    "paperAbstract": "  Quantum computation promises to execute certain computational tasks on time\nscales much faster than any known algorithm on an existing classical computer,\nfor example calculating the prime factors of large integers. Recently a\nresearch team from Google claimed to have carried out such a task with a\nquantum computer, demonstrating in practice a case of this so-called quantum\nsupremacy. Here we argue that this claim was not justified. Unlike other\ncomments, our criticism is concerned with the missing verification of the\noutput data of the quantum computation.\n",
    "query": "quantum computer supremacy",
    "docId": 1522677,
    "score": 36.661643981933594,
    "userScore": 1
  },
  {
    "title": "Characterizing Quantum Supremacy in Near-Term Devices",
    "paperAbstract": "  A critical question for the field of quantum computing in the near future is\nwhether quantum devices without error correction can perform a well-defined\ncomputational task beyond the capabilities of state-of-the-art classical\ncomputers, achieving so-called quantum supremacy. We study the task of sampling\nfrom the output distributions of (pseudo-)random quantum circuits, a natural\ntask for benchmarking quantum computers. Crucially, sampling this distribution\nclassically requires a direct numerical simulation of the circuit, with\ncomputational cost exponential in the number of qubits. This requirement is\ntypical of chaotic systems. We extend previous results in computational\ncomplexity to argue more formally that this sampling task must take exponential\ntime in a classical computer. We study the convergence to the chaotic regime\nusing extensive supercomputer simulations, modeling circuits with up to 42\nqubits - the largest quantum circuits simulated to date for a computational\ntask that approaches quantum supremacy. We argue that while chaotic states are\nextremely sensitive to errors, quantum supremacy can be achieved in the\nnear-term with approximately fifty superconducting qubits. We introduce cross\nentropy as a useful benchmark of quantum circuits which approximates the\ncircuit fidelity. We show that the cross entropy can be efficiently measured\nwhen circuit simulations are available. Beyond the classically tractable\nregime, the cross entropy can be extrapolated and compared with theoretical\nestimates of circuit fidelity to define a practical quantum supremacy test.\n",
    "query": "quantum computer supremacy",
    "docId": 756725,
    "score": 36.098388671875,
    "userScore": 1
  },
  {
    "title": "On the meaning of \"quantum supremacy\" experiments",
    "paperAbstract": "  The recently reported experimental results claiming \"quantum supremacy\"\nachieved by Google quantum device are critically discussed. The Google team\nconstructed a quantum chaotic system based on Josephson junction technology\nwhich cannot be reliably simulated by the present day supercomputers. However,\nthe similar \"supremacy\" can be realized for properly designed micro-mechanical\ndevices, like periodically forced Duffing oscillator, using the available\ntechnology of quartz clocks. It is also reminded that classical and quantum\nchaotic systems behave in a similar way. Therefore, in this case, one should\nspeak rather about the \"analog supremacy\" than \"quantum supremacy\" what means\nthat even now mechanical analog computers can outperform supercomputers when\nthe computational task can be reduced to sampling of ergodic measures generated\nby chaotic systems.\n",
    "query": "quantum computer supremacy",
    "docId": 1226204,
    "score": 35.982505798339844,
    "userScore": 2
  },
  {
    "title": "Bounding the speed of `spooky action at a distance'",
    "paperAbstract": "  In the well-known EPR paper, Einstein et al. called the nonlocal correlation\nin quantum entanglement as `spooky action at a distance'. If the spooky action\ndoes exist, what is its speed? All previous experiments along this direction\nhave locality loopholes and thus can be explained without having to invoke any\n`spooky action' at all. Here, we strictly closed the locality loopholes by\nobserving a 12-hour continuous violation of Bell inequality and concluded that\nthe lower bound speed of `spooky action' was four orders of magnitude of the\nspeed of light if the Earth's speed in any inertial reference frame was less\nthan 10^(-3) times of the speed of light.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 412271,
    "score": 63.13692855834961,
    "userScore": 3,
    "inAnnoy": true
  },
  {
    "title": "Extracting Spooky-activation-at-a-distance from Considerations of\n  Entanglement",
    "paperAbstract": "  Following an early claim by Nelson & McEvoy \\cite{Nelson:McEvoy:2007}\nsuggesting that word associations can display `spooky action at a distance\nbehaviour', a serious investigation of the potentially quantum nature of such\nassociations is currently underway. This paper presents a simple quantum model\nof a word association system. It is shown that a quantum model of word\nentanglement can recover aspects of both the Spreading Activation equation and\nthe Spooky-activation-at-a-distance equation, both of which are used to model\nthe activation level of words in human memory.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 105616,
    "score": 59.150970458984375,
    "userScore": 1
  },
  {
    "title": "Testing spooky action at a distance",
    "paperAbstract": "  In science, one observes correlations and invents theoretical models that\ndescribe them. In all sciences, besides quantum physics, all correlations are\ndescribed by either of two mechanisms. Either a first event influences a second\none by sending some information encoded in bosons or molecules or other\nphysical carriers, depending on the particular science. Or the correlated\nevents have some common causes in their common past. Interestingly, quantum\nphysics predicts an entirely different kind of cause for some correlations,\nnamed entanglement. This new kind of cause reveals itself, e.g., in\ncorrelations that violate Bell inequalities (hence cannot be described by\ncommon causes) between space-like separated events (hence cannot be described\nby classical communication). Einstein branded it as spooky action at a\ndistance. A real spooky action at a distance would require a faster than light\ninfluence defined in some hypothetical universally privileged reference frame.\nHere we put stringent experimental bounds on the speed of all such hypothetical\ninfluences. We performed a Bell test during more than 24 hours between two\nvillages separated by 18 km and approximately east-west oriented, with the\nsource located precisely in the middle. We continuously observed 2-photon\ninterferences well above the Bell inequality threshold. Taking advantage of the\nEarth's rotation, the configuration of our experiment allowed us to determine,\nfor any hypothetically privileged frame, a lower bound for the speed of this\nspooky influence. For instance, if such a privileged reference frame exists and\nis such that the Earth's speed in this frame is less than 10^-3 that of the\nspeed of light, then the speed of this spooky influence would have to exceed\nthat of light by at least 4 orders of magnitude.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 79448,
    "score": 57.877052307128906,
    "userScore": 1
  },
  {
    "title": "How Does Nature Accomplish Spooky Action at a Distance?",
    "paperAbstract": "  The enigmatic nonlocal quantum correlation that was famously derided by\nEinstein as \"spooky action at a distance\" has now been experimentally\ndemonstrated to be authentic. The quantum entanglement and nonlocal\ncorrelations emerged as inevitable consequences of John Bell's epochal paper on\nBell's inequality. However, in spite of some extraordinary applications as well\nas attempts to explain the reason for quantum nonlocality, a satisfactory\naccount of how Nature accomplishes this astounding phenomenon is yet to emerge.\nA cogent mechanism for the occurrence of this incredible event is presented in\nterms of a plausible quantum mechanical Einstein-Rosen bridge.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 1781304,
    "score": 54.53418731689453,
    "userScore": 1
  },
  {
    "title": "There Is No Action at a Distance in Quantum Mechanics, Spooky or\n  Otherwise",
    "paperAbstract": "  I feel compelled to respond to the frequent references to spooky action at a\ndistance that often accompany reports of experiments investigating entangled\nquantum mechanical states. Most, but not all, of these articles have appeared\nin the popular press. As an experimentalist I have great admiration for such\nexperiments and the concomitant advances in quantum information and quantum\ncomputing, but accompanying claims of action at a distance are quite simply\nnonsense. Some physicists and philosophers of science have bought into the\nstory by promoting the nonlocal nature of quantum mechanics. In 1964, John Bell\nproved that classical hidden variable theories cannot reproduce the predictions\nof quantum mechanics unless they employ some type of action at a distance. I\nhave no problem with this conclusion. Unfortunately, Bell later expanded his\nanalysis and mistakenly deduced that quantum mechanics and by implication\nnature herself are nonlocal. In addition, some of these articles present\nEinstein in caricature, a tragic figure who neither understood quantum\nmechanics nor believed it to be an accurate theory of nature. Consequently, the\ncurrent experiments have proven him wrong. This is also nonsense.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 993565,
    "score": 53.322391510009766,
    "userScore": 2
  },
  {
    "title": "Spooky Action at a Distance",
    "paperAbstract": "  This article studies quantum mechanical entanglement. We begin by\nillustrating why entanglement implies action at a distance. We then introduce a\nsimple criterion for determining when a pure quantum state is entangled.\nFinally, we present a measure for the amount of entanglement for a pure state.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 1291665,
    "score": 52.788414001464844,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "Comment on: Testing the speed of 'spooky action at a distance'",
    "paperAbstract": "  In a recent experiment, Salart et al. addressed the important issues of the\nspeed of hypothetical communication and of reference frames in Bell-type\nexperiments. The authors report that they \"performed a Bell experiment using\nentangled photons\" and conclude from their experimental results that \"to\nmaintain an explanation based on spooky action at a distance we would have to\nassume that the spooky action propagates at speeds even greater than the bounds\nobtained in our experiment\", exceeding the speed of light by orders of\nmagnitude. Here we show that, analyzing the experimental procedure,\nexplanations with subluminal or even no communication at all exist for the\nexperiment.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 90031,
    "score": 51.02146911621094,
    "userScore": 1
  },
  {
    "title": "Entanglement Swapping and Action at a Distance",
    "paperAbstract": "  A 2015 experiment by Hanson and Delft colleagues provided further\nconfirmation that the quantum world violates the Bell inequalities, being the\nfirst Bell test to close two known experimental loopholes simultaneously. The\nexperiment was also taken to provide new evidence of 'spooky action at a\ndistance'. Here we argue for caution about the latter claim. The Delft\nexperiment relies on entanglement swapping, and our main claim is that this\ngeometry introduces an additional loophole in the argument from violation of\nthe Bell inequalities to action at a distance: the apparent action at a\ndistance may be an artifact of 'collider bias'. In the absence of\nretrocausality, the sensitivity of such experiments to this 'Collider Loophole'\n(CL) depends on the temporal relation between the entanglement swapping\nmeasurement C and the two measurements A and B between which we seek to infer a\ncausal connection. CL looms large if the C is in the future of A and B, but not\nif C is in the past. The Delft experiment itself is the intermediate case, in\nwhich the separation is spacelike. We argue that this leaves it vulnerable to\nCL, unable to establish conclusively that it avoids it. An Appendix discusses\nthe implications of permitting retrocausality for the issue of causal influence\nacross entanglement swapping measurements.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 1409112,
    "score": 49.93588638305664,
    "userScore": 2
  },
  {
    "title": "Spooky action at a distance in general probabilistic theories",
    "paperAbstract": "  We call a probabilistic theory \"complete\" if it cannot be further refined by\nno-signaling hidden-variable models, and name a theory \"spooky\" if every\nequivalent hidden-variable model violates Shimony's Outcome Independence. We\nprove that a complete theory is spooky if and only if it admits a pure steering\nstate in the sense of Schr\\\"odinger. Finally we show that steering of\ncomplementary states leads to a Schr\\\"odinger's cat-like paradox.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 281719,
    "score": 42.248504638671875,
    "userScore": 2
  },
  {
    "title": "Spooky action at a global distance: analysis of space-based entanglement\n  distribution for the quantum internet",
    "paperAbstract": "  Recent experimental breakthroughs in satellite quantum communications have\nopened up the possibility of creating a global quantum internet using satellite\nlinks. This approach appears to be particularly viable in the near term, due to\nthe lower attenuation of optical signals from satellite to ground, and due to\nthe currently short coherence times of quantum memories. The latter prevents\nground-based entanglement distribution using atmospheric or optical-fiber links\nat high rates over long distances. In this work, we propose a global-scale\nquantum internet consisting of a constellation of orbiting satellites that\nprovides a continuous, on-demand entanglement distribution service to ground\nstations. The satellites can also function as untrusted nodes for the purpose\nof long-distance quantum-key distribution. We develop a technique for\ndetermining optimal satellite configurations with continuous coverage that\nbalances both the total number of satellites and entanglement-distribution\nrates. Using this technique, we determine various optimal satellite\nconfigurations for a polar-orbit constellation, and we analyze the resulting\nsatellite-to-ground loss and achievable entanglement-distribution rates for\nmultiple ground station configurations. We also provide a comparison between\nthese entanglement-distribution rates and the rates of ground-based quantum\nrepeater schemes. Overall, our work provides the theoretical tools and the\nexperimental guidance needed to make a satellite-based global quantum internet\na reality.\n",
    "query": "spooky action at  distance and quantum entanglement and encryption",
    "docId": 1218574,
    "score": 41.224082946777344,
    "userScore": 2
  },
  {
    "title": "Faster Shortest Path Algorithm for H-Minor Free Graphs with Negative\n  Edge Weights",
    "paperAbstract": "  Let $H$ be a fixed graph and let $G$ be an $H$-minor free $n$-vertex graph\nwith integer edge weights and no negative weight cycles reachable from a given\nvertex $s$. We present an algorithm that computes a shortest path tree in $G$\nrooted at $s$ in $\\tilde{O}(n^{4/3}\\log L)$ time, where $L$ is the absolute\nvalue of the smallest edge weight. The previous best bound was\n$\\tilde{O}(n^{\\sqrt{11.5}-2}\\log L) = O(n^{1.392}\\log L)$. Our running time\nmatches an earlier bound for planar graphs by Henzinger et al.\n",
    "query": "shortest path on negative graph weights",
    "docId": 205807,
    "score": 49.653263092041016,
    "userScore": 3,
    "inAnnoy": true
  },
  {
    "title": "Shortest-Path-Preserving Rounding",
    "paperAbstract": "  Various applications of graphs, in particular applications related to finding\nshortest paths, naturally get inputs with real weights on the edges. However,\nfor algorithmic or visualization reasons, inputs with integer weights would\noften be preferable or even required. This raises the following question: given\nan undirected graph with non-negative real weights on the edges and an error\nthreshold $\\varepsilon$, how efficiently can we decide whether we can round all\nweights such that shortest paths are maintained, and the change of weight of\neach shortest path is less than $\\varepsilon$? So far, only for path-shaped\ngraphs a polynomial-time algorithm was known. In this paper we prove, by\nreduction from 3-SAT, that, in general, the problem is NP-hard. However, if the\ngraph is a tree with $n$ vertices, the problem can be solved in $O(n^2)$ time.\n",
    "query": "shortest path on negative graph weights",
    "docId": 1127057,
    "score": 49.12934875488281,
    "userScore": 1,
    "inAnnoy": true
  },
  {
    "title": "Semi-dynamic shortest-path tree algorithms for directed graphs with\n  arbitrary weights",
    "paperAbstract": "  Given a directed graph $G$ with arbitrary real-valued weights, the single\nsource shortest-path problem (SSSP) asks for, given a source $s$ in $G$,\nfinding a shortest path from $s$ to each vertex $v$ in $G$. A classical SSSP\nalgorithm detects a negative cycle of $G$ or constructs a shortest-path tree\n(SPT) rooted at $s$ in $O(mn)$ time, where $m,n$ are the numbers of edges and\nvertices in $G$ respectively. In many practical applications, new constraints\ncome from time to time and we need to update the SPT frequently. Given an SPT\n$T$ of $G$, suppose the weight on a certain edge is modified. We show by\nrigorous proof that the well-known {\\sf Ball-String} algorithm for positively\nweighted graphs can be adapted to solve the dynamic SPT problem for directed\ngraphs with arbitrary weights. Let $n_0$ be the number of vertices that are\naffected (i.e., vertices that have different distances from $s$ or different\nparents in the input and output SPTs) and $m_0$ the number of edges incident to\nan affected vertex. The adapted algorithms terminate in $O(m_0+n_0 \\log n_0)$\ntime, either detecting a negative cycle (only in the decremental case) or\nconstructing a new SPT $T'$ for the updated graph. We show by an example that\nthe output SPT $T'$ may have more than necessary edge changes to $T$. To remedy\nthis, we give a general method for transforming $T'$ into an SPT with minimal\nedge changes in time $O(n_0)$ provided that $G$ has no cycles with zero length.\n",
    "query": "shortest path on negative graph weights",
    "docId": 1094142,
    "score": 46.692352294921875,
    "userScore": 2
  },
  {
    "title": "Breaking the Bellman-Ford Shortest-Path Bound",
    "paperAbstract": "  In this paper we give a single-source shortest-path algorithm that breaks,\nafter over 60 years, the $O(n \\cdot m)$ time bound for the Bellman-Ford\nalgorithm, where $n$ is the number of vertices and $m$ is the number of arcs of\nthe graph. Our algorithm converts the input graph to a graph with nonnegative\nweights by performing at most $\\min(\\sqrt{n},\\sqrt{m/\\log n})$ calls to\nDijkstra's algorithm, such that the shortest-path tree is the same for the new\ngraph as that for the original. When Dijkstra's algorithm is implemented using\nFibonacci heaps, the running time of our algorithm is therefore $O(\\sqrt{n}\n\\cdot m + n \\cdot \\sqrt{m \\log n})$. We also give a second implementation that\nperforms few calls to Dijkstra's algorithm if the graph contains few negative\narcs on the shortest-path tree.\n",
    "query": "shortest path on negative graph weights",
    "docId": 1119761,
    "score": 46.081748962402344,
    "userScore": 2
  },
  {
    "title": "A New Single-Source Shortest Path Algorithm for Nonnegative Weight Graph",
    "paperAbstract": "  The single-source shortest path problem is a classical problem in the\nresearch field of graph algorithm. In this paper, a new single-source shortest\npath algorithm for nonnegative weight graph is proposed. The algorithm can\ncompress multi-round Fibonacci heap operations to one round to save running\ntime relative to Dijkstra's algorithm using Fibonacci heap. The time complexity\nof the algorithm is also O(m+nlogn) in the worst case, where m is the number of\nedges and n is the number of nodes. However, the bound can be linear in some\ncase, for example, when edge weights of a graph are all the same and the hop\ncount of the longest shortest path is much less than n.Based on the theoretical\nanalyses, we demonstrate that the algorithm is faster than Dijkstra's algorithm\nusing Fibonacci heap in average situation when n is large enough.\n",
    "query": "shortest path on negative graph weights",
    "docId": 579848,
    "score": 43.89265441894531,
    "userScore": 3
  },
  {
    "title": "Constrained Shortest Path Search with Graph Convolutional Neural\n  Networks",
    "paperAbstract": "  Planning for Autonomous Unmanned Ground Vehicles (AUGV) is still a challenge,\nespecially in difficult, off-road, critical situations. Automatic planning can\nbe used to reach mission objectives, to perform navigation or maneuvers. Most\nof the time, the problem consists in finding a path from a source to a\ndestination, while satisfying some operational constraints. In a graph without\nnegative cycles, the computation of the single-pair shortest path from a start\nnode to an end node is solved in polynomial time. Additional constraints on the\nsolution path can however make the problem harder to solve. This becomes the\ncase when we need the path to pass through a few mandatory nodes without\nrequiring a specific order of visit. The complexity grows exponentially with\nthe number of mandatory nodes to visit. In this paper, we focus on shortest\npath search with mandatory nodes on a given connected graph. We propose a\nhybrid model that combines a constraint-based solver and a graph convolutional\nneural network to improve search performance. Promising results are obtained on\nrealistic scenarios.\n",
    "query": "shortest path on negative graph weights",
    "docId": 1509793,
    "score": 42.55018997192383,
    "userScore": 2
  },
  {
    "title": "Successive shortest paths in complete graphs with random edge weights",
    "paperAbstract": "  Consider a complete graph $K_n$ with edge weights drawn independently from a\nuniform distribution $U(0,1)$. The weight of the shortest (minimum-weight) path\n$P_1$ between two given vertices is known to be $\\ln n / n$, asymptotically.\nDefine a second-shortest path $P_2$ to be the shortest path edge-disjoint from\n$P_1$, and consider more generally the shortest path $P_k$ edge-disjoint from\nall earlier paths. We show that the cost $X_k$ of $P_k$ converges in\nprobability to $2k/n+\\ln n/n$ uniformly for all $k \\leq n-1$. We show analogous\nresults when the edge weights are drawn from an exponential distribution. The\nsame results characterise the collectively cheapest $k$ edge-disjoint paths,\ni.e., a minimum-cost $k$-flow. We also obtain the expectation of $X_k$\nconditioned on the existence of $P_k$.\n",
    "query": "shortest path on negative graph weights",
    "docId": 1199745,
    "score": 42.4311408996582,
    "userScore": 1
  },
  {
    "title": "Constrained Shortest Path and Hierarchical Structures",
    "paperAbstract": "  The Constraint Shortest Path (CSP) problem is as follows. An $n$-vertex graph\nis given, each edge/arc assigned two weights. Let us call them \"cost\" and\n\"length\" for definiteness. Finding a min-cost upper-bounded length path between\na given pair of vertices is required. The problem is NP-hard even when the\nlengths of all edges are the same. Therefore, various approximation algorithms\nhave been proposed in the literature for it. The constraint on path length can\nbe accounted for by considering one edge weight equals to a linear combination\nof cost and length. By varying the multiplier value in a linear combination, a\nfeasible solution delivers a minimum to the function with new weights. At the\nsame time, Dijkstra's algorithm or its modifications are used to construct the\nshortest path with the current weights of the edges. However, with\ninsufficiently large graphs, this approach may turn out to be time-consuming.\nIn this article, we propose to look for a solution, not in the original graph\nbut specially constructed hierarchical structures (HS). We show that the\nshortest path in the HS is constructed with $O(m)$-time complexity, where $m$\nis the number of edges/arcs of the graph, and the approximate solution in the\ncase of integer costs and lengths of the edges is found with $O(m\\log n)$-time\ncomplexity. The a priori estimate of the algorithm's accuracy turned out to\ndepend on the parameters of the problem and can be significant. Therefore, to\nevaluate the algorithm's effectiveness, we conducted a numerical experiment on\nthe graphs of roads of megalopolis and randomly constructed unit-disk graphs\n(UDGs). The numerical experiment results show that in the HS, a solution close\nto optimal one is built 10--100 times faster than in the methods which use\nDijkstra's algorithm to build a min-weight path in the original graph.\n",
    "query": "shortest path on negative graph weights",
    "docId": 1635098,
    "score": 42.31999206542969,
    "userScore": 1
  },
  {
    "title": "A scalable method to find the shortest path in a graph with circuits of\n  memristors",
    "paperAbstract": "  Finding the shortest path in a graph has applications to a wide range of\noptimization problems. However, algorithmic methods scale with the size of the\ngraph in terms of time and energy. We propose a method to solve the shortest\npath problem using circuits of nanodevices called memristors and validate it on\ngraphs of different sizes and topologies. It is both valid for an\nexperimentally derived memristor model and robust to device variability. The\ntime and energy of the computation scale with the length of the shortest path\nrather than with the size of the graph, making this method particularly\nattractive for solving large graphs with small path lengths.\n",
    "query": "shortest path on negative graph weights",
    "docId": 1024693,
    "score": 42.012962341308594,
    "userScore": 2
  },
  {
    "title": "Linear Time Algorithms Based on Multilevel Prefix Tree for Finding\n  Shortest Path with Positive Weights and Minimum Spanning Tree in a Networks",
    "paperAbstract": "  In this paper I present general outlook on questions relevant to the basic\ngraph algorithms; Finding the Shortest Path with Positive Weights and Minimum\nSpanning Tree. I will show so far known solution set of basic graph problems\nand present my own. My solutions to graph problems are characterized by their\nlinear worst-case time complexity. It should be noticed that the algorithms\nwhich compute the Shortest Path and Minimum Spanning Tree problems not only\nanalyze the weight of arcs (which is the main and often the only criterion of\nsolution hitherto known algorithms) but also in case of identical path weights\nthey select this path which walks through as few vertices as possible. I have\npresented algorithms which use priority queue based on multilevel prefix tree\n-- PTrie. PTrie is a clever combination of the idea of prefix tree -- Trie, the\nstructure of logarithmic time complexity for insert and remove operations,\ndoubly linked list and queues. In C++ I will implement linear worst-case time\nalgorithm computing the Single-Destination Shortest-Paths problem and I will\nexplain its usage.\n",
    "query": "shortest path on negative graph weights",
    "docId": 21259,
    "score": 41.96466064453125,
    "userScore": 1
  },
  {
    "title": "Super-Identity Convolutional Neural Network for Face Hallucination",
    "paperAbstract": "  Face hallucination is a generative task to super-resolve the facial image\nwith low resolution while human perception of face heavily relies on identity\ninformation. However, previous face hallucination approaches largely ignore\nfacial identity recovery. This paper proposes Super-Identity Convolutional\nNeural Network (SICNN) to recover identity information for generating faces\nclosed to the real identity. Specifically, we define a super-identity loss to\nmeasure the identity difference between a hallucinated face and its\ncorresponding high-resolution face within the hypersphere identity metric\nspace. However, directly using this loss will lead to a Dynamic Domain\nDivergence problem, which is caused by the large margin between the\nhigh-resolution domain and the hallucination domain. To overcome this\nchallenge, we present a domain-integrated training approach by constructing a\nrobust identity metric for faces from these two domains. Extensive experimental\nevaluations demonstrate that the proposed SICNN achieves superior visual\nquality over the state-of-the-art methods on a challenging task to\nsuper-resolve 12$\\times$14 faces with an 8$\\times$ upscaling factor. In\naddition, SICNN significantly improves the recognizability of\nultra-low-resolution faces.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 1046961,
    "score": 38.51967239379883,
    "userScore": 2
  },
  {
    "title": "Reverse Prevention Sampling for Misinformation Mitigation in Social\n  Networks",
    "paperAbstract": "  In this work, we consider misinformation propagating through a social network\nand study the problem of its prevention. In this problem, a \"bad\" campaign\nstarts propagating from a set of seed nodes in the network and we use the\nnotion of a limiting (or \"good\") campaign to counteract the effect of\nmisinformation. The goal is to identify a set of $k$ users that need to be\nconvinced to adopt the limiting campaign so as to minimize the number of people\nthat adopt the \"bad\" campaign at the end of both propagation processes.\n  This work presents \\emph{RPS} (Reverse Prevention Sampling), an algorithm\nthat provides a scalable solution to the misinformation mitigation problem. Our\ntheoretical analysis shows that \\emph{RPS} runs in $O((k + l)(n + m)(\\frac{1}{1\n- \\gamma}) \\log n / \\epsilon^2 )$ expected time and returns a $(1 - 1/e -\n\\epsilon)$-approximate solution with at least $1 - n^{-l}$ probability (where\n$\\gamma$ is a typically small network parameter and $l$ is a confidence\nparameter). The time complexity of \\emph{RPS} substantially improves upon the\npreviously best-known algorithms that run in time $\\Omega(m n k \\cdot\nPOLY(\\epsilon^{-1}))$. We experimentally evaluate \\emph{RPS} on large datasets\nand show that it outperforms the state-of-the-art solution by several orders of\nmagnitude in terms of running time. This demonstrates that misinformation\nmitigation can be made practical while still offering strong theoretical\nguarantees.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 998370,
    "score": 38.10630798339844,
    "userScore": 2
  },
  {
    "title": "FH-GAN: Face Hallucination and Recognition using Generative Adversarial\n  Network",
    "paperAbstract": "  There are many factors affecting visual face recognition, such as low\nresolution images, aging, illumination and pose variance, etc. One of the most\nimportant problem is low resolution face images which can result in bad\nperformance on face recognition. Most of the general face recognition\nalgorithms usually assume a sufficient resolution for the face images. However,\nin practice many applications often do not have sufficient image resolutions.\nThe modern face hallucination models demonstrate reasonable performance to\nreconstruct high-resolution images from its corresponding low resolution\nimages. However, they do not consider identity level information during\nhallucination which directly affects results of the recognition of low\nresolution faces. To address this issue, we propose a Face Hallucination\nGenerative Adversarial Network (FH-GAN) which improves the quality of low\nresolution face images and accurately recognize those low quality images.\nConcretely, we make the following contributions: 1) we propose FH-GAN network,\nan end-to-end system, that improves both face hallucination and face\nrecognition simultaneously. The novelty of this proposed network depends on\nincorporating identity information in a GAN-based face hallucination algorithm\nvia combining a face recognition network for identity preserving. 2) We also\npropose a new face hallucination network, namely Dense Sparse Network (DSNet),\nwhich improves upon the state-of-art in face hallucination. 3) We demonstrate\nbenefits of training the face recognition and GAN-based DSNet jointly by\nreporting good result on face hallucination and recognition.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 1124973,
    "score": 34.753475189208984,
    "userScore": 1
  },
  {
    "title": "Face Hallucination via Split-Attention in Split-Attention Network",
    "paperAbstract": "  Recently, convolutional neural networks (CNNs) have been widely employed to\npromote the face hallucination due to the ability to predict high-frequency\ndetails from a large number of samples. However, most of them fail to take into\naccount the overall facial profile and fine texture details simultaneously,\nresulting in reduced naturalness and fidelity of the reconstructed face, and\nfurther impairing the performance of downstream tasks (e.g., face detection,\nfacial recognition). To tackle this issue, we propose a novel external-internal\nsplit attention group (ESAG), which encompasses two paths responsible for\nfacial structure information and facial texture details, respectively. By\nfusing the features from these two paths, the consistency of facial structure\nand the fidelity of facial details are strengthened at the same time. Then, we\npropose a split-attention in split-attention network (SISN) to reconstruct\nphotorealistic high-resolution facial images by cascading several ESAGs.\nExperimental results on face hallucination and face recognition unveil that the\nproposed method not only significantly improves the clarity of hallucinated\nfaces, but also encourages the subsequent face recognition performance\nsubstantially. Codes have been released at\nhttps://github.com/mdswyz/SISN-Face-Hallucination.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 1367905,
    "score": 33.24884796142578,
    "userScore": 1
  },
  {
    "title": "Deep Cascaded Bi-Network for Face Hallucination",
    "paperAbstract": "  We present a novel framework for hallucinating faces of unconstrained poses\nand with very low resolution (face size as small as 5pxIOD). In contrast to\nexisting studies that mostly ignore or assume pre-aligned face spatial\nconfiguration (e.g. facial landmarks localization or dense correspondence\nfield), we alternatingly optimize two complementary tasks, namely face\nhallucination and dense correspondence field estimation, in a unified\nframework. In addition, we propose a new gated deep bi-network that contains\ntwo functionality-specialized branches to recover different levels of texture\ndetails. Extensive experiments demonstrate that such formulation allows\nexceptional hallucination quality on in-the-wild low-res faces with significant\npose and illumination variations.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 752597,
    "score": 32.63714599609375,
    "userScore": 1
  },
  {
    "title": "DeepTIO: A Deep Thermal-Inertial Odometry with Visual Hallucination",
    "paperAbstract": "  Visual odometry shows excellent performance in a wide range of environments.\nHowever, in visually-denied scenarios (e.g. heavy smoke or darkness), pose\nestimates degrade or even fail. Thermal cameras are commonly used for\nperception and inspection when the environment has low visibility. However,\ntheir use in odometry estimation is hampered by the lack of robust visual\nfeatures. In part, this is as a result of the sensor measuring the ambient\ntemperature profile rather than scene appearance and geometry. To overcome this\nissue, we propose a Deep Neural Network model for thermal-inertial odometry\n(DeepTIO) by incorporating a visual hallucination network to provide the\nthermal network with complementary information. The hallucination network is\ntaught to predict fake visual features from thermal images by using Huber loss.\nWe also employ selective fusion to attentively fuse the features from three\ndifferent modalities, i.e thermal, hallucination, and inertial features.\nExtensive experiments are performed in hand-held and mobile robot data in\nbenign and smoke-filled environments, showing the efficacy of the proposed\nmodel.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 1177269,
    "score": 32.2249755859375,
    "userScore": 1
  },
  {
    "title": "Self-Enhanced Convolutional Network for Facial Video Hallucination",
    "paperAbstract": "  As a domain-specific super-resolution problem, facial image hallucination has\nenjoyed a series of breakthroughs thanks to the advances of deep convolutional\nneural networks. However, the direct migration of existing methods to video is\nstill difficult to achieve good performance due to its lack of alignment and\nconsistency modelling in temporal domain. Taking advantage of high inter-frame\ndependency in videos, we propose a self-enhanced convolutional network for\nfacial video hallucination. It is implemented by making full usage of preceding\nsuper-resolved frames and a temporal window of adjacent low-resolution frames.\nSpecifically, the algorithm first obtains the initial high-resolution inference\nof each frame by taking into consideration a sequence of consecutive\nlow-resolution inputs through temporal consistency modelling. It further\nrecurrently exploits the reconstructed results and intermediate features of a\nsequence of preceding frames to improve the initial super-resolution of the\ncurrent frame by modelling the coherence of structural facial features across\nframes. Quantitative and qualitative evaluations demonstrate the superiority of\nthe proposed algorithm against state-of-the-art methods. Moreover, our\nalgorithm also achieves excellent performance in the task of general video\nsuper-resolution in a single-shot setting.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 1209730,
    "score": 32.06781005859375,
    "userScore": 1
  },
  {
    "title": "Deep Joint Face Hallucination and Recognition",
    "paperAbstract": "  Deep models have achieved impressive performance for face hallucination\ntasks. However, we observe that directly feeding the hallucinated facial images\ninto recog- nition models can even degrade the recognition performance despite\nthe much better visualization quality. In this paper, we address this problem\nby jointly learning a deep model for two tasks, i.e. face hallucination and\nrecognition. In particular, we design an end-to-end deep convolution network\nwith hallucination sub-network cascaded by recognition sub-network. The\nrecognition sub- network are responsible for producing discriminative feature\nrepresentations using the hallucinated images as inputs generated by\nhallucination sub-network. During training, we feed LR facial images into the\nnetwork and optimize the parameters by minimizing two loss items, i.e. 1) face\nhallucination loss measured by the pixel wise difference between the ground\ntruth HR images and network-generated images; and 2) verification loss which is\nmeasured by the classification error and intra-class distance. We extensively\nevaluate our method on LFW and YTF datasets. The experimental results show that\nour method can achieve recognition accuracy 97.95% on 4x down-sampled LFW\ntesting set, outperforming the accuracy 96.35% of conventional face recognition\nmodel. And on the more challenging YTF dataset, we achieve recognition accuracy\n90.65%, a margin over the recognition accuracy 89.45% obtained by conventional\nface recognition model on the 4x down-sampled version.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 793538,
    "score": 31.822689056396484,
    "userScore": 1
  },
  {
    "title": "Frequency Aware Face Hallucination Generative Adversarial Network with\n  Semantic Structural Constraint",
    "paperAbstract": "  In this paper, we address the issue of face hallucination. Most current face\nhallucination methods rely on two-dimensional facial priors to generate high\nresolution face images from low resolution face images. These methods are only\ncapable of assimilating global information into the generated image. Still\nthere exist some inherent problems in these methods; such as, local features,\nsubtle structural details and missing depth information in final output image.\nPresent work proposes a Generative Adversarial Network (GAN) based novel\nprogressive Face Hallucination (FH) network to address these issues present\namong current methods. The generator of the proposed model comprises of FH\nnetwork and two sub-networks, assisting FH network to generate high resolution\nimages. The first sub-network leverages on explicitly adding high frequency\ncomponents into the model. To explicitly encode the high frequency components,\nan auto encoder is proposed to generate high resolution coefficients of\nDiscrete Cosine Transform (DCT). To add three dimensional parametric\ninformation into the network, second sub-network is proposed. This network uses\na shape model of 3D Morphable Models (3DMM) to add structural constraint to the\nFH network. Extensive experimentation results in the paper shows that the\nproposed model outperforms the state-of-the-art methods.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 1540023,
    "score": 31.604690551757812,
    "userScore": 1
  },
  {
    "title": "On Hallucination and Predictive Uncertainty in Conditional Language\n  Generation",
    "paperAbstract": "  Despite improvements in performances on different natural language generation\ntasks, deep neural models are prone to hallucinating facts that are incorrect\nor nonexistent. Different hypotheses are proposed and examined separately for\ndifferent tasks, but no systematic explanations are available across these\ntasks. In this study, we draw connections between hallucinations and predictive\nuncertainty in conditional language generation. We investigate their\nrelationship in both image captioning and data-to-text generation and propose a\nsimple extension to beam search to reduce hallucination. Our analysis shows\nthat higher predictive uncertainty corresponds to a higher chance of\nhallucination. Epistemic uncertainty is more indicative of hallucination than\naleatoric or total uncertainties. It helps to achieve better results of trading\nperformance in standard metric for less hallucination with the proposed beam\nsearch variant.\n",
    "query": "neural network hallucination prevention and mitigation",
    "docId": 1445170,
    "score": 30.817333221435547,
    "userScore": 3
  },
  {
    "title": "Comparative Study of the Performance of Quantum Annealing and Simulated\n  Annealing",
    "paperAbstract": "  Relations of simulated annealing and quantum annealing are studied by a\nmapping from the transition matrix of classical Markovian dynamics of the Ising\nmodel to a quantum Hamiltonian and vice versa. It is shown that these two\noperators, the transition matrix and the Hamiltonian, share the eigenvalue\nspectrum. Thus, if simulated annealing with slow temperature change does not\nencounter a difficulty caused by an exponentially long relaxation time at a\nfirst-order phase transition, the same is true for the corresponding process of\nquantum annealing in the adiabatic limit. One of the important differences\nbetween the classical-to-quantum mapping and the converse quantum-to-classical\nmapping is that the Markovian dynamics of a short-range Ising model is mapped\nto a short-range quantum system, but the converse mapping from a short-range\nquantum system to a classical one results in long-range interactions. This\nleads to a difference in efficiencies that simulated annealing can be\nefficiently simulated by quantum annealing but the converse is not necessarily\ntrue. We conclude that quantum annealing is easier to implement and is more\nflexible than simulated annealing. We also point out that the present mapping\ncan be extended to accommodate explicit time dependence of temperature, which\nis used to justify the quantum-mechanical analysis of simulated annealing by\nSomma, Batista, and Ortiz. Additionally, an alternative method to solve the\nnon-equilibrium dynamics of the one-dimensional Ising model is provided through\nthe classical-to-quantum mapping.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 558811,
    "score": 36.87566375732422,
    "userScore": 2
  },
  {
    "title": "Performance of two different quantum annealing correction codes",
    "paperAbstract": "  Quantum annealing is a promising approach for solving optimization problems,\nbut like all other quantum information processing methods, it requires error\ncorrection to ensure scalability. In this work we experimentally compare two\nquantum annealing correction codes in the setting of antiferromagnetic chains,\nusing two different quantum annealing processors. The lower temperature\nprocessor gives rise to higher success probabilities. The two codes differ in a\nnumber of interesting and important ways, but both require four physical qubits\nper encoded qubit. We find significant performance differences, which we\nexplain in terms of the effective energy boost provided by the respective\nredundantly encoded logical operators of the two codes. The code with the\nhigher energy boost results in improved performance, at the expense of a lower\ndegree encoded graph. Therefore, we find that there exists an important\ntradeoff between encoded connectivity and performance for quantum annealing\ncorrection codes.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 649441,
    "score": 34.817108154296875,
    "userScore": 2
  },
  {
    "title": "Statistical Analysis of Quantum Annealing",
    "paperAbstract": "  Quantum computers use quantum resources to carry out computational tasks and\nmay outperform classical computers in solving certain computational problems.\nSpecial-purpose quantum computers such as quantum annealers employ quantum\nadiabatic theorem to solve combinatorial optimization problems. In this paper,\nwe compare classical annealings such as simulated annealing and quantum\nannealings that are done by the D-Wave machines both theoretically and\nnumerically. We show that if the classical and quantum annealing are\ncharacterized by equivalent Ising models, then solving an optimization problem,\ni.e., finding the minimal energy of each Ising model, by the two annealing\nprocedures, are mathematically identical. For quantum annealing, we also derive\nthe probability lower-bound on successfully solving an optimization problem by\nmeasuring the system at the end of the annealing procedure. Moreover, we\npresent the Markov chain Monte Carlo (MCMC) method to realize quantum annealing\nby classical computers and investigate its statistical properties. In the\nnumerical section, we discuss the discrepancies between the MCMC based\nannealing approaches and the quantum annealing approach in solving optimization\nproblems.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 1410596,
    "score": 33.82627487182617,
    "userScore": 2
  },
  {
    "title": "Assessing the performance of quantum annealing with nonlinear driving",
    "paperAbstract": "  Current generation quantum annealers have already proven to be successful\nproblem-solvers. Yet, quantum annealing is still very much in its infancy, with\nsuboptimal applicability. For instance, to date it is still an open question\nwhich annealing protocol causes the fewest diabatic excitations for a given\neigenspectrum, and even whether there is a universally optimal strategy.\nTherefore, in this paper, we report analytical and numerical studies of the\ndiabatic excitations arising from nonlinear protocols applied to the transverse\nfield Ising chain, the exactly solvable model that serves as a quantum\nannealing playground. Our analysis focuses on several driving schemes that\ninhibit or facilitate the dynamic phases discussed in a previous work. Rather\nremarkably, we find that the paradigmatic Kibble-Zurek behavior can be\nsuppressed with ``pauses'' in the evolution, both for crossing and for stopping\nat the quantum critical point of the system.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 1629871,
    "score": 33.33528518676758,
    "userScore": 1
  },
  {
    "title": "Optimizing Schedules for Quantum Annealing",
    "paperAbstract": "  Classical and quantum annealing are two heuristic optimization methods that\nsearch for an optimal solution by slowly decreasing thermal or quantum\nfluctuations. Optimizing annealing schedules is important both for performance\nand fair comparisons between classical annealing, quantum annealing, and other\nalgorithms. Here we present a heuristic approach for the optimization of\nannealing schedules for quantum annealing and apply it to 3D Ising spin glass\nproblems. We find that if both classical and quantum annealing schedules are\nsimilarly optimized, classical annealing outperforms quantum annealing for\nthese problems when considering the residual energy obtained in slow annealing.\nHowever, when performing many repetitions of fast annealing, simulated quantum\nannealing is seen to outperform classical annealing for our benchmark problems.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 843961,
    "score": 32.65407943725586,
    "userScore": 1
  },
  {
    "title": "Pulsed quantum annealing",
    "paperAbstract": "  We propose a modified quantum annealing protocol, i. e., pulsed quantum\nannealing} (PQA), in order to increase the success probability by a pulse\napplication during the quantum annealing process. It is well known that the\nsuccess probability of the conventional quantum annealing is reduced due to the\nLandau-Zener transitions. By applying a pulse to the system, we modulate the\nsuccess probability and increase it, compared to the conventional quantum\nannealing, by optimizing the pulse parameters. We demonstrate our findings for\na single qubit both numerically and analytically. The analytical model is based\non the tranfer matrix approach and it is in good agreement with the full\nnumerical results. We also investigate the PQA protocol for multi-qubit cases\n$i. e.,$ random spin-glass instances, and we present an overall increase of the\nsuccess probability over the conventional quantum annealing, by optimizing the\npulse parameters. Our results indicate that PQA can be used to design future\nhigh-performance quantum annealing machines, especially for hard instances that\nthe conventional QA protocol behaves poorly.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 994157,
    "score": 32.02132034301758,
    "userScore": 1
  },
  {
    "title": "Relation between quantum fluctuations and the performance enhancement of\n  quantum annealing in a nonstoquastic Hamiltonian",
    "paperAbstract": "  We study the relation between quantum fluctuations and the significant\nenhancement of the performance of quantum annealing in a mean-field\nHamiltonian. First-order quantum phase transitions were shown to be reduced to\nsecond order by antiferromagnetic transverse interactions in a mean-field-type\nmany-body-interacting Ising spin system in a transverse field, which means an\nexponential speedup of quantum annealing by adiabatic quantum computation. We\ninvestigate if and how quantum effects manifest themselves around these first-\nand second-order phase transitions to understand if the antiferromagnetic\ntransverse interactions appended to the conventional transverse-field Ising\nmodel induce notable quantum effects. By measuring the proximity of the\nsemiclassical spin-coherent state to the true ground state as well as the\nmagnitude of the concurrence representing entanglement, we conclude that\nsignificant quantum fluctuations exist around second-order transitions, whereas\nquantum effects are much less prominent at first-order transitions. Although\nthe location of the transition point can be predicted by the classical picture,\nsystem properties near the transition need quantum-mechanical descriptions for\na second-order transition but not necessarily for first order. It is also found\nthat quantum fluctuations are large within the ferromagnetic phase after a\nsecond-order transition from the paramagnetic phase. These results suggest that\nthe antiferromagnetic transverse interactions induce marked quantum effects,\nand this fact would be related to closely to the significant enhancement of the\nperformance of quantum annealing.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 804074,
    "score": 31.529212951660156,
    "userScore": 1
  },
  {
    "title": "Enhancing Quantum Annealing Performance for the Molecular Similarity\n  Problem",
    "paperAbstract": "  Quantum annealing is a promising technique which leverages quantum mechanics\nto solve hard optimization problems. Considerable progress has been made in the\ndevelopment of a physical quantum annealer, motivating the study of methods to\nenhance the efficiency of such a solver. In this work, we present a quantum\nannealing approach to measure similarity among molecular structures.\nImplementing real-world problems on a quantum annealer is challenging due to\nhardware limitations such as sparse connectivity, intrinsic control error, and\nlimited precision. In order to overcome the limited connectivity, a problem\nmust be reformulated using minor-embedding techniques. Using a real data set,\nwe investigate the performance of a quantum annealer in solving the molecular\nsimilarity problem. We provide experimental evidence that common practices for\nembedding can be replaced by new alternatives which mitigate some of the\nhardware limitations and enhance its performance. Common practices for\nembedding include minimizing either the number of qubits or the chain length,\nand determining the strength of ferromagnetic couplers empirically. We show\nthat current criteria for selecting an embedding do not improve the hardware's\nperformance for the molecular similarity problem. Furthermore, we use a\ntheoretical approach to determine the strength of ferromagnetic couplers. Such\nan approach removes the computational burden of the current empirical\napproaches, and also results in hardware solutions that can benefit from simple\nlocal classical improvement. Although our results are limited to the problems\nconsidered here, they can be generalized to guide future benchmarking studies.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 809841,
    "score": 31.418516159057617,
    "userScore": 3
  },
  {
    "title": "Customized quantum annealing schedules",
    "paperAbstract": "  In a typical quantum annealing protocol, the system starts with a transverse\nfield Hamiltonian which is gradually turned off and replaced by a longitudinal\nIsing Hamiltonian. The ground state of the Ising Hamiltonian encodes the\nsolution to the computational problem of interest, and the state overlap with\nthis ground state gives the success probability of the annealing protocol. The\nform of the annealing schedule can have a significant impact on the ground\nstate overlap at the end of the anneal, so precise control over these annealing\nschedules can be a powerful tool for increasing success probabilities of\nannealing protocols. Here we show how superconducting circuits, in particular\ncapacitively shunted flux qubits (CSFQs), can be used to construct quantum\nannealing systems by providing tools for mapping circuit flux biases to Pauli\ncoefficients. We use this mapping to find customized annealing schedules:\nappropriate circuit control biases that yield a desired annealing schedule,\nwhile accounting for the physical limitations of the circuitry. We then provide\nexamples and proposals that utilize this capability to improve quantum\nannealing performance.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 1436606,
    "score": 30.794635772705078,
    "userScore": 1
  },
  {
    "title": "Quantum annealing",
    "paperAbstract": "  Brief description on the state of the art of some local optimization methods:\nQuantum annealing Quantum annealing (also known as alloy, crystallization or\ntempering) is analogous to simulated annealing but in substitution of thermal\nactivation by quantum tunneling. The class of algorithmic methods for quantum\nannealing (dubbed: 'QA'), sometimes referred by the italian school as Quantum\nStochastic Optimization ('QSO'), is a promising metaheuristic tool for solving\nlocal search problems in multivariable optimization contexts.\n",
    "query": "performance analysis of quantum annealing",
    "docId": 515518,
    "score": 30.782764434814453,
    "userScore": 2
  },
  {
    "title": "Achieving short high-quality gate-all-around structures for horizontal\n  nanowire field-effect transistors",
    "paperAbstract": "  We introduce a fabrication method for gate-all-around nanowire field-effect\ntransistors. Single nanowires were aligned perpendicular to underlying bottom\ngates using a resist-trench alignment technique. Top gates were then defined\naligned to the bottom gates to form gate-all-around structures. This approach\novercomes significant limitations in minimal obtainable gate length and\ngate-length control in previous horizontal wrap-gated nanowire transistors that\narise because the gate is defined by wet etching. In the method presented here\ngate-length control is limited by the resolution of the\nelectron-beam-lithography process. We demonstrate the versatility of our\napproach by fabricating a device with an independent bottom gate, top gate, and\ngate-all-around structure as well as a device with three independent\ngate-all-around structures with 300 nm, 200 nm, and 150 nm gate length. Our\nmethod enables us to achieve sub-threshold swings as low as 38 mV/dec at 77 K\nfor a 150 nm gate length.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 1034546,
    "score": 48.75603485107422,
    "userScore": 3
  },
  {
    "title": "Compact spin qubits using the common gate structure of fin field-effect\n  transistors",
    "paperAbstract": "  The sizes of commercial transistors are of nanometer order, and there have\nalready been many proposals of spin qubits using conventional complementary\nmetal oxide semiconductor (CMOS) transistors. However, the previously proposed\nspin qubits require many wires to control a small number of qubits. This causes\na significant 'jungle of wires' problem when the qubits are integrated into a\nchip. Herein, to reduce the complicated wiring, we theoretically consider spin\nqubits embedded into fin field-effect transistor (FinFET) devices such that the\nspin qubits share the common gate electrode of the FinFET. The interactions\nbetween qubits occur via the Ruderman Kittel Kasuya Yosida (RKKY) interaction\nvia the channel of the FinFET. The compensation for the compact implementation\nrequires high-density current lines in a small space. The possibility of a\nquantum annealing machine is discussed in addition to the quantum computers of\nthe current proposals.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 1346123,
    "score": 43.88735580444336,
    "userScore": 1,
    "inAnnoy": true
  },
  {
    "title": "III-V Gate-all-around Nanowire MOSFET Process Technology: From 3D to 4D",
    "paperAbstract": "  In this paper, we have experimentally demonstrated, for the first time, III-V\n4D transistors with vertically stacked InGaAs nanowire (NW) channels and\ngate-all-around (GAA) architecture. Novel process technology enabling the\ntransition from 3D to 4D structure has been developed and summarized. The\nsuccessful fabrication of InGaAs lateral and vertical NW arrays has led to 4x\nincrease in MOSFET drive current. The top-down technology developed in this\npaper has opened a viable pathway towards future low-power logic and RF\ntransistors with high-density III-V NWs.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 393841,
    "score": 37.81746292114258,
    "userScore": 2
  },
  {
    "title": "Field Effect Transistors on Rubrene Single Crystals with Parylene Gate\n  Insulator",
    "paperAbstract": "  We report on fabrication and characterization of the organic field effect\ntransistors (OFETs) on the surface of single crystals of rubrene. The parylene\npolymer film has been used as the gate insulator. At room temperature, these\nOFETs exhibit the p-type conductivity with the field effect mobility up to 1\ncm^2/Vs and the on/off ratio ~ 10^4. The temperature dependence of the mobility\nis discussed.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 1913630,
    "score": 36.60612869262695,
    "userScore": 1
  },
  {
    "title": "The Difficulty of Gate Control in Molecular Transistors",
    "paperAbstract": "  The electrostatic gating effects on molecular transistors are investigated\nusing the density functional theory (DFT) combined with the nonequilibrium\nGreen's function (NEGF) method. When molecular energy levels are away from the\nFermi energy they can be linearly shifted by the gate voltage, which is\nconsistent with recent experimental observations [Nature 462, 1039 (2009)].\nHowever, when they move near to the Fermi energy (turn-on process), the shifts\nbecome extremely small and almost independent of the gate voltage. The fact\nthat the conductance may be beyond the gate control in the \"ON\" state will\nchallenge the implementation of molecular transistors.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 290308,
    "score": 36.54043960571289,
    "userScore": 1
  },
  {
    "title": "Laser written junctionless dual in-plane-gate thin-film transistors with\n  AND Logic function",
    "paperAbstract": "  A simple laser scribing process has been developed to fabricate low-voltage\njunctionless in-plane-gate thin-film transistors (TFTs) arrays without any mask\nand photolithography. Such junctionless TFTs feature that the channel and the\nsource/drain electrodes are of the same indium-tin-oxide films without any\nintentional source/drain junction deposition process. Effective field-effect\nmodulation of the drain current has been realized on such in-plane-gate device\nwith a field-effect mobility of ~12.6cm2/Vs. At last, AND gate logic function\nwas demonstrated on dual in-plane-gate device.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 334574,
    "score": 36.12542724609375,
    "userScore": 1
  },
  {
    "title": "Comparison of Josephson vortex flow transistors with different gate line\n  configurations",
    "paperAbstract": "  We performed numerical simulations and experiments on Josephson vortex flow\ntransistors based on parallel arrays of YBa2Cu3O(7-x) grain boundary junctions\nwith a cross gate-line allowing to operate the same devices in two different\nmodes named Josephson fluxon transistor (JFT) and Josephson fluxon-antifluxon\ntransistor (JFAT). The simulations yield a general expression for the current\ngain vs. number of junctions and normalized loop inductance and predict higher\ncurrent gain for the JFAT. The experiments are in good agreement with\nsimulations and show improved coupling between gate line and junctions for the\nJFAT as compared to the JFT.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 1900543,
    "score": 35.910003662109375,
    "userScore": 1
  },
  {
    "title": "Phosphorus oxide gate dielectric for black phosphorus field effect\n  transistors",
    "paperAbstract": "  The environmental stability of the layered semiconductor black phosphorus\n(bP) remains a challenge. Passivation of the bP surface with phosphorus oxide,\nPOx, grown by a reactive ion etch with oxygen plasma is known to improve\nphotoluminescence efficiency of exfoliated bP flakes. We apply phosphorus oxide\npassivation in the fabrication of bP field effect transistors using a gate\nstack consisting of a POx layer grown by reactive ion etching followed by\natomic layer deposition of Al2O3. We observe room temperature top-gate\nmobilities of 115 cm2/Vs in ambient conditions, which we attribute to the low\ndefect density of the bP/POx interface.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 965332,
    "score": 35.55320739746094,
    "userScore": 2
  },
  {
    "title": "InAs nanowire transistors with multiple, independent wrap-gate segments",
    "paperAbstract": "  We report a method for making horizontal wrap-gate nanowire transistors with\nup to four independently controllable wrap-gated segments. While the step up to\ntwo independent wrap-gates requires a major change in fabrication methodology,\na key advantage to this new approach, and the horizontal orientation more\ngenerally, is that achieving more than two wrap-gate segments then requires no\nextra fabrication steps. This is in contrast to the vertical orientation, where\na significant subset of the fabrication steps needs to be repeated for each\nadditional gate. We show that cross-talk between adjacent wrap-gate segments is\nnegligible despite separations less than 200 nm. We also demonstrate the\nability to make multiple wrap-gate transistors on a single nanowire using the\nexact same process. The excellent scalability potential of horizontal wrap-gate\nnanowire transistors makes them highly favourable for the development of\nadvanced nanowire devices and possible integration with vertical wrap-gate\nnanowire transistors in 3D nanowire network architectures.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 621961,
    "score": 35.54045104980469,
    "userScore": 1
  },
  {
    "title": "Using ultra-thin parylene films as an organic gate insulator in nanowire\n  field-effect transistors",
    "paperAbstract": "  We report the development of nanowire field-effect transistors featuring an\nultra-thin parylene film as a polymer gate insulator. The room temperature,\ngas-phase deposition of parylene is an attractive alternative to oxide\ninsulators prepared at high temperatures using atomic layer deposition. We\ndiscuss our custom-built parylene deposition system, which is designed for\nreliable and controlled deposition of <100 nm thick parylene films on III-V\nnanowires standing vertically on a growth substrate or horizontally on a device\nsubstrate. The former case gives conformally-coated nanowires, which we used to\nproduce functional $\\Omega$-gate and gate-all-around structures. These give\nsub-threshold swings as low as 140 mV/dec and on/off ratios exceeding $10^3$ at\nroom temperature. For the gate-all-around structure, we developed a novel\nfabrication strategy that overcomes some of the limitations with previous\nlateral wrap-gate nanowire transistors. Finally, we show that parylene can be\ndeposited over chemically-treated nanowire surfaces; a feature generally not\npossible with oxides produced by atomic layer deposition due to the surface\n`self-cleaning' effect. Our results highlight the potential for parylene as an\nalternative ultra-thin insulator in nanoscale electronic devices more broadly,\nwith potential applications extending into nanobioelectronics due to parylene's\nwell-established biocompatible properties.\n",
    "query": "gate all around transistors  vs FinFET",
    "docId": 1030487,
    "score": 35.3173828125,
    "userScore": 1
  },
  {
    "title": "On modular forms for some noncongruence arithmetic subgroups",
    "paperAbstract": "  In this paper, we consider modular forms for finite index subgroups of the\nmodular group whose Fourier coefficients are algebraic. It is well-known that\nthe Fourier coefficients of any holomorphic modular form for a congruence\nsubgroup (with algebraic coefficients) have bounded denominators. It was\nobserved by Atkin and Swinnerton-Dyer that this is no longer true for modular\nforms for noncongruence subgroups and they pointed out that unbounded\ndenominator property is a clear distinction between modular forms for\nnoncongruence and congruence modular forms. It is an open question whether\ngenuine noncongruence modular forms (with algebraic coefficients) always\nsatisfy the unbounded denominator property. Here, we give a partial positive\nanswer to the above open question by constructing special finite index\nsubgroups of SL_2(Z) called character groups and discuss the properties of\nmodular forms for some groups of this kind.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 2154967,
    "score": 60.38435363769531,
    "userScore": 1
  },
  {
    "title": "Finite index subgroups of the modular group and their modular forms",
    "paperAbstract": "  Classically, congruence subgroups of the modular group, which can be\ndescribed by congruence relations, play important roles in group theory and\nmodular forms. In reality, the majority of finite index subgroups of the\nmodular group are noncongruence. These groups as well as their modular forms\nare central players of this survey article. Differences between congruence and\nnoncongruence subgroups and modular forms will be discussed. We will mainly\nfocus on three interesting aspects of modular forms for noncongruence\nsubgroups: the unbounded denominator property, modularity of the Galois\nrepresentation arising from noncongruence cuspforms, and Atkin and\nSwinnerton-Dyer congruences.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 16485,
    "score": 52.79840850830078,
    "userScore": 2
  },
  {
    "title": "Moduli Interpretations for Noncongruence Modular Curves",
    "paperAbstract": "  We define the notion of a $G$-structure for elliptic curves, where $G$ is a\nfinite 2-generated group. When $G$ is abelian, a $G$-structure is the same as a\nclassical congruence level structure. There is a natural action of\n$\\text{SL}_2(\\mathbb{Z})$ on these level structures. If $\\Gamma$ is a\nstabilizer of this action, then the quotient of the upper half plane by\n$\\Gamma$ parametrizes isomorphism classes of elliptic curves equipped with\n$G$-structures. When $G$ is \"sufficiently\" nonabelian, the stabilizers $\\Gamma$\nare noncongruence. As a result we realize noncongruence modular curves as\nmoduli spaces of elliptic curves equipped with nonabelian $G$-structures. As\napplications we describe links to the Inverse Galois Problem, and show how our\nmoduli interpretations explains the bad primes for the Unbounded Denominators\nConjecture, and allows us to translate the conjecture into the language of\ngeometry and Galois theory.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 669644,
    "score": 51.84303665161133,
    "userScore": 1
  },
  {
    "title": "Atkin and Swinnerton-Dyer congruences and noncongruence modular forms",
    "paperAbstract": "  Atkin and Swinnerton-Dyer congruences are special congruence recursions\nsatisfied by coefficients of noncongruence modular forms. These are in some\nsense $p$-adic analogues of Hecke recursion satisfied by classic Hecke\neigenforms. They actually appeared in different context and sometimes can be\nobtained using the theory of formal groups. In this survey paper, we introduce\nthe Atkin and Swinnerton-Dyer congruences, and discuss some recent progress on\nthis topic.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 417885,
    "score": 51.20709228515625,
    "userScore": 1
  },
  {
    "title": "Congruence and Noncongruence Subgroups of Gamma(2) via Graphs on\n  Surfaces",
    "paperAbstract": "  There is an established bijection between finite-index subgroups Gamma of\nGamma(2) and bipartite graphs on surfaces, or, equivalently, certain triples of\npermutations. We utilize this relationship to study both congruence and\nnoncongruence subgroups in terms of the corresponding graphs. We show some\nelementary criteria which can be used to identify many noncongruence subgroups.\nGiven a graph on a surface, we have a method to produce generators for the\ncorresponding group Gamma in terms of the generators of Gamma(2). Given\ngenerators for Gamma(2n), we show how to determine whether or not a graph of\nlevel 2n corresponds to a congruence subgroup.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 448841,
    "score": 47.168087005615234,
    "userScore": 1
  },
  {
    "title": "The Modular number, Congruence number, and Multiplicity One",
    "paperAbstract": "  Let $N$ be a positive integer and let $f$ be a newform of weight 2 on\n$\\Gamma_0(N)$. In earlier joint work with K. Ribet and W. Stein, we introduced\nthe notions of the modular number and the congruence number of the quotient\nabelian variety $A_f$ of $J_0(N)$ associated to the newform $f$. These\ninvariants are analogs of the notions of the modular degree and congruence\nprimes respectively associated to elliptic curves. We show that if $p$ is a\nprime such that every maximal ideal of the Hecke algebra of characteristic $p$\nthat contains the annihilator ideal of $f$ satisfies multiplicity one, then the\nmodular number and the congruence number have the same $p$-adic valuation.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 90755,
    "score": 47.07740020751953,
    "userScore": 2
  },
  {
    "title": "A Database of Modular Forms on Noncongruence Subgroups",
    "paperAbstract": "  We present a database of several hundred modular forms up to and including\nweight six on noncongruence subgroups of index $\\leq 17$. In addition, our\ndatabase contains expressions for the Belyi map for genus zero subgroups and\nequations of the corresponding elliptic curves for genus one subgroups and\nnumerical approximations of noncongruence Eisenstein series to 1500 digits\nprecision.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 1773199,
    "score": 46.62986755371094,
    "userScore": 2
  },
  {
    "title": "Lifts of projective congruence groups, II",
    "paperAbstract": "  We continue and complete our previous paper `Lifts of projective congruence\ngroups' [2] concerning the question of whether there exist noncongruence\nsubgroups of $\\SL_2(\\Z)$ that are projectively equivalent to one of the groups\n$\\Gamma_0(N)$ or $\\Gamma_1(N)$. A complete answer to this question is obtained:\nIn case of $\\Gamma_0(N)$ such noncongruence subgroups exist precisely if\n$N\\not\\in {3,4,8}$ and we additionally have either that $4\\mid N$ or that $N$\nis divisible by an odd prime congruent to 3 modulo 4. In case of $\\Gamma_1(N)$\nthese noncongruence subgroups exist precisely if $N>4$.\n  As in our previous paper the main motivation for this question is the fact\nthat the above noncongruence subgroups represent a fairly accessible and\nexplicitly constructible reservoir of examples of noncongruence subgroups of\n$\\SL_2(\\Z)$ that can serve as basis for experimentation with modular forms on\nnoncongruence subgroups.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 311805,
    "score": 43.092994689941406,
    "userScore": 1
  },
  {
    "title": "Intertwining operators and vector-valued modular forms for minimal\n  models",
    "paperAbstract": "  Using the language of vertex operator algebras (VOAs) and vector-valued\nmodular forms we study the modular group representations and spaces of 1-point\nfunctions associated to intertwining operators for Virasoro minimal model VOAs.\nWe examine all representations of dimension less than four associated to\nirreducible modules for minimal models, and determine when the kernel of these\nrepresentations is a congruence or noncongruence subgroup of the modular group.\nArithmetic criteria are given on the indexing of the irreducible modules for\nminimal models that imply the associated modular group representation has a\nnoncongruence kernel, independent of the dimension of the representation. The\nalgebraic structure of the spaces of 1-point functions for intertwining\noperators is also studied, via a comparison with the associated spaces of\nholomorphic vector-valued modular forms.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 797943,
    "score": 42.731346130371094,
    "userScore": 1
  },
  {
    "title": "Potentially $\\text{GL}_2$-type Galois representations associated to\n  noncongruence modular forms",
    "paperAbstract": "  In this paper, we consider Galois representations of the absolute Galois\ngroup $\\text{Gal}(\\overline {\\mathbb Q}/\\mathbb Q)$ attached to modular forms\nfor noncongruence subgroups of $\\text{SL}_2(\\mathbb Z)$. When the underlying\nmodular curves have a model over $\\mathbb Q$, these representations are\nconstructed by Scholl and are referred to as Scholl representations, which form\na large class of motivic Galois representations. In particular, by a result of\nBelyi, Scholl representations include the Galois actions on the Jacobian\nvarieties of algebraic curves defined over $\\mathbb Q$. As Scholl\nrepresentations are motivic, they are expected to correspond to automorphic\nrepresentations according to the Langlands philosophy. Using recent\ndevelopments in the automorphy lifting theorem, we obtain various automphy and\npotential automorphy results for potentially $\\text{GL}_2$-type Galois\nrepresentations associated to noncongruence modular forms. Our results are\napplied to various kinds of examples. Especially, we obtain potential\nautomorphy results for Galois representations attached to an infinite family of\nspaces of weight 3 noncongruence cusp forms of arbitrarily large dimensions.\n",
    "query": "number theory modular form functions noncongruence  and congruence",
    "docId": 771892,
    "score": 42.696006774902344,
    "userScore": 2
  },
  {
    "title": "Intransitive dice tournament is not quasirandom",
    "paperAbstract": "  We settle a version of the conjecture about intransitive dice posed by\nConrey, Gabbard, Grant, Liu and Morrison in 2016 and Polymath in 2017. We\nconsider generalized dice with $n$ faces and we say that a die $A$ beats $B$ if\na random face of $A$ is more likely to show a higher number than a random face\nof $B$. We study random dice with faces drawn iid from the uniform distribution\non $[0,1]$ and conditioned on the sum of the faces equal to $n/2$. Considering\nthe \"beats\" relation for three such random dice, Polymath showed that each of\neight possible tournaments between them is asymptotically equally likely. In\nparticular, three dice form an intransitive cycle with probability converging\nto $1/4$. In this paper we prove that for four random dice not all tournaments\nare equally likely and the probability of a transitive tournament is strictly\nhigher than $3/8$.\n",
    "query": "intransitive dice rolling",
    "docId": 1382815,
    "score": 53.313316345214844,
    "userScore": 3
  },
  {
    "title": "Quantum dice rolling",
    "paperAbstract": "  A coin is just a two sided dice. Recently, Mochon proved that quantum weak\ncoin flipping with an arbitrarily small bias is possible. However, the use of\nquantum resources to allow N remote distrustful parties to roll an N-sided dice\nhas yet to be addressed. In this paper we show that contrary to the classical\ncase, N-sided dice rolling with arbitrarily small bias is possible for any N.\nIn addition, we present a six-round three-sided dice rolling protocol,\nachieving a bias of 0.181, which incorporates weak imbalanced coin flipping.\n",
    "query": "intransitive dice rolling",
    "docId": 139453,
    "score": 48.18231964111328,
    "userScore": 2
  },
  {
    "title": "Generalized Intransitive Dice: Mimicking an Arbitrary Tournament",
    "paperAbstract": "  A generalized $N$-sided die is a random variable $D$ on a sample space of $N$\nequally likely outcomes taking values in the set of positive integers. We say\nof independent $N$ sided dice $D_i, D_j$ that $D_i$ beats $D_j$, written $D_i\n\\to D_j$, if $Prob(D_i > D_j) > \\frac{1}{2} $. Examples are known of\nintransitive $6$-sided dice, i.e. $D_1 \\to D_2 \\to D_3$ but $D_3 \\to D_1$. A\ntournament of size $n$ is a choice of direction $i \\to j$ for each edge of the\ncomplete graph on $n$ vertices. We show that if $R$ is tournament on the set\n$\\{ 1, \\dots, n \\}$, then for sufficiently large $N$ there exist sets of\nindependent $N$-sided dice $\\{ D_1, \\dots, D_n \\}$ such that $D_i \\to D_j$ if\nand only if $i \\to j$ in $R$.\n",
    "query": "intransitive dice rolling",
    "docId": 1079024,
    "score": 45.287574768066406,
    "userScore": 3
  },
  {
    "title": "Quantum dice rolling: A multi-outcome generalization of quantum coin\n  flipping",
    "paperAbstract": "  We generalize the problem of coin flipping to more than two outcomes and\nparties. We term this problem dice rolling, and study both its weak and strong\nvariants. We prove by construction that in quantum settings (i) weak N-sided\ndice rolling admits an arbitrarily small bias for any value of N, and (ii)\ntwo-party strong N-sided dice rolling saturates the corresponding\ngeneralization of Kitaev's bound for any value of N. In addition, we make use\nof this last result to introduce a family of optimal 2m-party strong n^m-sided\ndice rolling protocols for any value of m and n.\n",
    "query": "intransitive dice rolling",
    "docId": 146554,
    "score": 42.49930191040039,
    "userScore": 2
  },
  {
    "title": "Intransitive Dice",
    "paperAbstract": "  We consider $n$-sided dice whose face values lie between $1$ and $n$ and\nwhose faces sum to $n(n+1)/2$. For two dice $A$ and $B$, define $A \\succ B$ if\nit is more likely for $A$ to show a higher face than $B$. Suppose $k$ such dice\n$A_1,\\dots,A_k$ are randomly selected. We conjecture that the probability of\nties goes to 0 as $n$ grows. We conjecture and provide some supporting evidence\nthat---contrary to intuition---each of the $2^{k \\choose 2}$ assignments of\n$\\succ$ or $\\prec$ to each pair is equally likely asymptotically. For a\nspecific example, suppose we randomly select $k$ dice $A_1,\\dots,A_k$ and\nobserve that $A_1 \\succ A_2 \\succ \\ldots \\succ A_k$. Then our conjecture\nasserts that the outcomes $A_k \\succ A_1$ and $A_1 \\prec A_k$ both have\nprobability approaching $1/2$ as $n \\rightarrow \\infty$.\n",
    "query": "intransitive dice rolling",
    "docId": 480172,
    "score": 41.99245071411133,
    "userScore": 3
  },
  {
    "title": "Emerging Diversity in a Population of Evolving Intransitive Dice",
    "paperAbstract": "  Exploiting the mathematical curiosity of intransitive dice, we present a\nsimple theoretical model for co-evolution that captures scales ranging from the\ngenome of the individual to the system-wide emergence of species diversity. We\nstudy a set of evolving agents that interact competitively in a closed system,\nin which both the dynamics of mutations and competitive advantage emerge\ndirectly from interpreting a genome as the sides of a die. The model\ndemonstrates sympatric speciation where new species evolve from existing ones\nwhile in contact with the entire ecosystem. Allowing free mutations both in the\ngenomes and the mutation rates, we find, in contrast to hierarchical models of\nfitness, the emergence of a metastable state of finite mutation rate and\ndiversity.\n",
    "query": "intransitive dice rolling",
    "docId": 1756551,
    "score": 41.93225860595703,
    "userScore": 2
  },
  {
    "title": "Intransitive Machines",
    "paperAbstract": "  The intransitive cycle of superiority is characterized by such binary\nrelations between A, B, and C that A is superior to B, B is superior to C, and\nC is superior to A (i.e., A>B>C>A - in contrast with transitive relations\nA>B>C). The first part of the article presents a brief review of studies of\nintransitive cycles in various disciplines (mathematics, biology, sociology,\nlogical games, decision theory, etc.), and their reflections in educational\nmaterials. The second part of the article introduces the issue of\nintransitivity in elementary physics. We present principles of building\nmechanical intransitive devices in correspondence with the structure of the\nCondorcet paradox, and describe five intransitive devices: intransitive gears;\nlevers; pulleys, wheels, and axles; wedges; inclined planes. Each of the\nmechanisms are constructed as compositions of simple machines and show\nparadoxical intransitivity of relations such as \"to rotate faster than\", \"to\nlift\", \"to be stronger than\" in some geometrical constructions. The article is\nan invitation to develop teaching materials and problems advancing the\nunderstanding of transitivity and intransitivity in various areas, including\nphysics education.\n",
    "query": "intransitive dice rolling",
    "docId": 1023885,
    "score": 33.8375244140625,
    "userScore": 2
  },
  {
    "title": "Generalized Intransitive Dice II: Partition Constructions",
    "paperAbstract": "  A generalized $N$-sided die is a random variable $D$ on a sample space of $N$\nequally likely outcomes taking values in the set of positive integers. We say\nof independent $N$ sided dice $D_i, D_j$ that $D_i$ beats $D_j$, written $D_i\n\\to D_j$, if $Prob(D_i > D_j) > \\frac{1}{2} $. A collection of dice $\\{ D_i : i\n= 1, \\dots, n \\}$ models a tournament on the set $[n] = \\{ 1, 2, \\dots, n \\}$,\ni.e. a complete digraph with $n$ vertices, when $D_i \\to D_j$ if and only if $i\n\\to j$ in the tournament. By using $n$-fold partitions of the set $[Nn] $ with\neach set of size $N$ we can model an arbitrary tournament on $[n]$. A bound on\nthe required size of $N$ is obtained by examples with $N = 3^{n-2}$.\n",
    "query": "intransitive dice rolling",
    "docId": 1120186,
    "score": 33.33968734741211,
    "userScore": 2
  },
  {
    "title": "Quantum dice",
    "paperAbstract": "  In a letter to Born, Einstein wrote: \"Quantum mechanics is certainly\nimposing. But an inner voice tells me that it is not yet the real thing. The\ntheory says a lot, but does not really bring us any closer to the secret of the\nold one. I, at any rate, am convinced that He does not throw dice.\" In this\npaper we take seriously Einstein's famous metaphor, and show that we can gain\nconsiderable insight into quantum mechanics by doing something as simple as\nrolling dice. More precisely, we show how to perform measurements on a single\ndie, to create typical quantum interference effects, and how to connect\n(entangle) two identical dice, to maximally violate Bell's inequality.\n",
    "query": "intransitive dice rolling",
    "docId": 399628,
    "score": 33.24567413330078,
    "userScore": 2
  },
  {
    "title": "How a Losing Team like the Canadiens can Steal a Stanley Cup: A\n  Quantitative Intransitive Hockey Analysis",
    "paperAbstract": "  We present here a simple mathematical model that provides a successful\nstrategy, quantitatively, to ending the continued championship futility\nexperienced by Canadian Hockey Teams. Competitive Intransitivity is used here\nas a simple predictive framework to capture how investing strategically, under\na uniform salary cap, in just 3 independently variable aspects of the sport\n(such as Offence, Defence, and a Goaltender), by just 3 Hockey Teams applying\ndiffering salary priorities (such as Montreal, Boston, and New York), can lead\nto rich and perhaps surprisingly unexpected outcomes in play, similar to\nrolling intransitive dice together in a series of head-to-head games. A\npossibly fortunate conclusion of this analysis is the prediction that for any\nTeam's chosen strategy (such as New York's), a counter strategy within the same\nsalary cap can be adopted by a playoff opponent (such as Montreal) which will\nprove victorious over a long playoff series, enabling a pathway to end\nprolonged championship futility.\n",
    "query": "intransitive dice rolling",
    "docId": 1476031,
    "score": 32.95924758911133,
    "userScore": 1
  },
  {
    "title": "A Survey of the Usages of Deep Learning in Natural Language Processing",
    "paperAbstract": "  Over the last several years, the field of natural language processing has\nbeen propelled forward by an explosion in the use of deep learning models. This\nsurvey provides a brief introduction to the field and a quick overview of deep\nlearning architectures and methods. It then sifts through the plethora of\nrecent studies and summarizes a large assortment of relevant contributions.\nAnalyzed research areas include several core linguistic processing issues in\naddition to a number of applications of computational linguistics. A discussion\nof the current state of the art is then provided along with recommendations for\nfuture research in the field.\n",
    "query": "natural language processing and deep learning",
    "docId": 1008060,
    "score": 50.34075927734375,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "Recent Trends in Deep Learning Based Natural Language Processing",
    "paperAbstract": "  Deep learning methods employ multiple processing layers to learn hierarchical\nrepresentations of data and have produced state-of-the-art results in many\ndomains. Recently, a variety of model designs and methods have blossomed in the\ncontext of natural language processing (NLP). In this paper, we review\nsignificant deep learning related models and methods that have been employed\nfor numerous NLP tasks and provide a walk-through of their evolution. We also\nsummarize, compare and contrast the various models and put forward a detailed\nunderstanding of the past, present and future of deep learning in NLP.\n",
    "query": "natural language processing and deep learning",
    "docId": 877721,
    "score": 49.63845443725586,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "Natural Language Processing Advancements By Deep Learning: A Survey",
    "paperAbstract": "  Natural Language Processing (NLP) helps empower intelligent machines by\nenhancing a better understanding of the human language for linguistic-based\nhuman-computer communication. Recent developments in computational power and\nthe advent of large amounts of linguistic data have heightened the need and\ndemand for automating semantic analysis using data-driven approaches. The\nutilization of data-driven strategies is pervasive now due to the significant\nimprovements demonstrated through the usage of deep learning methods in areas\nsuch as Computer Vision, Automatic Speech Recognition, and in particular, NLP.\nThis survey categorizes and addresses the different aspects and applications of\nNLP that have benefited from deep learning. It covers core NLP tasks and\napplications and describes how deep learning methods and models advance these\nareas. We further analyze and compare different approaches and state-of-the-art\nmodels.\n",
    "query": "natural language processing and deep learning",
    "docId": 1251555,
    "score": 49.23789978027344,
    "userScore": 3,
    "inAnnoy": true
  },
  {
    "title": "Development of Deep Learning Based Natural Language Processing Model for\n  Turkish",
    "paperAbstract": "  Natural language is one of the most fundamental features that distinguish\npeople from other living things and enable people to communicate each other.\nLanguage is a tool that enables people to express their feelings and thoughts\nand to transfers cultures through generations. Texts and audio are examples of\nnatural language in daily life. In the natural language, many words disappear\nin time, on the other hand new words are derived. Therefore, while the process\nof natural language processing (NLP) is complex even for human, it is difficult\nto process in computer system. The area of linguistics examines how people use\nlanguage. NLP, which requires the collaboration of linguists and computer\nscientists, plays an important role in human computer interaction. Studies in\nNLP have increased with the use of artificial intelligence technologies in the\nfield of linguistics. With the deep learning methods which are one of the\nartificial intelligence study areas, platforms close to natural language are\nbeing developed. Developed platforms for language comprehension, machine\ntranslation and part of speech (POS) tagging benefit from deep learning\nmethods. Recurrent Neural Network (RNN), one of the deep learning\narchitectures, is preferred for processing sequential data such as text or\naudio data. In this study, Turkish POS tagging model has been proposed by using\nBidirectional Long-Short Term Memory (BLSTM) which is an RNN type. The proposed\nPOS tagging model is provided to natural language researchers with a platform\nthat allows them to perform and use their own analysis. In the development\nphase of the platform developed by using BLSTM, the error rate of the POS\ntagger has been reduced by taking feedback with expert opinion.\n",
    "query": "natural language processing and deep learning",
    "docId": 1124135,
    "score": 48.8092041015625,
    "userScore": 2
  },
  {
    "title": "Federated Learning Meets Natural Language Processing: A Survey",
    "paperAbstract": "  Federated Learning aims to learn machine learning models from multiple\ndecentralized edge devices (e.g. mobiles) or servers without sacrificing local\ndata privacy. Recent Natural Language Processing techniques rely on deep\nlearning and large pre-trained language models. However, both big deep neural\nand language models are trained with huge amounts of data which often lies on\nthe server side. Since text data is widely originated from end users, in this\nwork, we look into recent NLP models and techniques which use federated\nlearning as the learning framework. Our survey discusses major challenges in\nfederated natural language processing, including the algorithm challenges,\nsystem challenges as well as the privacy issues. We also provide a critical\nreview of the existing Federated NLP evaluation methods and tools. Finally, we\nhighlight the current research gaps and future directions.\n",
    "query": "natural language processing and deep learning",
    "docId": 1506615,
    "score": 47.627098083496094,
    "userScore": 2
  },
  {
    "title": "Evolution of transfer learning in natural language processing",
    "paperAbstract": "  In this paper, we present a study of the recent advancements which have\nhelped bring Transfer Learning to NLP through the use of semi-supervised\ntraining. We discuss cutting-edge methods and architectures such as BERT, GPT,\nELMo, ULMFit among others. Classically, tasks in natural language processing\nhave been performed through rule-based and statistical methodologies. However,\nowing to the vast nature of natural languages these methods do not generalise\nwell and failed to learn the nuances of language. Thus machine learning\nalgorithms such as Naive Bayes and decision trees coupled with traditional\nmodels such as Bag-of-Words and N-grams were used to usurp this problem.\nEventually, with the advent of advanced recurrent neural network architectures\nsuch as the LSTM, we were able to achieve state-of-the-art performance in\nseveral natural language processing tasks such as text classification and\nmachine translation. We talk about how Transfer Learning has brought about the\nwell-known ImageNet moment for NLP. Several advanced architectures such as the\nTransformer and its variants have allowed practitioners to leverage knowledge\ngained from unrelated task to drastically fasten convergence and provide better\nperformance on the target task. This survey represents an effort at providing a\nsuccinct yet complete understanding of the recent advances in natural language\nprocessing using deep learning in with a special focus on detailing transfer\nlearning and its potential advantages.\n",
    "query": "natural language processing and deep learning",
    "docId": 1191289,
    "score": 47.23075485229492,
    "userScore": 2
  },
  {
    "title": "Knowledge Efficient Deep Learning for Natural Language Processing",
    "paperAbstract": "  Deep learning has become the workhorse for a wide range of natural language\nprocessing applications. But much of the success of deep learning relies on\nannotated examples. Annotation is time-consuming and expensive to produce at\nscale. Here we are interested in methods for reducing the required quantity of\nannotated data -- by making the learning methods more knowledge efficient so as\nto make them more applicable in low annotation (low resource) settings. There\nare various classical approaches to making the models more knowledge efficient\nsuch as multi-task learning, transfer learning, weakly supervised and\nunsupervised learning etc. This thesis focuses on adapting such classical\nmethods to modern deep learning models and algorithms.\n  This thesis describes four works aimed at making machine learning models more\nknowledge efficient. First, we propose a knowledge rich deep learning model\n(KRDL) as a unifying learning framework for incorporating prior knowledge into\ndeep models. In particular, we apply KRDL built on Markov logic networks to\ndenoise weak supervision. Second, we apply a KRDL model to assist the machine\nreading models to find the correct evidence sentences that can support their\ndecision. Third, we investigate the knowledge transfer techniques in\nmultilingual setting, where we proposed a method that can improve pre-trained\nmultilingual BERT based on the bilingual dictionary. Fourth, we present an\nepisodic memory network for language modelling, in which we encode the large\nexternal knowledge for the pre-trained GPT.\n",
    "query": "natural language processing and deep learning",
    "docId": 1340600,
    "score": 46.91511154174805,
    "userScore": 3
  },
  {
    "title": "Deep Learning Based Natural Language Processing for End to End Speech\n  Translation",
    "paperAbstract": "  Deep Learning methods employ multiple processing layers to learn hierarchial\nrepresentations of data. They have already been deployed in a humongous number\nof applications and have produced state-of-the-art results. Recently with the\ngrowth in processing power of computers to be able to do high dimensional\ntensor calculations, Natural Language Processing (NLP) applications have been\ngiven a significant boost in terms of efficiency as well as accuracy. In this\npaper, we will take a look at various signal processing techniques and then\napplication of them to produce a speech-to-text system using Deep Recurrent\nNeural Networks.\n",
    "query": "natural language processing and deep learning",
    "docId": 1013605,
    "score": 46.378082275390625,
    "userScore": 3
  },
  {
    "title": "Deep Natural Language Processing for LinkedIn Search Systems",
    "paperAbstract": "  Many search systems work with large amounts of natural language data, e.g.,\nsearch queries, user profiles and documents, where deep learning based natural\nlanguage processing techniques (deep NLP) can be of great help. In this paper,\nwe introduce a comprehensive study of applying deep NLP techniques to five\nrepresentative tasks in search engines. Through the model design and\nexperiments of the five tasks, readers can find answers to three important\nquestions: (1) When is deep NLP helpful/not helpful in search systems? (2) How\nto address latency challenges? (3) How to ensure model robustness? This work\nbuilds on existing efforts of LinkedIn search, and is tested at scale on a\ncommercial search engine. We believe our experiences can provide useful\ninsights for the industry and research communities.\n",
    "query": "natural language processing and deep learning",
    "docId": 1517067,
    "score": 45.746498107910156,
    "userScore": 2
  },
  {
    "title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural\n  Language Processing",
    "paperAbstract": "  We present GluonCV and GluonNLP, the deep learning toolkits for computer\nvision and natural language processing based on Apache MXNet (incubating).\nThese toolkits provide state-of-the-art pre-trained models, training scripts,\nand training logs, to facilitate rapid prototyping and promote reproducible\nresearch. We also provide modular APIs with flexible building blocks to enable\nefficient customization. Leveraging the MXNet ecosystem, the deep learning\nmodels in GluonCV and GluonNLP can be deployed onto a variety of platforms with\ndifferent programming languages. The Apache 2.0 license has been adopted by\nGluonCV and GluonNLP to allow for software distribution, modification, and\nusage.\n",
    "query": "natural language processing and deep learning",
    "docId": 1148969,
    "score": 45.34199905395508,
    "userScore": 2
  },
  {
    "title": "Mining Rank Data",
    "paperAbstract": "  The problem of frequent pattern mining has been studied quite extensively for\nvarious types of data, including sets, sequences, and graphs. Somewhat\nsurprisingly, another important type of data, namely rank data, has received\nvery little attention in data mining so far. In this paper, we therefore\naddresses the problem of mining rank data, that is, data in the form of\nrankings (total orders) of an underlying set of items. More specifically, two\ntypes of patterns are considered, namely frequent rankings and dependencies\nbetween such rankings in the form of association rules. Algorithms for mining\nfrequent rankings and frequent closed rankings are proposed and tested\nexperimentally, using both synthetic and real data.\n",
    "query": "types of the data mining",
    "docId": 991537,
    "score": 32.8436279296875,
    "userScore": 1
  },
  {
    "title": "Role of Data Mining in E-Payment systems",
    "paperAbstract": "  Data Mining deals extracting hidden knowledge, unexpected pattern and new\nrules from large database. Various customized data mining tools have been\ndeveloped for domain specific applications such as Biomedicine, DNA analysis\nand telecommunication. Trends in data mining include further efforts towards\nthe exploration of new application areas and methods for handling complex data\ntypes, algorithm scalability, constraint based data mining and visualization\nmethods. In this paper we will present domain specific Secure Multiparty\ncomputation technique and applications. Data mining has matured as a field of\nbasic and applied research in computer science in general. In this paper, we\nsurvey some of the recent approaches and architectures where data mining has\nbeen applied in the fields of e-payment systems. In this paper we limit our\ndiscussion to data mining in the context of e-payment systems. We also mention\na few directions for further work in this domain, based on the survey.\n",
    "query": "types of the data mining",
    "docId": 177623,
    "score": 29.382604598999023,
    "userScore": 2
  },
  {
    "title": "Proof Mining with Dependent Types",
    "paperAbstract": "  Several approaches exist to data-mining big corpora of formal proofs. Some of\nthese approaches are based on statistical machine learning, and some -- on\ntheory exploration. However, most are developed for either untyped or\nsimply-typed theorem provers. In this paper, we present a method that combines\nstatistical data mining and theory exploration in order to analyse and automate\nproofs in dependently typed language of Coq.\n",
    "query": "types of the data mining",
    "docId": 848221,
    "score": 29.366649627685547,
    "userScore": 1
  },
  {
    "title": "Scientific Data Mining in Astronomy",
    "paperAbstract": "  We describe the application of data mining algorithms to research problems in\nastronomy. We posit that data mining has always been fundamental to\nastronomical research, since data mining is the basis of evidence-based\ndiscovery, including classification, clustering, and novelty discovery. These\nalgorithms represent a major set of computational tools for discovery in large\ndatabases, which will be increasingly essential in the era of data-intensive\nastronomy. Historical examples of data mining in astronomy are reviewed,\nfollowed by a discussion of one of the largest data-producing projects\nanticipated for the coming decade: the Large Synoptic Survey Telescope (LSST).\nTo facilitate data-driven discoveries in astronomy, we envision a new\ndata-oriented research paradigm for astronomy and astrophysics --\nastroinformatics. Astroinformatics is described as both a research approach and\nan educational imperative for modern data-intensive astronomy. An important\napplication area for large time-domain sky surveys (such as LSST) is the rapid\nidentification, characterization, and classification of real-time sky events\n(including moving objects, photometrically variable objects, and the appearance\nof transients). We describe one possible implementation of a classification\nbroker for such events, which incorporates several astroinformatics techniques:\nuser annotation, semantic tagging, metadata markup, heterogeneous data\nintegration, and distributed data mining. Examples of these types of\ncollaborative classification and discovery approaches within other science\ndisciplines are presented.\n",
    "query": "types of the data mining",
    "docId": 154526,
    "score": 29.08222007751465,
    "userScore": 2
  },
  {
    "title": "Spatio-Temporal Data Mining: A Survey of Problems and Methods",
    "paperAbstract": "  Large volumes of spatio-temporal data are increasingly collected and studied\nin diverse domains including, climate science, social sciences, neuroscience,\nepidemiology, transportation, mobile health, and Earth sciences.\nSpatio-temporal data differs from relational data for which computational\napproaches are developed in the data mining community for multiple decades, in\nthat both spatial and temporal attributes are available in addition to the\nactual measurements/attributes. The presence of these attributes introduces\nadditional challenges that needs to be dealt with. Approaches for mining\nspatio-temporal data have been studied for over a decade in the data mining\ncommunity. In this article we present a broad survey of this relatively young\nfield of spatio-temporal data mining. We discuss different types of\nspatio-temporal data and the relevant data mining questions that arise in the\ncontext of analyzing each of these datasets. Based on the nature of the data\nmining problem studied, we classify literature on spatio-temporal data mining\ninto six major categories: clustering, predictive learning, change detection,\nfrequent pattern mining, anomaly detection, and relationship mining. We discuss\nthe various forms of spatio-temporal data mining problems in each of these\ncategories.\n",
    "query": "types of the data mining",
    "docId": 911720,
    "score": 28.830968856811523,
    "userScore": 3
  },
  {
    "title": "Journey from Data Mining to Web Mining to Big Data",
    "paperAbstract": "  This paper describes the journey of big data starting from data mining to web\nmining to big data. It discusses each of this method in brief and also provides\ntheir applications. It states the importance of mining big data today using\nfast and novel approaches.\n",
    "query": "types of the data mining",
    "docId": 517193,
    "score": 28.60602569580078,
    "userScore": 3
  },
  {
    "title": "Beyond the EULA: Improving consent for data mining",
    "paperAbstract": "  Companies and academic researchers may collect, process, and distribute large\nquantities of personal data without the explicit knowledge or consent of the\nindividuals to whom the data pertains. Existing forms of consent often fail to\nbe appropriately readable and ethical oversight of data mining may not be\nsufficient. This raises the question of whether existing consent instruments\nare sufficient, logistically feasible, or even necessary, for data mining. In\nthis chapter, we review the data collection and mining landscape, including\ncommercial and academic activities, and the relevant data protection concerns,\nto determine the types of consent instruments used. Using three case studies,\nwe use the new paradigm of human-data interaction to examine whether these\nexisting approaches are appropriate. We then introduce an approach to consent\nthat has been empirically demonstrated to improve on the state of the art and\ndeliver meaningful consent. Finally, we propose some best practices for data\ncollectors to ensure their data mining activities do not violate the\nexpectations of the people to whom the data relate.\n",
    "query": "types of the data mining",
    "docId": 813407,
    "score": 28.12188720703125,
    "userScore": 1
  },
  {
    "title": "Multi Relational Data Mining Approaches: A Data Mining Technique",
    "paperAbstract": "  The multi relational data mining approach has developed as an alternative way\nfor handling the structured data such that RDBMS. This will provides the mining\nin multiple tables directly. In MRDM the patterns are available in multiple\ntables (relations) from a relational database. As the data are available over\nthe many tables which will affect the many problems in the practice of the data\nmining. To deal with this problem, one either constructs a single table by\nPropositionalisation, or uses a Multi-Relational Data Mining algorithm. MRDM\napproaches have been successfully applied in the area of bioinformatics. Three\npopular pattern finding techniques classification, clustering and association\nare frequently used in MRDM. Multi relational approach has developed as an\nalternative for analyzing the structured data such as relational database. MRDM\nallowing applying directly in the data mining in multiple tables. To avoid the\nexpensive joining operations and semantic losses we used the MRDM technique.\nThis paper focuses some of the application areas of MRDM and feature directions\nas well as the comparison of ILP, GM, SSDM and MRDM\n",
    "query": "types of the data mining",
    "docId": 386117,
    "score": 27.877614974975586,
    "userScore": 2
  },
  {
    "title": "On Integrating Information Visualization Techniques into Data Mining: A\n  Review",
    "paperAbstract": "  The exploding growth of digital data in the information era and its\nimmeasurable potential value has called for different types of data-driven\ntechniques to exploit its value for further applications. Information\nvisualization and data mining are two research field with such goal. While the\ntwo communities advocates different approaches of problem solving, the vision\nof combining the sophisticated algorithmic techniques from data mining as well\nas the intuitivity and interactivity of information visualization is tempting.\nIn this paper, we attempt to survey recent researches and real world systems\nintegrating the wisdom in two fields towards more effective and efficient data\nanalytics. More specifically, we study the intersection from a data mining\npoint of view, explore how information visualization can be used to complement\nand improve different stages of data mining through established theories for\noptimized visual presentation as well as practical toolsets for rapid\ndevelopment. We organize the survey by identifying three main stages of typical\nprocess of data mining, the preliminary analysis of data, the model\nconstruction, as well as the model evaluation, and study how each stage can\nbenefit from information visualization.\n",
    "query": "types of the data mining",
    "docId": 602916,
    "score": 27.46898651123047,
    "userScore": 2
  },
  {
    "title": "Spatiotemporal Data Mining: A Survey",
    "paperAbstract": "  Spatiotemporal data mining aims to discover interesting, useful but\nnon-trivial patterns in big spatial and spatiotemporal data. They are used in\nvarious application domains such as public safety, ecology, epidemiology, earth\nscience, etc. This problem is challenging because of the high societal cost of\nspurious patterns and exorbitant computational cost. Recent surveys of\nspatiotemporal data mining need update due to rapid growth. In addition, they\ndid not adequately survey parallel techniques for spatiotemporal data mining.\nThis paper provides a more up-to-date survey of spatiotemporal data mining\nmethods. Furthermore, it has a detailed survey of parallel formulations of\nspatiotemporal data mining.\n",
    "query": "types of the data mining",
    "docId": 1673173,
    "score": 27.30633544921875,
    "userScore": 2
  },
  {
    "title": "Firefly Algorithms for Multimodal Optimization",
    "paperAbstract": "  Nature-inspired algorithms are among the most powerful algorithms for\noptimization. This paper intends to provide a detailed description of a new\nFirefly Algorithm (FA) for multimodal optimization applications. We will\ncompare the proposed firefly algorithm with other metaheuristic algorithms such\nas particle swarm optimization (PSO). Simulations and results indicate that the\nproposed firefly algorithm is superior to existing metaheuristic algorithms.\nFinally we will discuss its applications and implications for further research.\n",
    "query": "optimization algorithms",
    "docId": 177273,
    "score": 24.856460571289062,
    "userScore": 2
  },
  {
    "title": "On the Convergence of Bound Optimization Algorithms",
    "paperAbstract": "  Many practitioners who use the EM algorithm complain that it is sometimes\nslow. When does this happen, and what can be done about it? In this paper, we\nstudy the general class of bound optimization algorithms - including\nExpectation-Maximization, Iterative Scaling and CCCP - and their relationship\nto direct optimization algorithms such as gradient-based methods for parameter\nlearning. We derive a general relationship between the updates performed by\nbound optimization methods and those of gradient and second-order methods and\nidentify analytic conditions under which bound optimization algorithms exhibit\nquasi-Newton behavior, and conditions under which they possess poor,\nfirst-order convergence. Based on this analysis, we consider several specific\nalgorithms, interpret and analyze their convergence properties and provide some\nrecipes for preprocessing input to these algorithms to yield faster convergence\nbehavior. We report empirical results supporting our analysis and showing that\nsimple data preprocessing can result in dramatically improved performance of\nbound optimizers in practice.\n",
    "query": "optimization algorithms",
    "docId": 392106,
    "score": 24.146543502807617,
    "userScore": 2
  },
  {
    "title": "A Comparison of Optimization Algorithms for Deep Learning",
    "paperAbstract": "  In recent years, we have witnessed the rise of deep learning. Deep neural\nnetworks have proved their success in many areas. However, the optimization of\nthese networks has become more difficult as neural networks going deeper and\ndatasets becoming bigger. Therefore, more advanced optimization algorithms have\nbeen proposed over the past years. In this study, widely used optimization\nalgorithms for deep learning are examined in detail. To this end, these\nalgorithms called adaptive gradient methods are implemented for both supervised\nand unsupervised tasks. The behaviour of the algorithms during training and\nresults on four image datasets, namely, MNIST, CIFAR-10, Kaggle Flowers and\nLabeled Faces in the Wild are compared by pointing out their differences\nagainst basic optimization algorithms.\n",
    "query": "optimization algorithms",
    "docId": 1325680,
    "score": 23.906850814819336,
    "userScore": 3
  },
  {
    "title": "Convex Optimization: Algorithms and Complexity",
    "paperAbstract": "  This monograph presents the main complexity theorems in convex optimization\nand their corresponding algorithms. Starting from the fundamental theory of\nblack-box optimization, the material progresses towards recent advances in\nstructural optimization and stochastic optimization. Our presentation of\nblack-box optimization, strongly influenced by Nesterov's seminal book and\nNemirovski's lecture notes, includes the analysis of cutting plane methods, as\nwell as (accelerated) gradient descent schemes. We also pay special attention\nto non-Euclidean settings (relevant algorithms include Frank-Wolfe, mirror\ndescent, and dual averaging) and discuss their relevance in machine learning.\nWe provide a gentle introduction to structural optimization with FISTA (to\noptimize a sum of a smooth and a simple non-smooth term), saddle-point mirror\nprox (Nemirovski's alternative to Nesterov's smoothing), and a concise\ndescription of interior point methods. In stochastic optimization we discuss\nstochastic gradient descent, mini-batches, random coordinate descent, and\nsublinear algorithms. We also briefly touch upon convex relaxation of\ncombinatorial problems and the use of randomness to round solutions, as well as\nrandom walks based methods.\n",
    "query": "optimization algorithms",
    "docId": 525888,
    "score": 23.903980255126953,
    "userScore": 2
  },
  {
    "title": "Algorithms for Weighted Boolean Optimization",
    "paperAbstract": "  The Pseudo-Boolean Optimization (PBO) and Maximum Satisfiability (MaxSAT)\nproblems are natural optimization extensions of Boolean Satisfiability (SAT).\n  In the recent past, different algorithms have been proposed for PBO and for\nMaxSAT, despite the existence of straightforward mappings from PBO to MaxSAT\nand vice-versa. This papers proposes Weighted Boolean Optimization (WBO), a new\nunified framework that aggregates and extends PBO and MaxSAT. In addition, the\npaper proposes a new unsatisfiability-based algorithm for WBO, based on recent\nunsatisfiability-based algorithms for MaxSAT. Besides standard MaxSAT, the new\nalgorithm can also be used to solve weighted MaxSAT and PBO, handling\npseudo-Boolean constraints either natively or by translation to clausal form.\nExperimental results illustrate that unsatisfiability-based algorithms for\nMaxSAT can be orders of magnitude more efficient than existing dedicated\nalgorithms. Finally, the paper illustrates how other algorithms for either PBO\nor MaxSAT can be extended to WBO.\n",
    "query": "optimization algorithms",
    "docId": 111962,
    "score": 23.854236602783203,
    "userScore": 2
  },
  {
    "title": "The Analysis of Optimization Algorithms, A Dissipativity Approach",
    "paperAbstract": "  Optimization problems in engineering and applied mathematics are typically\nsolved in an iterative fashion, by systematically adjusting the variables of\ninterest until an adequate solution is found. The iterative algorithms that\ngovern these systematic adjustments can be viewed as a control system. In\ncontrol systems, the output in measured and the input is adjusted using\nfeedback to drive the error to zero. Similarly, in iterative algorithms, the\noptimization objective is evaluated and the candidate solution is adjusted to\ndrive it toward the optimal point. Choosing an algorithm that works well for a\nvariety of optimization problems is akin to robust controller design. Just as\ndissipativity theory can be used to analyze the stability properties of control\nsystems, it can also be used to analyze the convergence properties of iterative\nalgorithms. By defining an appropriate notion of \"energy\" that dissipates with\nevery iteration of the algorithm, the convergence properties of the algorithm\ncan be characterized. This article formalizes the connection between iterative\nalgorithms and control systems and shows through examples how dissipativity\ntheory can be used to analyze the performance of many classes of optimization\nalgorithms. This control-theoretic viewpoint enables the selection and tuning\nof optimization algorithms to be performed in an automated and systematic way.\n",
    "query": "optimization algorithms",
    "docId": 1658676,
    "score": 23.760236740112305,
    "userScore": 2
  },
  {
    "title": "Provably Faster Algorithms for Bilevel Optimization",
    "paperAbstract": "  Bilevel optimization has been widely applied in many important machine\nlearning applications such as hyperparameter optimization and meta-learning.\nRecently, several momentum-based algorithms have been proposed to solve bilevel\noptimization problems faster. However, those momentum-based algorithms do not\nachieve provably better computational complexity than $\\mathcal{\\widetilde\nO}(\\epsilon^{-2})$ of the SGD-based algorithm. In this paper, we propose two\nnew algorithms for bilevel optimization, where the first algorithm adopts\nmomentum-based recursive iterations, and the second algorithm adopts recursive\ngradient estimations in nested loops to decrease the variance. We show that\nboth algorithms achieve the complexity of $\\mathcal{\\widetilde\nO}(\\epsilon^{-1.5})$, which outperforms all existing algorithms by the order of\nmagnitude. Our experiments validate our theoretical results and demonstrate the\nsuperior empirical performance of our algorithms in hyperparameter\napplications.\n",
    "query": "optimization algorithms",
    "docId": 1482456,
    "score": 23.71802520751953,
    "userScore": 1
  },
  {
    "title": "Best practices for comparing optimization algorithms",
    "paperAbstract": "  Comparing, or benchmarking, of optimization algorithms is a complicated task\nthat involves many subtle considerations to yield a fair and unbiased\nevaluation. In this paper, we systematically review the benchmarking process of\noptimization algorithms, and discuss the challenges of fair comparison. We\nprovide suggestions for each step of the comparison process and highlight the\npitfalls to avoid when evaluating the performance of optimization algorithms.\nWe also discuss various methods of reporting the benchmarking results. Finally,\nsome suggestions for future research are presented to improve the current\nbenchmarking process.\n",
    "query": "optimization algorithms",
    "docId": 893108,
    "score": 23.6295223236084,
    "userScore": 3
  },
  {
    "title": "Communication-Efficient Algorithms For Distributed Optimization",
    "paperAbstract": "  This thesis is concerned with the design of distributed algorithms for\nsolving optimization problems. We consider networks where each node has\nexclusive access to a cost function, and design algorithms that make all nodes\ncooperate to find the minimum of the sum of all the cost functions. Several\nproblems in signal processing, control, and machine learning can be posed as\nsuch optimization problems. Given that communication is often the most\nenergy-consuming operation in networks, it is important to design\ncommunication-efficient algorithms. The main contributions of this thesis are a\nclassification scheme for distributed optimization and a set of corresponding\ncommunication-efficient algorithms.\n  The class of optimization problems we consider is quite general, since each\nfunction may depend on arbitrary components of the optimization variable, and\nnot necessarily on all of them. In doing so, we go beyond the common assumption\nin distributed optimization and create additional structure that can be used to\nreduce the number of communications. This structure is captured by our\nclassification scheme, which identifies easier instances of the problem, for\nexample the standard distributed optimization problem, where all functions\ndepend on all the components of the variable.\n  In our algorithms, no central node coordinates the network, all the\ncommunications occur between neighboring nodes, and the data associated with\neach node is processed locally. We show several applications including average\nconsensus, support vector machines, network flows, and several distributed\nscenarios for compressed sensing. We also propose a new framework for\ndistributed model predictive control. Through extensive numerical experiments,\nwe show that our algorithms outperform prior distributed algorithms in terms of\ncommunication-efficiency, even some that were specifically designed for a\nparticular application.\n",
    "query": "optimization algorithms",
    "docId": 481616,
    "score": 23.524484634399414,
    "userScore": 1
  },
  {
    "title": "Biorthogonal Greedy Algorithms in Convex Optimization",
    "paperAbstract": "  The study of greedy approximation in the context of convex optimization is\nbecoming a promising research direction as greedy algorithms are actively being\nemployed to construct sparse minimizers for convex functions with respect to\ngiven sets of elements. In this paper we propose a unified way of analyzing a\ncertain kind of greedy-type algorithms for the minimization of convex functions\non Banach spaces. Specifically, we define the class of Weak Biorthogonal Greedy\nAlgorithms for convex optimization that contains a wide range of greedy\nalgorithms. We analyze the introduced class of algorithms and establish the\nproperties of convergence, rate of convergence, and numerical stability, which\nis understood in the sense that the steps of the algorithm are allowed to be\nperformed not precisely but with controlled computational inaccuracies. We show\nthat the following well-known algorithms for convex optimization -- the Weak\nChebyshev Greedy Algorithm (co) and the Weak Greedy Algorithm with Free\nRelaxation (co) -- belong to this class, and introduce a new algorithm -- the\nRescaled Weak Relaxed Greedy Algorithm (co). Presented numerical experiments\ndemonstrate the practical performance of the aforementioned greedy algorithms\nin the setting of convex minimization as compared to optimization with\nregularization, which is the conventional approach of constructing sparse\nminimizers.\n",
    "query": "optimization algorithms",
    "docId": 1230943,
    "score": 23.473440170288086,
    "userScore": 1
  },
  {
    "title": "GDP growth rate and population",
    "paperAbstract": "  Real GDP growth rate in developed countries is found to be a sum of two\nterms. The first term is the reciprocal value of the duration of the period of\nmean income growth with work experience, Tcr. The current value of Tcr in the\nUSA is 40 years. The second term is inherently related to population and\ndefined by the relative change in the number of people with a specific age (9\nyears in the USA), (1/2)*dN9(t) /N9(t), where N9(t) is the number of\n9-year-olds at time t. The Tcr grows as the square root of real GDP per capita.\nHence, evolution of real GDP is defined by only one parameter - the number of\npeople of the specific age. Predictions for the USA, the UK, and France are\npresented and discussed. A similar relationship is derived for real GDP per\ncapita. Annual increment of GDP per capita is also a combination of economic\ntrend term and the same specific age population term. The economic trend term\nduring last 55 years is equal to $400 (2002 US dollars) divided by the attained\nlevel of real GDP per capita. Thus, the economic trend term has an asymptotic\nvalue of zero. Inversion of the measured GDP values is used to recover the\ncorresponding change of the specific age population between 1955 and 2003. The\npopulation recovery method based on GDP potentially is of a higher accuracy\nthan routine censuses.\n",
    "query": "GDP growth and inflation rate",
    "docId": 93477,
    "score": 49.76604461669922,
    "userScore": 2
  },
  {
    "title": "Violation of Invariance of Measurement for GDP Growth Rate and its\n  Consequences",
    "paperAbstract": "  The aim here is to address the origins of sustainability for the real growth\nrate in the United States. For over a century of observations on the real GDP\nper capita of the United States a sustainable two percent growth rate has been\nobserved. To find an explanation for this observation I consider the impact of\nutility preferences and the effect of mobility of labor \\& capital on every\nprovided measurement. Mobility of labor results in heterogenous rates of\nincrease in prices which is called Baumol's cost disease phenomenon.\nHeterogeneous rates of inflation then make it impossible to define an invariant\nmeasure for the real growth rate. Paradoxical and ambiguous results already\nhave been observed when different measurements provided by the World Bank have\nbeen compared with the ones from the systems of national accounts (SNA). Such\nambiguity is currently being discussed in economy. I define a toy model for\ncaring out measurements in order to state that this ambiguity can be very\nsignificant. I provide examples in which GDP expands 5 folds while measurements\npercept an expansion around 2 folds. Violation of invariance of the\nmeasurements leads to state that it is hard to compare the growth rate of GDP\nfor a smooth growing country such as the U.S. with a fast growing country such\nas China. Besides, I state that to extrapolate the time that economy of China\npasses the economy of the US we need to consider local metric of the central\nbanks of both countries. Finally I conclude that it is our method of\nmeasurements that leads us to percept the sustainable growth rate.\n",
    "query": "GDP growth and inflation rate",
    "docId": 642509,
    "score": 48.32359313964844,
    "userScore": 1
  },
  {
    "title": "Secular bipolar growth rate of the real US GDP per capita: implications\n  for understanding past and future economic growth",
    "paperAbstract": "  We present a quantitative characterisation of the fluctuations of the\nannualized growth rate of the real US GDP per capita growth at many scales,\nusing a wavelet transform analysis of two data sets, quarterly data from 1947\nto 2015 and annual data from 1800 to 2010. Our main finding is that the\ndistribution of GDP growth rates can be well approximated by a bimodal function\nassociated to a series of switches between regimes of strong growth rate\n$\\rho_\\text{high}$ and regimes of low growth rate $\\rho_\\text{low}$. The\nsuccession of such two regimes compounds to produce a remarkably stable long\nterm average real annualized growth rate of 1.6\\% from 1800 to 2010 and\n$\\approx 2.0\\%$ since 1950, which is the result of a subtle compensation\nbetween the high and low growth regimes that alternate continuously. Thus, the\noverall growth dynamics of the US economy is punctuated, with phases of strong\ngrowth that are intrinsically unsustainable, followed by corrections or\nconsolidation until the next boom starts. We interpret these findings within\nthe theory of \"social bubbles\" and argue as a consequence that estimations of\nthe cost of the 2008 crisis may be misleading. We also interpret the absence of\nstrong recovery since 2008 as a protracted low growth regime $\\rho_\\text{low}$\nassociated with the exceptional nature of the preceding large growth regime.\n",
    "query": "GDP growth and inflation rate",
    "docId": 751687,
    "score": 40.1461296081543,
    "userScore": 1
  },
  {
    "title": "Does GDP measure growth in the economy or simply growth in the money\n  supply?",
    "paperAbstract": "  Gross Domestic Product(GDP) is a widely used measurement of economic growth\nrepresenting the market value of all final goods and services produced by a\ncountry within a given time. In this paper we question the assumption that GDP\nmeasures production, and suggest that in reality it merely captures changes in\nthe rate of expansion of the money supply used to measure the price data it is\nderived from. We first review the Quantity Theory of Money $MV=PT$, and show\nthat the Velocity of Circulation of Money(V) does not affect the price level as\nclaimed, as it is also a factor of the quantity of transactions(T). It then\nfollows directly that attempts to measure total production from any form of\nprice data as the GDP measurement does, will necessarily be confounded by the\ninverse relationship between prices and the quantity of production, which\nrequires that as the total quantity of production increases, prices will drop.\nFinally, in support of this claim we present an empirical analysis of the GDP\nof nine countries and one currency union, showing that when normalized for\nmoney supply growth GDP measures have been uniformly shrinking over the last 20\nyears, and discuss the possible reasons for this behaviour.\n",
    "query": "GDP growth and inflation rate",
    "docId": 361214,
    "score": 39.5714111328125,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "Why is GDP growth linear?",
    "paperAbstract": "  In many European countries the growth of the real GDP per capita has been\nlinear since 1950. An explanation for this linearity is still missing. We\npropose that in artificial intelligence we may find models for a linear growth\nof performance. We also discuss possible consequences of the fact that in\nsystems with linear growth the percentage growth goes to zero.\n",
    "query": "GDP growth and inflation rate",
    "docId": 650902,
    "score": 39.096717834472656,
    "userScore": 2
  },
  {
    "title": "Transitional Dynamics of the Saving Rate and Economic Growth",
    "paperAbstract": "  We estimate the relationship between GDP per capita growth and the growth\nrate of the national savings rate using a panel of 130 countries over the\nperiod 1960-2017. We find that GDP per capita growth increases (decreases) the\ngrowth rate of the national savings rate in poor countries (rich countries),\nand a higher credit-to-GDP ratio decreases the national savings rate as well as\nthe income elasticity of the national savings rate. We develop a model with a\ncredit constraint to explain the growth-saving relationship by the saving\nbehavior of entrepreneurs at both the intensive and extensive margins. We\nfurther present supporting evidence for our theoretical findings by utilizing\ncross-country time series data of the number of new businesses registered and\nthe corporate savings rate.\n",
    "query": "GDP growth and inflation rate",
    "docId": 1403313,
    "score": 38.40980911254883,
    "userScore": 1
  },
  {
    "title": "The role of the \"Maximizing Output Growth Inflation Rate\" in monetary\n  policy",
    "paperAbstract": "  The paper discusses the role of monetary policy when potential output depends\non the inflation rate. If the intention of the central bank is to maximize\nactual output growth, then it has to be credibly committed to a strict\ninflation targeting rule, and to take the MOGIR (the Maximizing Output Growth\nInflation Rate) as the target.\n",
    "query": "GDP growth and inflation rate",
    "docId": 511011,
    "score": 37.80487060546875,
    "userScore": 1,
    "inAnnoy": true
  },
  {
    "title": "Unified Growth Theory Contradicted by the GDP/cap Data",
    "paperAbstract": "  Mathematical properties of the historical GDP/cap distributions are discussed\nand explained. These distributions are frequently incorrectly interpreted and\nthe Unified Growth Theory is an outstanding example of such common\nmisconceptions. It is shown here that the fundamental postulates of this theory\nare contradicted by the data used in its formulation. The postulated three\nregimes of growth did not exist and there was no takeoff at any time. It is\ndemonstrated that features interpreted as three regimes of growth represent\njust mathematical properties of a single, monotonically-increasing\ndistribution, indicating that a single mechanism should be used to explain the\nhistorical economic growth. It is shown that using different socio-economic\nconditions for different perceived parts of the historical GDP/cap data is\nirrelevant and scientifically unjustified. The GDP/cap growth was indeed\nincreasing slowly over a long time and fast over a short time but these\nfeatures represent a single, uniform and uninterrupted growth process, which\nshould be interpreted as whole using a single mechanism of growth.\n",
    "query": "GDP growth and inflation rate",
    "docId": 682503,
    "score": 37.692832946777344,
    "userScore": 2
  },
  {
    "title": "Logistic forecasting of GDP competitiveness",
    "paperAbstract": "  The GDP growth of national economies is modelled by the logistic function.\nApplying it on the GDP data of the World Bank till the year 2020, we forecast\nthe outcome of the competitive GDP growth of Japan, Germany, UK and India, all\nof whose current GDPs are very close to one another. Fulfilling one of the\npredictions, in 2022 the GDP of India has indeed overtaken the GDP of UK. Our\noverall forecast is that by 2047, the GDP of India will be greater than that of\nthe other three countries. We argue that when trade saturates, large and\npopulous countries (like India) have the benefit of high domestic consumption\nto propel their GDP growth.\n",
    "query": "GDP growth and inflation rate",
    "docId": 1742031,
    "score": 36.47157669067383,
    "userScore": 2
  },
  {
    "title": "On the nature of monetary and price inflation and hyperinflation",
    "paperAbstract": "  Monetary inflation is a sustained increase in the money supply than can\nresult in price inflation, which is a rise in the general level of prices of\ngoods and services. The objectives of this paper were to develop economic\nmodels to (1) predict the annual rate of growth in the US consumer price index\n(CPI), based on the annual growth in the US broad money supply (BMS), the\nannual growth in US real GDP, and the annual growth in US savings, over the\ntime period 2001 to 2019; (2) investigate the means by which monetary and price\ninflation can develop into monetary and price hyperinflation. The hypothesis\nthat the annual rate of growth in the US CPI is a function of the annual growth\nin the US BMS minus the annual growth in US real GDP minus the annual growth in\nUS savings, over the time period investigated, has been shown to be the case.\nHowever, an exact relationship required the use of a non-zero residual term. A\nmathematical statistical formulation of a hyperinflationary process has been\nprovided and used to quantify the period of hyperinflation in the Weimar\nRepublic, from July 1922 until the end of November 1923.\n",
    "query": "GDP growth and inflation rate",
    "docId": 1535801,
    "score": 36.30400085449219,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "A Survey of Impedance Measurement Methods in Power Electronics",
    "paperAbstract": "  Impedance is one of the vital parameters that provides useful information for\nmany power electronics related applications. A lot of impedance measurement\nmethods in power electronics have been reported. However, a comprehensive\ninvestigation among these methods in terms of their characteristics,\nadvantages, and limitations has not been found in the literature. In order to\nbridge this gap, a survey of the impedance measurement methods is conducted in\nthis paper. These methods are introduced, discussed, and then classified into\ndifferent categories depending on the measurement modes, principles, and\ninstruments. Moreover, recommendations for the future research on the impedance\nmeasurement are also presented.\n",
    "query": "power electronics applications",
    "docId": 1636233,
    "score": 31.992956161499023,
    "userScore": 3,
    "inAnnoy": true
  },
  {
    "title": "An open-source simulation package for power electronics education",
    "paperAbstract": "  Extension of the open-source simulation package GSEIM for power electronics\napplications is presented. Recent developments in GSEIM, including those\noriented specifically towards power electronic circuits, are described. Some\nexamples of electrical element templates, which form a part of the GSEIM\nlibrary, are discussed. Representative simulation examples in power electronics\nare presented to bring out important features of the simulator. Advantages of\nGSEIM for educational purposes are discussed. Finally, plans regarding future\ndevelopments in GSEIM are presented.\n",
    "query": "power electronics applications",
    "docId": 1643062,
    "score": 31.927505493164062,
    "userScore": 2
  },
  {
    "title": "Review for AI-based Open-Circuit Faults Diagnosis Methods in Power\n  Electronics Converters",
    "paperAbstract": "  Power electronics converters have been widely used in aerospace system, DC\ntransmission, distributed energy, smart grid and so forth, and the reliability\nof power electronics converters has been a hotspot in academia and industry. It\nis of great significance to carry out power electronics converters open-circuit\nfaults monitoring and intelligent fault diagnosis to avoid secondary faults,\nreduce time and cost of operation and maintenance, and improve the reliability\nof power electronics system. Firstly, the faults features of power electronic\nconverters are analyzed and summarized. Secondly, some AI-based fault diagnosis\nmethods and application examples in power electronics converters are reviewed,\nand a fault diagnosis method based on the combination of random forests and\ntransient fault features is proposed for three-phase power electronics\nconverters. Finally, the future research challenges and directions of AI-based\nfault diagnosis methods are pointed out.\n",
    "query": "power electronics applications",
    "docId": 1719773,
    "score": 28.1877384185791,
    "userScore": 2
  },
  {
    "title": "Towards the Solution of Power Dissipation in Electronics Systems through\n  Thermodynamics",
    "paperAbstract": "  Power loss in the electronic system is a very crucial limiting factor that\ncan be reduced or minimized with the help of using the reversible logics \"a\nconcept came from Thermodynamics\". In this paper the authors shows the concept\nof reversible logics for the Electronics system. The logical and physical\ndesigning approach is given in the paper in detail. The contradiction of\nlogical and physical reversibility with the conventional CMOS designing is also\nshows and the solution of that contradiction is also proposed by the authors\nusing adiabatic logic. This Paper gives a complete and clear idea if the\nthermodynamical concept for the electronics industries for power reduction.\n",
    "query": "power electronics applications",
    "docId": 337788,
    "score": 27.18125343322754,
    "userScore": 1
  },
  {
    "title": "Review of Thermal Properties of Graphene and Few-Layer Graphene:\n  Applications in Electronics",
    "paperAbstract": "  We review thermal properties of graphene and few-layer graphene, and discuss\napplications of these materials in thermal management of advanced electronics.\nThe intrinsic thermal conductivity of graphene - among the highest of known\nmaterials - is dominated by phonons near the room temperature. The examples of\nthermal management applications include the few-layer graphene heat spreaders\nintegrated near the heat generating areas of the high-power density\ntransistors. It has been demonstrated that few-layer graphene heat spreaders\ncan lower the hot-spot temperature during device operation resulting in\nimproved performance and reliability of the devices.\n",
    "query": "power electronics applications",
    "docId": 604539,
    "score": 26.957103729248047,
    "userScore": 2
  },
  {
    "title": "Power Converter Topologies for Electrolyzer Applications to Enable\n  Electric Grid Services",
    "paperAbstract": "  Hydrogen electrolyzers, with their operational flexibility, can be configured\nas smart dynamic loads which can provide grid services and facilitate the\nintegration of more renewable energy sources into the electrical grid. However,\nto enable this ability, the electrolyzer system should be able to control both\nactive and reactive power in coordination with the low-level controller of the\nelectrolyzer via the power electronics system interface between the utility\ngrid and electrolyzer. This paper discusses power converter topologies and the\ncontrol scheme of this power electronics interface for electrolyzer\napplications to enable electricity grid services. For the sake of unity, in\nthis paper, we consider the power converter system interfacing the utility grid\nat the line-to-line root mean square RMS value of 480 VAC 60 Hz and supplying\nto the 3500 A 750 kW PEM electrolyzer stack.\n",
    "query": "power electronics applications",
    "docId": 1711682,
    "score": 26.05181884765625,
    "userScore": 1
  },
  {
    "title": "Synthesis of Dispersed Metal Particles for Applications in\n  Photovoltaics, Catalysis, and Electronics",
    "paperAbstract": "  In colloid and nanoparticle chemistry, particle size, shape, crystallinity,\nsurface morphology and composition are controlled by employing the mechanisms\nof burst nucleation, diffusional growth, aggregation, or their combinations.\nHere we review and survey practical examples of recently developed methods for\npreparing metal colloids and nanoparticles for industrial applications such as\nphotovoltaics, catalysis, and consumer electronics. We discuss relevant\ntheoretical models, many of which are general, and identify growth mechanisms\nthat play a major role in other systems and applications as well.\n",
    "query": "power electronics applications",
    "docId": 427233,
    "score": 24.826526641845703,
    "userScore": 1
  },
  {
    "title": "Organic Thermoelectric Textiles for Harvesting Thermal Energy and\n  Powering Electronics",
    "paperAbstract": "  Wearable thermoelectric devices show promises to generate electricity in a\nubiquitous, unintermittent and noiseless way for on-body applications.\nThree-dimensional thermoelectric textiles (TETs) outperform other types in\nsmart textiles owing to their out-of-plane thermoelectric generation and good\nstructural conformability with fabrics. Yet, there has been lack of efficient\nstrategies in scalable manufacture of TETs for sustainably powering\nelectronics. Here, we fabricate organic spacer fabric shaped TETs by knitting\ncarbon nanotube yarn based segmented thermoelectric yarn in large scale.\nCombing finite element analysis with experimental evaluation, we elucidate that\nthe fabric structure significantly influences the power generation. The\noptimally designed TET with good wearability and stability shows high output\npower density of 51.5 mW/m2 and high specific power of 173.3 uW/(g.K) at delta\nT= 47.5 K. The promising on-body applications of the TET in directly and\ncontinuously powering electronics for healthcare and environmental monitoring\nis fully demonstrated. This work will broaden the research vision and provide\nnew routines for developing high-performance and large-scale TETs toward\npractical applications.\n",
    "query": "power electronics applications",
    "docId": 1149419,
    "score": 24.46778678894043,
    "userScore": 1
  },
  {
    "title": "The MAJORANA DEMONSTRATOR Readout Electronics System",
    "paperAbstract": "  The MAJORANA DEMONSTRATOR comprises two arrays of high-purity germanium\ndetectors constructed to search for neutrinoless double-beta decay in 76-Ge and\nother physics beyond the Standard Model. Its readout electronics were designed\nto have low electronic noise, and radioactive backgrounds were minimized by\nusing low-mass components and low-radioactivity materials near the detectors.\nThis paper provides a description of all components of the MAJORANA\nDEMONSTRATOR readout electronics, spanning the front-end electronics and\ninternal cabling, back-end electronics, digitizer, and power supplies, along\nwith the grounding scheme. The spectroscopic performance achieved with these\nreadout electronics is also demonstrated.\n",
    "query": "power electronics applications",
    "docId": 1563454,
    "score": 24.33807373046875,
    "userScore": 1
  },
  {
    "title": "Reservoir Computing with Superconducting Electronics",
    "paperAbstract": "  The rapidity and low power consumption of superconducting electronics makes\nthem an ideal substrate for physical reservoir computing, which commandeers the\ncomputational power inherent to the evolution of a dynamical system for the\npurposes of performing machine learning tasks. We focus on a subset of\nsuperconducting circuits that exhibit soliton-like dynamics in simple\ntransmission line geometries. With numerical simulations we demonstrate the\neffectiveness of these circuits in performing higher-order parity calculations\nand channel equalization at rates approaching 100 Gb/s. The availability of a\nproven superconducting logic scheme considerably simplifies the path to a fully\nintegrated reservoir computing platform and makes superconducting reservoirs an\nenticing substrate for high rate signal processing applications.\n",
    "query": "power electronics applications",
    "docId": 1432667,
    "score": 24.30495834350586,
    "userScore": 2
  },
  {
    "title": "Ramsey Optimal Policy versus Multiple Equilibria with Fiscal and\n  Monetary Interactions",
    "paperAbstract": "  We consider a frictionless constant endowment economy based on Leeper (1991).\nIn this economy, it is shown that, under an ad-hoc monetary rule and an ad-hoc\nfiscal rule, there are two equilibria. One has active monetary policy and\npassive fiscal policy, while the other has passive monetary policy and active\nfiscal policy. We consider an extended setup in which the policy maker\nminimizes a loss function under quasi-commitment, as in Schaumburg and\nTambalotti (2007). Under this formulation there exists a unique Ramsey\nequilibrium, with an interest rate peg and a passive fiscal policy. We thank\nJohn P. Conley, Luis de Araujo and one referree for their very helpful\ncomments.\n",
    "query": "what is fiscal policy",
    "docId": 1241931,
    "score": 43.415802001953125,
    "userScore": 1,
    "inAnnoy": true
  },
  {
    "title": "Estimating the Effects of Fiscal Policy using a Novel Proxy Shrinkage\n  Prior",
    "paperAbstract": "  Different proxy variables commonly used in fiscal policy SVARs lead to\ncontradicting conclusions implying that some of the exogeneity assumptions may\nnot be fulfilled. We combine data-driven identification with a novel proxy\nshrinkage prior which enables us to estimate the effects of fiscal policy\nshocks without relying on strong assumptions about the validity of the proxy\nvariables. Our results suggest that increasing government spending is a more\neffective tool to stimulate the economy than reducing taxes. Additionally, we\nprovide evidence that the commonly used proxies in the literature are\nendogenously related to the structural shocks which leads to biased estimates.\nWe construct new exogenous proxies that can be used in the traditional proxy\nVAR approach resulting in similar estimates compared to our proxy shrinkage\nmodel.\n",
    "query": "what is fiscal policy",
    "docId": 1798000,
    "score": 37.98930740356445,
    "userScore": 2
  },
  {
    "title": "The fiscal response to revenue shocks",
    "paperAbstract": "  We study the impact of fiscal revenue shocks on local fiscal policy. We focus\non the very volatile revenues from the immovable property gains tax in the\ncanton of Zurich, Switzerland, and analyze fiscal behavior following large and\nrare positive and negative revenue shocks. We apply causal machine learning\nstrategies and implement the post-double-selection LASSO estimator to identify\nthe causal effect of revenue shocks on public finances. We show that local\npolicymakers overall predominantly smooth fiscal shocks. However, we also find\nsome patterns consistent with fiscal conservatism, where positive shocks are\nsmoothed, while negative ones are mitigated by spending cuts.\n",
    "query": "what is fiscal policy",
    "docId": 1411403,
    "score": 37.794403076171875,
    "userScore": 1
  },
  {
    "title": "Fiscal shocks and asymmetric effects: a comparative analysis",
    "paperAbstract": "  We empirically test the effects of unanticipated fiscal policy shocks on the\ngrowth rate and the cyclical component of real private output and reveal\ndifferent types of asymmetries in fiscal policy implementation. The data used\nare quarterly U.S. observati ons over the period 1967:1 to 2011:4. In doing so,\nwe use both a vector autoregressive and the novel support vector machines\nsystems in order to extract the fiscal policy shocks series. The latter has\nnever been used before in a similar macroeconomic setting. Within our research\nframework, in order to test the robustness of our results to alternative\naggregate money supply definitions we use two alternative moentary aggregates.\nThese are the commonly reported by central banks and policy makers simple sum\nmonetary aggregates at the MZM level of aggregation and the alternative CFS\nDivisia MZM aggregate. From each of these four systems we extracted four types\nof shocks: a negative and a positive government spending shock and a negative\nand a positive government revenue shock. These eight different types of\nunanticipated fiscal policy shocks are next used to empirically examine their\neffects on the growth rate and the cyclical component of real private GNP in\ntwo sets of regressions: one that assumes only contemporaneous effects of the\nshocks on output and one that is augmented with four lags of each fiscal shock.\n",
    "query": "what is fiscal policy",
    "docId": 484046,
    "score": 36.896697998046875,
    "userScore": 1
  },
  {
    "title": "Preliminary steps toward a universal economic dynamics for monetary and\n  fiscal policy",
    "paperAbstract": "  We consider the relationship between economic activity and intervention,\nincluding monetary and fiscal policy, using a universal dynamic framework.\nCentral bank policies are designed for growth without excess inflation.\nHowever, unemployment, investment, consumption, and inflation are interlinked.\nUnderstanding dynamics is crucial to assessing the effects of policy,\nespecially in the aftermath of the financial crisis. Here we lay out a program\nof research into monetary and economic dynamics and preliminary steps toward\nits execution. We use principles of response theory to derive implications for\npolicy. We find that the current approach, which considers the overall money\nsupply, is insufficient to regulate economic growth. While it can achieve some\ndegree of control, optimizing growth also requires a fiscal policy balancing\nmonetary injection between two dominant loop flows, the consumption and wages\nloop, and investment and returns loop. The balance arises from a composite of\ngovernment tax, entitlement, subsidy policies, corporate policies, as well as\nmonetary policy. We show empirically that a transition occurred in 1980 between\ntwo regimes--an oversupply to the consumption and wages loop, to an oversupply\nof the investment and returns loop. The imbalance is manifest in savings and\nborrowing by consumers and investors, and in inflation. The latter increased\nuntil 1980, and decreased subsequently, resulting in a zero rate largely\nunrelated to the financial crisis. Three recessions and the financial crisis\nare part of this dynamic. Optimizing growth now requires shifting the balance.\nOur analysis supports advocates of greater income and / or government support\nfor the poor who use a larger fraction of income for consumption. This promotes\ninvestment due to growth in demand. Otherwise, investment opportunities are\nlimited, capital remains uninvested, and does not contribute to growth.\n",
    "query": "what is fiscal policy",
    "docId": 901668,
    "score": 35.704345703125,
    "userScore": 2
  },
  {
    "title": "Fiscal policy and inequality in a model with endogenous positional\n  concerns",
    "paperAbstract": "  We investigate the dynamics of wealth inequality in an economy where\nhouseholds have positional preferences, with the strength of the positional\nconcern determined endogenously by inequality of wealth distribution in the\nsociety. We demonstrate that in the long run such an economy converges to a\nunique egalitarian steady-state equilibrium, with all households holding equal\npositive wealth, when the initial inequality is sufficiently low. Otherwise,\nthe steady state is characterised by polarisation of households into rich, who\nown all the wealth, and poor, whose wealth is zero. A fiscal policy with\ngovernment consumption funded by taxes on labour income and wealth can move the\neconomy from any initial state towards an egalitarian equilibrium with a higher\naggregate wealth.\n",
    "query": "what is fiscal policy",
    "docId": 1494422,
    "score": 35.25770568847656,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "Monetary-fiscal interactions under price level targeting",
    "paperAbstract": "  The adoption of a \"makeup\" strategy is one of the proposals in the ongoing\nreview of the Fed's monetary policy framework. Another suggestion, to avoid the\nzero lower bound, is a more active role for fiscal policy. We put together\nthese ideas to study monetary-fiscal interactions under price level targeting.\nUnder price level targeting and a fiscally-led regime, we find that following a\ndeflationary demand shock: (i) the central bank increases (rather than\ndecreases) the policy rate; (ii) the central bank, thus, avoids the zero lower\nbound; (iii) price level targeting is generally welfare improving if compared\nto inflation targeting.\n",
    "query": "what is fiscal policy",
    "docId": 1371309,
    "score": 34.774776458740234,
    "userScore": 2
  },
  {
    "title": "Balancing Fiscal and Mortality Impact of SARS-CoV-2 Mitigation\n  Measurements",
    "paperAbstract": "  An epidemic carries human and fiscal costs. In the case of imported\npandemics, the first-best solution is to restrict national borders to identify\nand isolate infected individuals. However, when that opportunity is not fully\nseized and there is no preventative intervention available, second-best options\nmust be chosen. In this article we develop a system of differential equations\nthat simulate both the fiscal and human costs associated to different\nmitigation measurements. After simulating several scenarios, we conclude that\nherd immunity (or unleashing the pandemic) is the worst policy in terms of both\nhuman and fiscal cost. We found that the second-best policy would be a strict\npolicy (e.g. physical distancing with massive testing) established under the\nfirst 20 days after the pandemic, that lowers the probability of infection by\n80%. In the case of the US, this strict policy would save more than 239\nthousands lives and almost $170.8 billion to taxpayers when compared to the\nherd immunity case.\n",
    "query": "what is fiscal policy",
    "docId": 1295877,
    "score": 34.28071212768555,
    "userScore": 1
  },
  {
    "title": "Fiscal Stimulus of Last Resort",
    "paperAbstract": "  I examine global dynamics in a monetary model with overlapping generations of\nfinite-horizon agents and a binding lower bound on nominal interest rates. Debt\ntargeting rules exacerbate the possibility of self-fulfilling liquidity traps,\nfor agents expect austerity following deflationary slumps. Conversely, activist\nbut sustainable fiscal policy regimes - implementing intertemporally balanced\ntax cuts and/or transfer increases in response to disinflationary trajectories\n- are capable of escaping liquidity traps and embarking inflation into a\nglobally stable path that converges to the target. Should fiscal stimulus of\nlast resort be overly aggressive, however, spiral dynamics around the\nliquidity-trap steady state exist, causing global indeterminacy.\n",
    "query": "what is fiscal policy",
    "docId": 1450171,
    "score": 34.231651306152344,
    "userScore": 1,
    "inAnnoy": true
  },
  {
    "title": "Shifting Policy Strategy in Keynesianism",
    "paperAbstract": "  This paper analyzes the evolution of Keynesianism making use of concepts\noffered by Imre Lakatos. The Keynesian \"hard core\" lies in its views regarding\nthe instability of the market economy, its \"protective belt\" in the policy\nstrategy for macroeconomic stabilization using fiscal policy and monetary\npolicy. Keynesianism developed as a policy program to counter classical\nliberalism, which attributes priority to the autonomy of the market economy and\ntries to limit the role of government. In general, the core of every policy\nprogram consists in an unfalsifiable worldview and a value judgment that remain\nunchanged. On the other hand, a policy strategy with a protective belt\ninevitably evolves owing to changes in reality and advances in scientific\nknowledge. This is why the Keynesian policy strategy has shifted from being\nfiscal-led to one that is monetary-led because of the influence of monetarism;\nfurther, the Great Recession has even led to their integration.\n",
    "query": "what is fiscal policy",
    "docId": 1306263,
    "score": 30.933746337890625,
    "userScore": 1,
    "inAnnoy": true
  },
  {
    "title": "Deep Learning for Audio Signal Processing",
    "paperAbstract": "  Given the recent surge in developments of deep learning, this article\nprovides a review of the state-of-the-art deep learning techniques for audio\nsignal processing. Speech, music, and environmental sound processing are\nconsidered side-by-side, in order to point out similarities and differences\nbetween the domains, highlighting general methods, problems, key references,\nand potential for cross-fertilization between areas. The dominant feature\nrepresentations (in particular, log-mel spectra and raw waveform) and deep\nlearning models are reviewed, including convolutional neural networks, variants\nof the long short-term memory architecture, as well as more audio-specific\nneural network models. Subsequently, prominent deep learning application areas\nare covered, i.e. audio recognition (automatic speech recognition, music\ninformation retrieval, environmental sound detection, localization and\ntracking) and synthesis and transformation (source separation, audio\nenhancement, generative models for speech, sound, and music synthesis).\nFinally, key issues and future questions regarding deep learning applied to\naudio signal processing are identified.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1118514,
    "score": 57.53107452392578,
    "userScore": 2
  },
  {
    "title": "Recognition of Isolated Words using Zernike and MFCC features for Audio\n  Visual Speech Recognition",
    "paperAbstract": "  Automatic Speech Recognition (ASR) by machine is an attractive research topic\nin signal processing domain and has attracted many researchers to contribute in\nthis area. In recent year, there have been many advances in automatic speech\nreading system with the inclusion of audio and visual speech features to\nrecognize words under noisy conditions. The objective of audio-visual speech\nrecognition system is to improve recognition accuracy. In this paper we\ncomputed visual features using Zernike moments and audio feature using Mel\nFrequency Cepstral Coefficients (MFCC) on vVISWa (Visual Vocabulary of\nIndependent Standard Words) dataset which contains collection of isolated set\nof city names of 10 speakers. The visual features were normalized and dimension\nof features set was reduced by Principal Component Analysis (PCA) in order to\nrecognize the isolated word utterance on PCA space.The performance of\nrecognition of isolated words based on visual only and audio only features\nresults in 63.88 and 100 respectively.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 537922,
    "score": 51.62249755859375,
    "userScore": 2
  },
  {
    "title": "The Multimodal Information based Speech Processing (MISP) 2022\n  Challenge: Audio-Visual Diarization and Recognition",
    "paperAbstract": "  The Multi-modal Information based Speech Processing (MISP) challenge aims to\nextend the application of signal processing technology in specific scenarios by\npromoting the research into wake-up words, speaker diarization, speech\nrecognition, and other technologies. The MISP2022 challenge has two tracks: 1)\naudio-visual speaker diarization (AVSD), aiming to solve ``who spoken when''\nusing both audio and visual data; 2) a novel audio-visual diarization and\nrecognition (AVDR) task that focuses on addressing ``who spoken what when''\nwith audio-visual speaker diarization results. Both tracks focus on the Chinese\nlanguage, and use far-field audio and video in real home-tv scenarios: 2-6\npeople communicating each other with TV noise in the background. This paper\nintroduces the dataset, track settings, and baselines of the MISP2022\nchallenge. Our analyses of experiments and examples indicate the good\nperformance of AVDR baseline system, and the potential difficulties in this\nchallenge due to, e.g., the far-field video quality, the presence of TV noise\nin the background, and the indistinguishable speakers.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1806123,
    "score": 51.50925827026367,
    "userScore": 2
  },
  {
    "title": "An Overview on Audio, Signal, Speech, & Language Processing for COVID-19",
    "paperAbstract": "  Recently, there has been an increased attention towards innovating,\nenhancing, building, and deploying applications of speech signal processing for\nproviding assistance and relief to human mankind from the Coronavirus\n(COVID-19) pandemic. Many AI with speech initiatives are taken to combat with\nthe present situation and also to create a safe and secure environment for the\nfuture. This paper summarises all these efforts taken by the re-search\ncommunity towards helping the individuals and the society in the fight against\nCOVID-19 over the past 3-4 months using speech signal processing. We also\nsummarise the deep techniques used in this direction to come up with capable\nsolutions in a short span of time. This paper further gives an overview of the\ncontributions from non-speech modalities that may complement or serve as\ninspiration for audio and speech analysis. In addition, we discuss our\nobservations with respect to solution usability, challenges, and the\nsignificant technology achievements.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1288374,
    "score": 50.27043914794922,
    "userScore": 3
  },
  {
    "title": "Audio, Speech, Language, & Signal Processing for COVID-19: A\n  Comprehensive Overview",
    "paperAbstract": "  The Coronavirus (COVID-19) pandemic has been the research focus world-wide in\nthe year 2020. Several efforts, from collection of COVID-19 patients' data to\nscreening them for the virus's detection are taken with rigour. A major portion\nof COVID-19 symptoms are related to the functioning of the respiratory system,\nwhich in-turn critically influences the human speech production system. This\ndrives the research focus towards identifying the markers of COVID-19 in speech\nand other human generated audio signals. In this paper, we give an overview of\nthe speech and other audio signal, language and general signal processing-based\nwork done using Artificial Intelligence techniques to screen, diagnose,\nmonitor, and spread the awareness aboutCOVID-19. We also briefly describe the\nresearch related to detect accord-ing COVID-19 symptoms carried out so far. We\naspire that this collective information will be useful in developing automated\nsystems, which can help in the context of COVID-19 using non-obtrusive and easy\nto use modalities such as audio, speech, and language.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1387193,
    "score": 49.598121643066406,
    "userScore": 3
  },
  {
    "title": "Audio-visual multi-channel speech separation, dereverberation and\n  recognition",
    "paperAbstract": "  Despite the rapid advance of automatic speech recognition (ASR) technologies,\naccurate recognition of cocktail party speech characterised by the interference\nfrom overlapping speakers, background noise and room reverberation remains a\nhighly challenging task to date. Motivated by the invariance of visual modality\nto acoustic signal corruption, audio-visual speech enhancement techniques have\nbeen developed, although predominantly targeting overlapping speech separation\nand recognition tasks. In this paper, an audio-visual multi-channel speech\nseparation, dereverberation and recognition approach featuring a full\nincorporation of visual information into all three stages of the system is\nproposed. The advantage of the additional visual modality over using audio only\nis demonstrated on two neural dereverberation approaches based on DNN-WPE and\nspectral mapping respectively. The learning cost function mismatch between the\nseparation and dereverberation models and their integration with the back-end\nrecognition system is minimised using fine-tuning on the MSE and LF-MMI\ncriteria. Experiments conducted on the LRS2 dataset suggest that the proposed\naudio-visual multi-channel speech separation, dereverberation and recognition\nsystem outperforms the baseline audio-visual multi-channel speech separation\nand recognition system containing no dereverberation module by a statistically\nsignificant word error rate (WER) reduction of 2.06% absolute (8.77% relative).\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1632115,
    "score": 48.84076690673828,
    "userScore": 2
  },
  {
    "title": "Deep Audio-Visual Speech Recognition",
    "paperAbstract": "  The goal of this work is to recognise phrases and sentences being spoken by a\ntalking face, with or without the audio. Unlike previous works that have\nfocussed on recognising a limited number of words or phrases, we tackle lip\nreading as an open-world problem - unconstrained natural language sentences,\nand in the wild videos. Our key contributions are: (1) we compare two models\nfor lip reading, one using a CTC loss, and the other using a\nsequence-to-sequence loss. Both models are built on top of the transformer\nself-attention architecture; (2) we investigate to what extent lip reading is\ncomplementary to audio speech recognition, especially when the audio signal is\nnoisy; (3) we introduce and publicly release a new dataset for audio-visual\nspeech recognition, LRS2-BBC, consisting of thousands of natural sentences from\nBritish television. The models that we train surpass the performance of all\nprevious work on a lip reading benchmark dataset by a significant margin.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1022124,
    "score": 48.5115852355957,
    "userScore": 2
  },
  {
    "title": "Audio-visual Multi-channel Recognition of Overlapped Speech",
    "paperAbstract": "  Automatic speech recognition (ASR) of overlapped speech remains a highly\nchallenging task to date. To this end, multi-channel microphone array data are\nwidely used in state-of-the-art ASR systems. Motivated by the invariance of\nvisual modality to acoustic signal corruption, this paper presents an\naudio-visual multi-channel overlapped speech recognition system featuring\ntightly integrated separation front-end and recognition back-end. A series of\naudio-visual multi-channel speech separation front-end components based on\n\\textit{TF masking}, \\textit{filter\\&sum} and \\textit{mask-based MVDR}\nbeamforming approaches were developed. To reduce the error cost mismatch\nbetween the separation and recognition components, they were jointly fine-tuned\nusing the connectionist temporal classification (CTC) loss function, or a\nmulti-task criterion interpolation with scale-invariant signal to noise ratio\n(Si-SNR) error cost. Experiments suggest that the proposed multi-channel AVSR\nsystem outperforms the baseline audio-only ASR system by up to 6.81\\% (26.83\\%\nrelative) and 22.22\\% (56.87\\% relative) absolute word error rate (WER)\nreduction on overlapped speech constructed using either simulation or replaying\nof the lipreading sentence 2 (LRS2) dataset respectively.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1288366,
    "score": 48.13784408569336,
    "userScore": 2
  },
  {
    "title": "Multimodal Speech Recognition with Unstructured Audio Masking",
    "paperAbstract": "  Visual context has been shown to be useful for automatic speech recognition\n(ASR) systems when the speech signal is noisy or corrupted. Previous work,\nhowever, has only demonstrated the utility of visual context in an unrealistic\nsetting, where a fixed set of words are systematically masked in the audio. In\nthis paper, we simulate a more realistic masking scenario during model\ntraining, called RandWordMask, where the masking can occur for any word\nsegment. Our experiments on the Flickr 8K Audio Captions Corpus show that\nmultimodal ASR can generalize to recover different types of masked words in\nthis unstructured masking setting. Moreover, our analysis shows that our models\nare capable of attending to the visual signal when the audio signal is\ncorrupted. These results show that multimodal ASR systems can leverage the\nvisual signal in more generalized noisy scenarios.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1364972,
    "score": 47.831268310546875,
    "userScore": 3
  },
  {
    "title": "Predict-and-Update Network: Audio-Visual Speech Recognition Inspired by\n  Human Speech Perception",
    "paperAbstract": "  Audio and visual signals complement each other in human speech perception, so\ndo they in speech recognition. The visual hint is less evident than the\nacoustic hint, but more robust in a complex acoustic environment, as far as\nspeech perception is concerned. It remains a challenge how we effectively\nexploit the interaction between audio and visual signals for automatic speech\nrecognition. There have been studies to exploit visual signals as redundant or\ncomplementary information to audio input in a synchronous manner. Human studies\nsuggest that visual signal primes the listener in advance as to when and on\nwhich frequency to attend to. We propose a Predict-and-Update Network (P&U\nnet), to simulate such a visual cueing mechanism for Audio-Visual Speech\nRecognition (AVSR). In particular, we first predict the character posteriors of\nthe spoken words, i.e. the visual embedding, based on the visual signals. The\naudio signal is then conditioned on the visual embedding via a novel\ncross-modal Conformer, that updates the character posteriors. We validate the\neffectiveness of the visual cueing mechanism through extensive experiments. The\nproposed P&U net outperforms the state-of-the-art AVSR methods on both LRS2-BBC\nand LRS3-BBC datasets, with the relative reduced Word Error Rate (WER)s\nexceeding 10% and 40% under clean and noisy conditions, respectively.\n",
    "query": "speech recognition and audio signal processing",
    "docId": 1707483,
    "score": 47.706825256347656,
    "userScore": 3
  },
  {
    "title": "EDGE COVID-19: A Web Platform to generate submission-ready genomes for\n  SARS-CoV-2 sequencing efforts",
    "paperAbstract": "  Genomics has become an essential technology for surveilling emerging\ninfectious disease outbreaks. A wide range of technologies and strategies for\npathogen genome enrichment and sequencing are being used by laboratories\nworldwide, together with different, and sometimes ad hoc, analytical procedures\nfor generating genome sequences. As a result, public repositories now contain\nnon-standard entries of varying quality. A standardized analytical process for\nconsensus genome sequence determination, particularly for outbreaks such as the\nongoing COVID-19 pandemic, is critical to provide a solid genomic basis for\nepidemiological analyses and well-informed decision making. To address this\nneed, we have developed a bioinformatic workflow to standardize the analysis of\nSARS-CoV-2 sequencing data generated with either the Illumina or Oxford\nNanopore platforms. Using an intuitive web-based interface, this workflow\nautomates SARS-CoV-2 reference-based genome assembly, variant calling, lineage\ndetermination, and provides the ability to submit the consensus sequence and\nnecessary metadata to GenBank or GISAID. Given a raw Illumina or Oxford\nNanopore FASTQ read file, this web-based platform enables non-bioinformatics\nexperts to automatically produce a SARS-CoV-2 genome that is ready for\nsubmission to GISAID or GenBank.\n  Availability:https://edge-covid19.edgebioinformatics.org;https://github.com/LANL-Bioinformatics/EDGE/tree/SARS-CoV2\n",
    "query": "genome sequencing of covid-19",
    "docId": 1302572,
    "score": 45.29828643798828,
    "userScore": 2
  },
  {
    "title": "Benchmarking Machine Learning Robustness in Covid-19 Genome Sequence\n  Classification",
    "paperAbstract": "  The rapid spread of the COVID-19 pandemic has resulted in an unprecedented\namount of sequence data of the SARS-CoV-2 genome -- millions of sequences and\ncounting. This amount of data, while being orders of magnitude beyond the\ncapacity of traditional approaches to understanding the diversity, dynamics,\nand evolution of viruses is nonetheless a rich resource for machine learning\n(ML) approaches as alternatives for extracting such important information from\nthese data. It is of hence utmost importance to design a framework for testing\nand benchmarking the robustness of these ML models.\n  This paper makes the first effort (to our knowledge) to benchmark the\nrobustness of ML models by simulating biological sequences with errors. In this\npaper, we introduce several ways to perturb SARS-CoV-2 genome sequences to\nmimic the error profiles of common sequencing platforms such as Illumina and\nPacBio. We show from experiments on a wide array of ML models that some\nsimulation-based approaches are more robust (and accurate) than others for\nspecific embedding methods to certain adversarial attacks to the input\nsequences. Our benchmarking framework may assist researchers in properly\nassessing different ML models and help them understand the behavior of the\nSARS-CoV-2 virus or avoid possible future pandemics.\n",
    "query": "genome sequencing of covid-19",
    "docId": 1684796,
    "score": 43.76053237915039,
    "userScore": 1
  },
  {
    "title": "COVID-19 Evolves in Human Hosts",
    "paperAbstract": "  Today, we are all threatened by an unprecedented pandemic: COVID-19. How\ndifferent is it from other coronaviruses? Will it be attenuated or become more\nvirulent? Which animals may be its original host? In this study, we collected\nand analyzed nearly thirty thousand publicly available complete genome\nsequences for COVID-19 virus from 79 different countries, the previously known\nflu-causing coronaviruses (HCov-229E, HCov-OC43, HCov-NL63 and HCov-HKU1) and\nthe lethal, pathogenic viruses, SARS, MERS, Victoria, Lassa, Yamagata, Ebola,\nand Dengue. We found strong similarities between the current circulating\nCOVID-19 and SARS and MERS, as well as COVID-19 in rhinolophines and pangolins.\nOn the contrary, COVID-19 shares little similarity with the flu-causing\ncoronaviruses and the other known viruses. Strikingly, we observed that the\ndivergence of COVID-19 strains isolated from human hosts has steadily increased\nfrom December 2019 to May 2020, suggesting COVID-19 is actively evolving in\nhuman hosts. In this paper, we first propose a novel MLCS algorithm NP-MLCS1\nfor the big sequence analysis, which can calculate the common model for\nCOVID-19 complete genome sequences to provide important information for vaccine\nand antibody development. Geographic and time-course analysis of the evolution\ntrees of the human COVID-19 reveals possible evolutional paths among strains\nfrom 79 countries. This finding has important implications to the management of\nCOVID-19 and the development of vaccines and medications.\n",
    "query": "genome sequencing of covid-19",
    "docId": 1255935,
    "score": 42.60210418701172,
    "userScore": 3,
    "inAnnoy": true
  },
  {
    "title": "Mutations on COVID-19 diagnostic targets",
    "paperAbstract": "  Effective, sensitive, and reliable diagnostic reagents are of paramount\nimportance for combating the ongoing coronavirus disease 2019 (COVID-19)\npandemic at a time there is no preventive vaccine nor specific drug available\nfor severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). It would be\nan absolute tragedy if currently used diagnostic reagents are undermined in any\nmanner. Based on the genotyping of 7818 SARS-CoV-2 genome samples collected up\nto May 1, 2020, we reveal that essentially all of the current COVID-19\ndiagnostic targets have had mutations. We further show that SARS-CoV-2 has the\nmost devastating mutations on the targets of various nucleocapsid (N) gene\nprimers and probes, which have been unfortunately used by countries around the\nworld to diagnose COVID-19. Our findings explain what has seriously gone wrong\nwith a specific diagnostic reagent made in China. To understand whether\nSARS-CoV-2 genes have mutated unevenly, we have computed the mutation ratio and\nmutation $h$-index of all SARS-CoV genes, indicating that the N gene is the\nmost non-conservative gene in the SARS-CoV-2 genome. Our findings enable\nresearchers to target the most conservative SARS-CoV-2 genes and proteins for\nthe design and development of COVID-19 diagnostic reagents, preventive\nvaccines, and therapeutic medicines.\n",
    "query": "genome sequencing of covid-19",
    "docId": 1281983,
    "score": 39.55888366699219,
    "userScore": 1
  },
  {
    "title": "The Chills and Thrills of Whole Genome Sequencing",
    "paperAbstract": "  In recent years, Whole Genome Sequencing (WGS) evolved from a\nfuturistic-sounding research project to an increasingly affordable technology\nfor determining complete genome sequences of complex organisms, including\nhumans. This prompts a wide range of revolutionary applications, as WGS\npromises to improve modern healthcare and provide a better understanding of the\nhuman genome -- in particular, its relation to diseases and response to\ntreatments. However, this progress raises worrisome privacy and ethical issues,\nsince, besides uniquely identifying its owner, the genome contains a treasure\ntrove of highly personal and sensitive information. In this article, after\nsummarizing recent advances in genomics, we discuss some important privacy\nissues associated with human genomic information and identify a number of\nparticularly relevant research challenges.\n",
    "query": "genome sequencing of covid-19",
    "docId": 436048,
    "score": 39.338436126708984,
    "userScore": 1
  },
  {
    "title": "The sequencing and interpretation of the genome obtained from a Serbian\n  individual",
    "paperAbstract": "  Recent genetic studies and whole-genome sequencing projects have greatly\nimproved our understanding of human variation and clinically actionable genetic\ninformation. Smaller ethnic populations, however, remain underrepresented in\nboth individual and large-scale sequencing efforts and hence present an\nopportunity to discover new variants of biomedical and demographic\nsignificance. This report describes the sequencing and analysis of a genome\nobtained from an individual of Serbian origin, introducing tens of thousands of\npreviously unknown variants to the currently available pool. Ancestry analysis\nplaces this individual in close proximity of the Central and Eastern European\npopulations; i.e., closest to Croatian, Bulgarian and Hungarian individuals\nand, in terms of other Europeans, furthest from Ashkenazi Jewish, Spanish,\nSicilian, and Baltic individuals. Our analysis confirmed gene flow between\nNeanderthal and ancestral pan-European populations, with similar contributions\nto the Serbian genome as those observed in other European groups. Finally, to\nassess the burden of potentially disease-causing/clinically relevant variation\nin the sequenced genome, we utilized manually curated genotype-phenotype\nassociation databases and variant-effect predictors. We identified several\nvariants that have previously been associated with severe early-onset disease\nthat is not evident in the proband, as well as variants that could yet prove to\nbe clinically relevant to the proband over the next decades. The presence of\nnumerous private and low-frequency variants along with the observed and\npredicted disease-causing mutations in this genome exemplify some of the global\nchallenges of genome interpretation, especially in the context of understudied\nethnic groups.\n",
    "query": "genome sequencing of covid-19",
    "docId": 979995,
    "score": 38.99424743652344,
    "userScore": 1
  },
  {
    "title": "Identification of Repurposable Drugs and Adverse Drug Reactions for\n  Various Courses of COVID-19 Based on Single-Cell RNA Sequencing Data",
    "paperAbstract": "  Coronavirus disease 2019 (COVID-19) has impacted almost every part of human\nlife worldwide, posing a massive threat to human health. There is no specific\ndrug for COVID-19, highlighting the urgent need for the development of\neffective therapeutics. To identify potentially repurposable drugs, we employed\na systematic approach to mine candidates from U.S. FDA-approved drugs and\npreclinical small-molecule compounds by integrating the gene expression\nperturbation data for chemicals from the Library of Integrated Network-Based\nCellular Signatures project with a publicly available single-cell RNA\nsequencing dataset from mild and severe COVID-19 patients. We identified 281\nFDA-approved drugs that have the potential to be effective against SARS-CoV-2\ninfection, 16 of which are currently undergoing clinical trials to evaluate\ntheir efficacy against COVID-19. We experimentally tested the inhibitory\neffects of tyrphostin-AG-1478 and brefeldin-a on the replication of the\nsingle-stranded ribonucleic acid (ssRNA) virus influenza A virus. In\nconclusion, we have identified a list of repurposable anti-SARS-CoV-2 drugs\nusing a systems biology approach.\n",
    "query": "genome sequencing of covid-19",
    "docId": 1287651,
    "score": 38.930233001708984,
    "userScore": 1
  },
  {
    "title": "Whole Genome Sequencing: Innovation Dream or Privacy Nightmare?",
    "paperAbstract": "  Over the past several years, DNA sequencing has emerged as one of the driving\nforces in life-sciences, paving the way for affordable and accurate whole\ngenome sequencing. As genomes represent the entirety of an organism's\nhereditary information, the availability of complete human genomes prompts a\nwide range of revolutionary applications. The hope for improving modern\nhealthcare and better understanding the human genome propels many interesting\nand challenging research frontiers. Unfortunately, however, the proliferation\nof human genomes amplifies worrisome privacy concerns, since a genome\nrepresents a treasure trove of highly personal and sensitive information. In\nthis article, we provide an overview of positive results and biomedical\nadvances in the field, and discuss privacy issues associated with human genomic\ninformation. Finally, we survey available privacy-enhancing technologies and\nlist a number of open research challenges.\n",
    "query": "genome sequencing of covid-19",
    "docId": 378614,
    "score": 38.849605560302734,
    "userScore": 1
  },
  {
    "title": "Nanopore Sequencing of the phi X 174 genome",
    "paperAbstract": "  Nanopore sequencing of DNA is a single-molecule technique that may achieve\nlong reads, low cost, and high speed with minimal sample preparation and\ninstrumentation. Here, we build on recent progress with respect to nanopore\nresolution and DNA control to interpret the procession of ion current levels\nobserved during the translocation of DNA through the pore MspA. As\napproximately four nucleotides affect the ion current of each level, we\nmeasured the ion current corresponding to all 256 four-nucleotide combinations\n(quadromers). This quadromer map is highly predictive of ion current levels of\npreviously unmeasured sequences derived from the bacteriophage phi X 174\ngenome. Furthermore, we show nanopore sequencing reads of phi X 174 up to 4,500\nbases in length that can be unambiguously aligned to the phi X 174 reference\ngenome, and demonstrate proof-of-concept utility with respect to hybrid genome\nassembly and polymorphism detection. All methods and data are made fully\navailable.\n",
    "query": "genome sequencing of covid-19",
    "docId": 533097,
    "score": 38.66313552856445,
    "userScore": 1
  },
  {
    "title": "Cancer systems biology in the genome sequencing era: Part 1, dissecting\n  and modeling of tumor clones and their networks",
    "paperAbstract": "  Recent tumor genome sequencing confirmed that one tumor often consists of\nmultiple cell subpopulations (clones) which bear different, but related,\ngenetic profiles such as mutation and copy number variation profiles. Thus far,\none tumor has been viewed as a whole entity in cancer functional studies. With\nthe advances of genome sequencing and computational analysis, we are able to\nquantify and computationally dissect clones from tumors, and then conduct\nclone-based analysis. Emerging technologies such as single-cell genome\nsequencing and RNA-Seq could profile tumor clones. Thus, we should reconsider\nhow to conduct cancer systems biology studies in the genome sequencing era. We\nwill outline new directions for conducting cancer systems biology by\nconsidering that genome sequencing technology can be used for dissecting,\nquantifying and genetically characterizing clones from tumors. Topics discussed\nin Part 1 of this review include computationally quantifying of tumor\nsubpopulations; clone-based network modeling, cancer hallmark-based networks\nand their high-order rewiring principles and the principles of cell survival\nnetworks of fast-growing clones.\n",
    "query": "genome sequencing of covid-19",
    "docId": 554398,
    "score": 37.10791015625,
    "userScore": 1
  },
  {
    "title": "Survey on Positioning System: Sampling methods",
    "paperAbstract": "  Millimeter-accuracy Ultra-Wideband (UWB) positioning systems using the Time\nDifference Of Arrival (TDOA) algorithm are able to be utilized in military and\nmany other important applications. Previous research on UWB positioning system\nhas achieved up to mm or sub-mm accuracy. However, one bottleneck in UWB system\nis at sampling high resolution UWB signals, as well as high resolution timing\ninformation. In this paper, UWB positioning systems are surveyed and we focus\non sampling methods for handling UWB signals. Among different sampling methods,\none traditional way is the sequential sampling method, which is not a real time\nsampling method and blocks UWB positioning system to achieve higher precision.\nAnother way is by applying Compressed Sensing (CS) to UWB system for achieving\nsub-mm positioning accuracy. In this paper, we compare different TDOA-based UWB\nsystems with different sampling methods. In particular, several CS-UWB\nalgorithms for UWB signal reconstruction are compared in terms of positioning\naccuracy. Simulation results in 2D and 3D experiments demonstrate performance\nof different algorithms including typical BCS, OMP and BP algorithms. CS-UWB is\nalso compared with UWB positioning system based on the sequential sampling\nmethod.\n",
    "query": "different sampling methods",
    "docId": 449330,
    "score": 27.23198699951172,
    "userScore": 1
  },
  {
    "title": "Evaluation of Sampling Methods for Scatterplots",
    "paperAbstract": "  Given a scatterplot with tens of thousands of points or even more, a natural\nquestion is which sampling method should be used to create a small but \"good\"\nscatterplot for a better abstraction. We present the results of a user study\nthat investigates the influence of different sampling strategies on multi-class\nscatterplots. The main goal of this study is to understand the capability of\nsampling methods in preserving the density, outliers, and overall shape of a\nscatterplot. To this end, we comprehensively review the literature and select\nseven typical sampling strategies as well as eight representative datasets. We\nthen design four experiments to understand the performance of different\nstrategies in maintaining: 1) region density; 2) class density; 3) outliers;\nand 4) overall shape in the sampling results. The results show that: 1) random\nsampling is preferred for preserving region density; 2) blue noise sampling and\nrandom sampling have comparable performance with the three multi-class sampling\nstrategies in preserving class density; 3) outlier biased density based\nsampling, recursive subdivision based sampling, and blue noise sampling perform\nthe best in keeping outliers; and 4) blue noise sampling outperforms the others\nin maintaining the overall shape of a scatterplot.\n",
    "query": "different sampling methods",
    "docId": 1326180,
    "score": 26.84219741821289,
    "userScore": 2
  },
  {
    "title": "Enhanced sampling methods for molecular dynamics simulations",
    "paperAbstract": "  Enhanced sampling algorithms have emerged as powerful methods to extend the\nutility of molecular dynamics simulations and allow the sampling of larger\nportions of the configuration space of complex systems in a given amount of\nsimulation time. This review aims to present the unifying principles and\ndifferences of many of the computational methods currenly used for enhanced\nsampling in molecular simulations of biomolecules, soft matter and molecular\ncrystals. Indeed, despite the apparent abundance and divergence of such\nmethods, the principles at their core can be boiled down to a relatively\nlimited number of statistical and physical principles. To enable comparisons,\nthe various methods are introduced using similar terminology and notation. We\nthen illustrate in which ways many different methods combine principles from a\nsmaller class of enhanced sampling concepts. This review is intended for\nscientists with an understanding of the basics of molecular dynamics\nsimulations and statistical physics who want a deeper understanding of the\nideas that underlie various enhanced sampling methods and the relationships\nbetween them. This living review is intended to be updated to continue to\nreflect the wealth of sampling methods as they continue to emerge in the\nliterature.\n",
    "query": "different sampling methods",
    "docId": 1602988,
    "score": 26.035198211669922,
    "userScore": 2
  },
  {
    "title": "Sampling Algorithms, from Survey Sampling to Monte Carlo Methods:\n  Tutorial and Literature Review",
    "paperAbstract": "  This paper is a tutorial and literature review on sampling algorithms. We\nhave two main types of sampling in statistics. The first type is survey\nsampling which draws samples from a set or population. The second type is\nsampling from probability distribution where we have a probability density or\nmass function. In this paper, we cover both types of sampling. First, we review\nsome required background on mean squared error, variance, bias, maximum\nlikelihood estimation, Bernoulli, Binomial, and Hypergeometric distributions,\nthe Horvitz-Thompson estimator, and the Markov property. Then, we explain the\ntheory of simple random sampling, bootstrapping, stratified sampling, and\ncluster sampling. We also briefly introduce multistage sampling, network\nsampling, and snowball sampling. Afterwards, we switch to sampling from\ndistribution. We explain sampling from cumulative distribution function, Monte\nCarlo approximation, simple Monte Carlo methods, and Markov Chain Monte Carlo\n(MCMC) methods. For simple Monte Carlo methods, whose iterations are\nindependent, we cover importance sampling and rejection sampling. For MCMC\nmethods, we cover Metropolis algorithm, Metropolis-Hastings algorithm, Gibbs\nsampling, and slice sampling. Then, we explain the random walk behaviour of\nMonte Carlo methods and more efficient Monte Carlo methods, including\nHamiltonian (or hybrid) Monte Carlo, Adler's overrelaxation, and ordered\noverrelaxation. Finally, we summarize the characteristics, pros, and cons of\nsampling methods compared to each other. This paper can be useful for different\nfields of statistics, machine learning, reinforcement learning, and\ncomputational physics.\n",
    "query": "different sampling methods",
    "docId": 1373649,
    "score": 25.964487075805664,
    "userScore": 2
  },
  {
    "title": "Towards Cost-efficient Sampling Methods",
    "paperAbstract": "  The sampling method has been paid much attention in the field of complex\nnetwork in general and statistical physics in particular. This paper presents\ntwo new sampling methods based on the perspective that a small part of vertices\nwith high node degree can possess the most structure information of a network.\nThe two proposed sampling methods are efficient in sampling the nodes with high\ndegree. The first new sampling method is improved on the basis of the\nstratified random sampling method and selects the high degree nodes with higher\nprobability by classifying the nodes according to their degree distribution.\nThe second sampling method improves the existing snowball sampling method so\nthat it enables to sample the targeted nodes selectively in every sampling\nstep. Besides, the two proposed sampling methods not only sample the nodes but\nalso pick the edges directly connected to these nodes. In order to demonstrate\nthe two methods' availability and accuracy, we compare them with the existing\nsampling methods in three commonly used simulation networks that are scale-free\nnetwork, random network, small-world network, and two real networks. The\nexperimental results show that the two proposed sampling methods perform much\nbetter than the compared existing sampling methods in terms of sampling cost\nand obtaining the true network structural characteristics.\n",
    "query": "different sampling methods",
    "docId": 526664,
    "score": 25.672130584716797,
    "userScore": 2
  },
  {
    "title": "Direct sampling methods for inverse elastic scattering problems",
    "paperAbstract": "  We consider the inverse elastic scattering of incident plane compressional\nand shear waves from the knowledge of the far field patterns. Specifically,\nthree direct sampling methods for location and shape reconstruction are\nproposed using the different component of the far field patterns. Only inner\nproducts are involved in the computation, thus the novel sampling methods are\nvery simple and fast to be implemented. With the help of the factorization of\nthe far field operator, we give a lower bound of the proposed indicator\nfunctionals for sampling points inside the scatterers. While for the sampling\npoints outside the scatterers, we show that the indicator functionals decay\nlike the Bessel functions as the sampling point goes away from the boundary of\nthe scatterers. We also show that the proposed indicator functionals\ncontinuously dependent on the far field patterns, which further implies that\nthe novel sampling methods are extremely stable with respect to data error. For\nthe case when the observation directions are restricted into the limited\naperture, we firstly introduce some data retrieval techniques to obtain those\ndata that can not be measured directly and then use the proposed direct\nsampling methods for location and shape reconstructions. Finally, some\nnumerical simulations in two dimensions are conducted with noisy data, and the\nresults further verify the effectiveness and robustness of the proposed\nsampling methods, even for multiple multiscale cases and limited-aperture\nproblems.\n",
    "query": "different sampling methods",
    "docId": 907636,
    "score": 24.87826156616211,
    "userScore": 2
  },
  {
    "title": "Study of sampling methods in sentiment analysis of imbalanced data",
    "paperAbstract": "  This work investigates the application of sampling methods for sentiment\nanalysis on two different highly imbalanced datasets. One dataset contains\nonline user reviews from the cooking platform Epicurious and the other contains\ncomments given to the Planned Parenthood organization. In both these datasets,\nthe classes of interest are rare. Word n-grams were used as features from these\ndatasets. A feature selection technique based on information gain is first\napplied to reduce the number of features to a manageable space. A number of\ndifferent sampling methods were then applied to mitigate the class imbalance\nproblem which are then analyzed.\n",
    "query": "different sampling methods",
    "docId": 1484437,
    "score": 24.702167510986328,
    "userScore": 1
  },
  {
    "title": "Research into the sampling methods of digital beam position measurement",
    "paperAbstract": "  BPM (Beam Position Measurement) system is one of the most important beam\ndiagnostic instruments in accelerators. A fully digital BPM (DBPM) has been\ndesigned for SSRF (Shanghai Synchrotron Radiation Facility). As\nAnalog-to-Digital Converter (ADC) is one crucial part in the DBPM system, the\nsampling methods should be studied to achieve optimum performance. We\nimplemented different sampling modes and compared them through tests.\nMeanwhile, long term variation among four sampling channels is another concern,\nwhich would introduce errors in beam position measurement. We designed an\ninterleaved distribution scheme to address this issue. To evaluate these\nsampling methods, we conducted commissioning tests with the beam in SSRF. Test\nresults indicate that with proper sampling methods, a turn-by-turn (TBT)\nposition resolution better than 1 um is achieved, and the slow-acquisition (SA)\nposition resolution is enhanced from 4.28 {\\mu}m to 0.17 {\\mu}m successfully\nwith interleaved distribution applied, both beyond requirement.\n",
    "query": "different sampling methods",
    "docId": 1182538,
    "score": 24.51502799987793,
    "userScore": 1
  },
  {
    "title": "Coupling methods for multistage sampling",
    "paperAbstract": "  Multistage sampling is commonly used for household surveys when there exists\nno sampling frame, or when the population is scattered over a wide area.\nMultistage sampling usually introduces a complex dependence in the selection of\nthe final units, which makes asymptotic results quite difficult to prove. In\nthis work, we consider multistage sampling with simple random without\nreplacement sampling at the first stage, and with an arbitrary sampling design\nfor further stages. We consider coupling methods to link this sampling design\nto sampling designs where the primary sampling units are selected\nindependently. We first generalize a method introduced by [Magyar Tud. Akad.\nMat. Kutat\\'{o} Int. K\\\"{o}zl. 5 (1960) 361-374] to get a coupling with\nmultistage sampling and Bernoulli sampling at the first stage, which leads to a\ncentral limit theorem for the Horvitz--Thompson estimator. We then introduce a\nnew coupling method with multistage sampling and simple random with replacement\nsampling at the first stage. When the first-stage sampling fraction tends to\nzero, this method is used to prove consistency of a with-replacement bootstrap\nfor simple random without replacement sampling at the first stage, and\nconsistency of bootstrap variance estimators for smooth functions of totals.\n",
    "query": "different sampling methods",
    "docId": 678517,
    "score": 24.393896102905273,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "Are Outlier Detection Methods Resilient to Sampling?",
    "paperAbstract": "  Outlier detection is a fundamental task in data mining and has many\napplications including detecting errors in databases. While there has been\nextensive prior work on methods for outlier detection, modern datasets often\nhave sizes that are beyond the ability of commonly used methods to process the\ndata within a reasonable time. To overcome this issue, outlier detection\nmethods can be trained over samples of the full-sized dataset. However, it is\nnot clear how a model trained on a sample compares with one trained on the\nentire dataset. In this paper, we introduce the notion of resilience to\nsampling for outlier detection methods. Orthogonal to traditional performance\nmetrics such as precision/recall, resilience represents the extent to which the\noutliers detected by a method applied to samples from a sampling scheme matches\nthose when applied to the whole dataset. We propose a novel approach for\nestimating the resilience to sampling of both individual outlier methods and\ntheir ensembles. We performed an extensive experimental study on synthetic and\nreal-world datasets where we study seven diverse and representative outlier\ndetection methods, compare results obtained from samples versus those obtained\nfrom the whole datasets and evaluate the accuracy of our resilience estimates.\nWe observed that the methods are not equally resilient to a given sampling\nscheme and it is often the case that careful joint selection of both the\nsampling scheme and the outlier detection method is necessary. It is our hope\nthat the paper initiates research on designing outlier detection algorithms\nthat are resilient to sampling.\n",
    "query": "different sampling methods",
    "docId": 1157812,
    "score": 24.334787368774414,
    "userScore": 2
  },
  {
    "title": "On entropy in eulerian thermodynamics",
    "paperAbstract": "  To the student of thermodynamics the most difficult subject is entropy. In\nthis paper we examine the actual, practical application of entropy to two\nsimple systems, the homogeneous slab with fixed boundary values of the\ntemperature, and an isolated atmosphere in the presence of the static\ngravitational field. The first gives valuable insight into the nature of\nentropy that is subsequently applied to the second system.\n  It is a basic tenet of thermodynamics that the equilibrium of an extended,\nhomogeneous and isolated system is characterized by a uniform temperature\ndistribution and it is a strongly held belief that this remains true in the\npresence of gravity. We find that this is consistent with the equations of\nextended thermodynamics but that entropy enters in an essential way. The\nprinciple of equivalence takes on a new aspect.\n",
    "query": "entropy and thermodynamics",
    "docId": 267908,
    "score": 31.056026458740234,
    "userScore": 3,
    "inAnnoy": true
  },
  {
    "title": "Thermodynamics from relative entropy",
    "paperAbstract": "  Thermodynamics is usually developed starting from entropy and the maximum\nentropy principle. We investigate here to what extent one can replace entropy\nwith relative entropy which has several advantages, for example in the context\nof local quantum field theory. We find that the principle of maximum entropy\ncan be replaced by a principle of minimum expected relative entropy. Various\nensembles and their thermodynamic potentials can be defined through relative\nentropy. We also show that thermal fluctuations are in fact governed by a\nrelative entropy. Furthermore we reformulate the third law of thermodynamics\nusing relative entropy only.\n",
    "query": "entropy and thermodynamics",
    "docId": 1278303,
    "score": 30.103422164916992,
    "userScore": 2
  },
  {
    "title": "Positive and negative entropy production in thermodynamics systems",
    "paperAbstract": "  This article presents a heuristic combination of the local and global\nformulations of the second law of thermodynamics that suggests the possibility\nof theoretical existence of thermodynamics processes with positive and negative\nentropy production.Such processes may exhibit entropy couplings that reveal an\nunusual behavior from the point of view of conventional thermodynamics.\n",
    "query": "entropy and thermodynamics",
    "docId": 101265,
    "score": 28.98822593688965,
    "userScore": 2
  },
  {
    "title": "No Entropy Production in Quantum Thermodynamics",
    "paperAbstract": "  In this work we will show that there exists a fundamental difference between\nmicroscopic quantum thermodynamics and macroscopic classical thermodynamics. It\nwill be proved that the entropy production in quantum thermodynamics always\nvanishes for both closed and open quantum thermodynamic systems. This novel and\nvery surprising result is derived based on the genuine reasoning Clausius used\nto establish the science of thermodynamics in the first place. This result will\ninterestingly lead to define the generalized temperature for any\nnon-equilibrium quantum system.\n",
    "query": "entropy and thermodynamics",
    "docId": 1248170,
    "score": 28.880586624145508,
    "userScore": 2
  },
  {
    "title": "A few words on Entropy, Thermodynamics, and Horizons",
    "paperAbstract": "  We review recent progress in understanding certain aspects of the\nthermodynamics of black holes and other horizons. Our discussion centers on\nvarious ``entropy bounds'' which have been proposed in the literature and on\nthe current understanding of how such bounds are {\\it not} required for the\nsemi-classical consistency of black hole thermodynamics. Instead, consistency\nunder certain extreme circumstances is provided by two effects. The first is\nsimply the exponential enhancement of the rate at which a macrostate with large\nentropy is emitted in any thermal process. The second is a new sense in which\nthe entropy of an ``object'' depends on the observer making the measurement, so\nthat observers crossing the horizon measure a different entropy flux across the\nhorizon than do observers remaining outside. In addition to the review, some\nrecent criticisms are addressed. In particular, additional arguments and\ndetailed numerical calculations showing the observer dependence of entropy are\npresented in a simple model. This observer-dependence may have further\ninteresting implications for the thermodynamics of black holes.\n",
    "query": "entropy and thermodynamics",
    "docId": 2081866,
    "score": 28.56754493713379,
    "userScore": 2
  },
  {
    "title": "The Entropy Anomaly and the Linear Irreversible Thermodynamics",
    "paperAbstract": "  The irreversible currents and entropy production rate of a dilute colloidal\nsuspension are calculated using the linear irreversible thermodynamics and the\nlinear response theory. The \\anomalous\" or \\hidden\" entropy recently discussed\nin the context of the stochastic thermodynamics is fully accounted in these\nclassic frameworks. We show that the two distinct formulations lead to\nidentical results as long as the local equilibrium assumption or, equivalently\nthe linear response theory, is valid.\n",
    "query": "entropy and thermodynamics",
    "docId": 967744,
    "score": 28.43494987487793,
    "userScore": 2
  },
  {
    "title": "The generalized second law of thermodynamics with Barrow entropy",
    "paperAbstract": "  We investigate the validity of the generalized second law of thermodynamics,\napplying Barrow entropy for the horizon entropy. The former arises from the\nfact that the black-hole surface may be deformed due to quantum-gravitational\neffects, quantified by a new exponent $\\Delta$. We calculate the entropy\ntime-variation in a universe filled with the matter and dark energy fluids, as\nwell as the corresponding quantity for the apparent horizon. We show that\nalthough in the case $\\Delta=0$, which corresponds to usual entropy, the sum of\nthe entropy enclosed by the apparent horizon plus the entropy of the horizon\nitself is always a non-decreasing function of time and thus the generalized\nsecond law of thermodynamics is valid, in the case of Barrow entropy this is\nnot true anymore, and the generalized second law of thermodynamics may be\nviolated, depending on the universe evolution. Hence, in order not to have\nviolation, the deformation from standard Bekenstein-Hawking expression should\nbe small as expected.\n",
    "query": "entropy and thermodynamics",
    "docId": 1288053,
    "score": 28.433868408203125,
    "userScore": 2
  },
  {
    "title": "Measuring the Entropy and Testing the Second Law of Thermodynamics",
    "paperAbstract": "  Evidence implies that basic laws of thermodynamics must be tested by\nexperiments. In this paper, an experiment is designed to measure the entropy of\na system with at least one known (measurable) equation of state, especially the\ngas systems. Since the entropy can be measured now, the formulae related to the\nsecond law of thermodynamics can be examined by other experiments.\n",
    "query": "entropy and thermodynamics",
    "docId": 2188899,
    "score": 28.03491973876953,
    "userScore": 3
  },
  {
    "title": "Entropy in the interior of a black hole and thermodynamics",
    "paperAbstract": "  Based on a recent proposal for the volume inside a black hole, we calculate\nthe entropy associated with this volume and show that such entropy is\nproportional to the surface area of the black hole. Together with the\nconsideration of black hole radiation, we find that the thermodynamics\nassociated with the entropy is likely to be caused by the vacuum polarization\nnear the horizon.\n",
    "query": "entropy and thermodynamics",
    "docId": 666139,
    "score": 27.783172607421875,
    "userScore": 3
  },
  {
    "title": "Entropy and time: Thermodynamics of diffusion processes",
    "paperAbstract": "  We give meaning to the first and second laws of thermodynamics in case of\nmesoscopic out-of-equilibrium systems which are driven by diffusion processes.\nThe notion of the entropy production is analyzed. The role of the Helmholtz\nextremum principle is contrasted to that of the more familiar entropy extremum\nprinciples.\n",
    "query": "entropy and thermodynamics",
    "docId": 1944499,
    "score": 27.53847885131836,
    "userScore": 3
  },
  {
    "title": "A Bayesian latent allocation model for clustering compositional data\n  with application to the Great Barrier Reef",
    "paperAbstract": "  Relative abundance is a common metric to estimate the composition of species\nin ecological surveys reflecting patterns of commonness and rarity of\nbiological assemblages. Measurements of coral reef compositions formed by four\ncommunities along Australia's Great Barrier Reef (GBR) gathered between 2012\nand 2017 are the focus of this paper. We undertake the task of finding clusters\nof transect locations with similar community composition and investigate\nchanges in clustering dynamics over time. During these years, an unprecedented\nsequence of extreme weather events (cyclones and coral bleaching) impacted the\n58 surveyed locations. The dependence between constituent parts of a\ncomposition presents a challenge for existing multivariate clustering\napproaches. In this paper, we introduce a finite mixture of Dirichlet\ndistributions with group-specific parameters, where cluster memberships are\ndictated by unobserved latent variables. The inference is carried in a Bayesian\nframework, where MCMC strategies are outlined to sample from the posterior\nmodel. Simulation studies are presented to illustrate the performance of the\nmodel in a controlled setting. The application of the model to the 2012 coral\nreef data reveals that clusters were spatially distributed in similar ways\nacross reefs which indicates a potential influence of wave exposure at the\norigin of coral reef community composition. The number of clusters estimated by\nthe model decreased from four in 2012 to two from 2014 until 2017. Posterior\nprobabilities of transect allocations to the same cluster substantially\nincrease through time showing a potential homogenization of community\ncomposition across the whole GBR. The Bayesian model highlights the diversity\nof coral reef community composition within a coral reef and rapid changes\nacross large spatial scales that may contribute to undermining the future of\nthe GBR's biodiversity.\n",
    "query": "great barrier reef",
    "docId": 1464699,
    "score": 48.288612365722656,
    "userScore": 2
  },
  {
    "title": "Reef-insight: A framework for reef habitat mapping with clustering\n  methods via remote sensing",
    "paperAbstract": "  Environmental damage has been of much concern, particularly coastal areas and\nthe oceans given climate change and drastic effects of pollution and extreme\nclimate events. Our present day analytical capabilities along with the\nadvancements in information acquisition techniques such as remote sensing can\nbe utilized for the management and study of coral reef ecosystems. In this\npaper, we present Reef-insight, an unsupervised machine learning framework that\nfeatures advanced clustering methods and remote sensing for reef community\nmapping. Our framework compares different clustering methods to evaluate them\nfor reef community mapping using remote sensing data. We evaluate four major\nclustering approaches such as k- means, hierarchical clustering, Gaussian\nmixture model, and density-based clustering based on qualitative and visual\nassessment. We utilise remote sensing data featuring Heron reef island region\nin the Great Barrier Reef of Australia. Our results indicate that clustering\nmethods using remote sensing data can well identify benthic and geomorphic\nclusters that are found in reefs when compared to other studies. Our results\nindicate that Reef-insight can generate detailed reef community maps outlining\ndistinct reef habitats and has the potential to enable further insights for\nreef restoration projects. We release our framework as open source software to\nenable its extension to different parts of the world\n",
    "query": "great barrier reef",
    "docId": 1781940,
    "score": 42.41688919067383,
    "userScore": 2
  },
  {
    "title": "Monitoring through many eyes: Integrating disparate datasets to improve\n  monitoring of the Great Barrier Reef",
    "paperAbstract": "  Numerous organisations collect data in the Great Barrier Reef (GBR), but they\nare rarely analysed together due to different program objectives, methods, and\ndata quality. We developed a weighted spatiotemporal Bayesian model and used it\nto integrate image based hard coral data collected by professional and citizen\nscientists, who captured and or classified underwater images. We used the model\nto predict coral cover across the GBR with estimates of uncertainty; thus\nfilling gaps in space and time where no data exist. Additional data increased\nthe models predictive ability by 43 percent, but did not affect model\ninferences about pressures (e.g. bleaching and cyclone damage). Thus, effective\nintegration of professional and high-volume citizen data could enhance the\ncapacity and cost efficiency of monitoring programs. This general approach is\nequally viable for other variables collected in the marine environment or other\necosystems; opening up new opportunities to integrate data and provide pathways\nfor community engagement and stewardship.\n",
    "query": "great barrier reef",
    "docId": 1014444,
    "score": 41.839149475097656,
    "userScore": 3
  },
  {
    "title": "Bayesreef: A Bayesian inference framework for modelling reef growth in\n  response to environmental change and biological dynamics",
    "paperAbstract": "  Estimating the impact of environmental processes on vertical reef development\nin geological time is a very challenging task. pyReef-Core is a deterministic\ncarbonate stratigraphic forward model designed to simulate the key biological\nand environmental processes that determine vertical reef accretion and\nassemblage changes in fossil reef drill cores. We present a Bayesian framework\ncalled Bayesreef for the estimation and uncertainty quantification of\nparameters in pyReef-Core that represent environmental conditions affecting the\ngrowth of coral assemblages on geological timescales. We demonstrate the\nexistence of multimodal posterior distributions and investigate the challenges\nof sampling using Markov chain Monte-Carlo (MCMC) methods, which includes\nparallel tempering MCMC. We use synthetic reef-core to investigate fundamental\nissues and then apply the methodology to a selected reef-core from the Great\nBarrier Reef in Australia. The results show that Bayesreef accurately estimates\nand provides uncertainty quantification of the selected parameters that\nrepresent the environment and ecological conditions in pyReef-Core. Bayesreef\nprovides insights into the complex posterior distributions of parameters in\npyReef-Core, which provides the groundwork for future research in this area.\n",
    "query": "great barrier reef",
    "docId": 1011909,
    "score": 37.486854553222656,
    "userScore": 2
  },
  {
    "title": "A Real-time Edge-AI System for Reef Surveys",
    "paperAbstract": "  Crown-of-Thorn Starfish (COTS) outbreaks are a major cause of coral loss on\nthe Great Barrier Reef (GBR) and substantial surveillance and control programs\nare ongoing to manage COTS populations to ecologically sustainable levels. In\nthis paper, we present a comprehensive real-time machine learning-based\nunderwater data collection and curation system on edge devices for COTS\nmonitoring. In particular, we leverage the power of deep learning-based object\ndetection techniques, and propose a resource-efficient COTS detector that\nperforms detection inferences on the edge device to assist marine experts with\nCOTS identification during the data collection phase. The preliminary results\nshow that several strategies for improving computational efficiency (e.g.,\nbatch-wise processing, frame skipping, model input size) can be combined to run\nthe proposed detection model on edge hardware with low resource consumption and\nlow information loss.\n",
    "query": "great barrier reef",
    "docId": 1691310,
    "score": 32.85376739501953,
    "userScore": 2
  },
  {
    "title": "OysterSim: Underwater Simulation for Enhancing Oyster Reef Monitoring",
    "paperAbstract": "  Oysters are the living vacuum cleaners of the oceans. There is an exponential\ndecline in the oyster population due to over-harvesting. With the current\ndevelopment of the automation and AI, robots are becoming an integral part of\nthe environmental monitoring process that can be also utilized for oyster reef\npreservation. Nevertheless, the underwater environment poses many difficulties,\nboth from the practical - dangerous and time consuming operations, and the\ntechnical perspectives - distorted perception and unreliable navigation. To\nthis end, we present a simulated environment that can be used to improve oyster\nreef monitoring. The simulated environment can be used to create\nphoto-realistic image datasets with multiple sensor data and ground truth\nlocation of a remotely operated vehicle(ROV). Currently, there are no\nphoto-realistic image datasets for oyster reef monitoring. Thus, we want to\nprovide a new benchmark suite to the underwater community.\n",
    "query": "great barrier reef",
    "docId": 1715110,
    "score": 29.420106887817383,
    "userScore": 1
  },
  {
    "title": "A Cooperative Dynamic Task Assignment Framework for COTSBot AUVs",
    "paperAbstract": "  This paper presents a cooperative dynamic task assignment framework for a\ncertain class of Autonomous Underwater Vehicles (AUVs) employed to control\noutbreak of Crown-Of-Thorns Starfish (COTS) in Australia's Great Barrier Reef.\nThe problem of monitoring and controlling the COTS is transcribed into a\nconstrained task assignment problem in which eradicating clusters of COTS, by\nthe injection system of COTSbot AUVs, is considered as a task. A probabilistic\nmap of the operating environment including seabed terrain, clusters of COTS,\nand coastlines is constructed. Then, a novel heuristic algorithm called\nHeuristic Fleet Cooperation (HFC) is developed to provide a cooperative\ninjection of the COTSbot AUVs to the maximum possible COTS in an assigned\nmission time. Extensive simulation studies together with quantitative\nperformance analysis are conducted to demonstrate the effectiveness and\nrobustness of the proposed cooperative task assignment algorithm in eradicating\nthe COTS in the Great Barrier Reef.\n",
    "query": "great barrier reef",
    "docId": 1407438,
    "score": 28.617843627929688,
    "userScore": 1
  },
  {
    "title": "Bistability in a differential equation model of oyster reef height and\n  sediment accumulation",
    "paperAbstract": "  Native oyster populations in Chesapeake Bay have been the focus of three\ndecades of restoration attempts, which have generally failed to rebuild the\npopulations and oyster reef structure. Recent restoration successes and field\nexperiments suggest that high-relief reefs offset heavy sedimentation and\npromote oyster survival, disease resistance and growth, in contrast to\nlow-relief reefs which degrade in just a few years. These findings suggest the\nexistence of alternative stable states in oyster reef populations. We developed\na mathematical model consisting of three differential equations that represent\nvolumes of live oysters, dead oyster shells (= accreting reef), and sediment.\nBifurcation analysis and numerical simulations demonstrated that multiple\nnonnegative equilibria can exist for live oyster, accreting reef and sediment\nvolume at an ecologically reasonable range of parameter values; the initial\nheight of oyster reefs determined which equilibrium was reached. This\ninvestigation thus provides a conceptual framework for alternative stable\nstates in native oyster populations, and can be used as a tool to improve the\nlikelihood of success in restoration efforts.\n",
    "query": "great barrier reef",
    "docId": 244160,
    "score": 28.456119537353516,
    "userScore": 1
  },
  {
    "title": "Topological descriptors for coral reef resilience using a stochastic\n  spatial model",
    "paperAbstract": "  A complex interplay between species governs the evolution of spatial patterns\nin ecology. An open problem in the biological sciences is characterizing\nspatio-temporal data and understanding how changes at the local scale affect\nglobal dynamics/behavior. We present a toolkit of multiscale methods and use\nthem to analyze coral reef resilience and dynamics.Here, we extend a\nwell-studied temporal mathematical model of coral reef dynamics to include\nstochastic and spatial interactions and then generate data to study different\necological scenarios. We present descriptors to characterize patterns in\nheterogeneous spatio-temporal data surpassing spatially averaged measures. We\napply these descriptors to simulated coral data and demonstrate the utility of\ntwo topological data analysis techniques--persistent homology and zigzag\npersistence--for characterizing the spatiotemporal evolution of reefs and\ngenerating insight into mechanisms of reef resilience. We show that the\nintroduction of local competition between species leads to the appearance of\ncoral clusters in the reef. Furthermore, we use our analyses to distinguish the\ntemporal dynamics that stem from different initial configurations of coral,\nshowing that the neighborhood composition of coral sites determines their\nlong-term survival. Finally, we use zigzag persistence to quantify spatial\nbehavior in the metastable regime as the level of fish grazing on algae varies\nand determine which spatial configurations protect coral from extinction in\ndifferent environments.\n",
    "query": "great barrier reef",
    "docId": 1714689,
    "score": 27.578990936279297,
    "userScore": 2
  },
  {
    "title": "Integrative omics framework for characterization of coral reef\n  ecosystems from the Tara Pacific expedition",
    "paperAbstract": "  Coral reef science is a fast-growing field propelled by the need to better\nunderstand coral health and resilience to devise strategies to slow reef loss\nresulting from environmental stresses. Key to coral resilience are the\nsymbiotic interactions established within a complex holobiont, i.e. the\nmultipartite assemblages comprising the host coral organism, endosymbiotic\ndinoflagellates, bacteria, archaea, fungi, and viruses. Tara Pacific is an\nambitious project built upon the experience of previous Tara Oceans\nexpeditions, and leveraging state-of-the-art sequencing technologies and\nanalyses to dissect the biodiversity and biocomplexity of the coral holobiont\nscreened across most archipelagos spread throughout the entire Pacific Ocean.\nHere we detail the Tara Pacific workflow for multi-omics data generation, from\nsample handling to nucleotide sequence data generation and deposition. This\nunique multidimensional framework also includes a large amount of concomitant\nmetadata collected side-by-side that provide new assessments of coral reef\nbiodiversity including micro-biodiversity and shape future investigations of\ncoral reef dynamics and their fate in the Anthropocene.\n",
    "query": "great barrier reef",
    "docId": 1678373,
    "score": 27.46497344970703,
    "userScore": 1
  },
  {
    "title": "Bias in Machine Learning -- What is it Good for?",
    "paperAbstract": "  In public media as well as in scientific publications, the term \\emph{bias}\nis used in conjunction with machine learning in many different contexts, and\nwith many different meanings. This paper proposes a taxonomy of these different\nmeanings, terminology, and definitions by surveying the, primarily scientific,\nliterature on machine learning. In some cases, we suggest extensions and\nmodifications to promote a clear terminology and completeness. The survey is\nfollowed by an analysis and discussion on how different types of biases are\nconnected and depend on each other. We conclude that there is a complex\nrelation between bias occurring in the machine learning pipeline that leads to\na model, and the eventual bias of the model (which is typically related to\nsocial discrimination). The former bias may or may not influence the latter, in\na sometimes bad, and sometime good way.\n",
    "query": "what is bias in machine learning",
    "docId": 1265456,
    "score": 42.610408782958984,
    "userScore": 1,
    "inAnnoy": true
  },
  {
    "title": "Underestimation Bias and Underfitting in Machine Learning",
    "paperAbstract": "  Often, what is termed algorithmic bias in machine learning will be due to\nhistoric bias in the training data. But sometimes the bias may be introduced\n(or at least exacerbated) by the algorithm itself. The ways in which algorithms\ncan actually accentuate bias has not received a lot of attention with\nresearchers focusing directly on methods to eliminate bias - no matter the\nsource. In this paper we report on initial research to understand the factors\nthat contribute to bias in classification algorithms. We believe this is\nimportant because underestimation bias is inextricably tied to regularization,\ni.e. measures to address overfitting can accentuate bias.\n",
    "query": "what is bias in machine learning",
    "docId": 1288847,
    "score": 38.028564453125,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "Understanding Bias in Machine Learning",
    "paperAbstract": "  Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.\n",
    "query": "what is bias in machine learning",
    "docId": 1171904,
    "score": 37.44269561767578,
    "userScore": 3,
    "inAnnoy": true
  },
  {
    "title": "Contextuality and inductive bias in quantum machine learning",
    "paperAbstract": "  Generalisation in machine learning often relies on the ability to encode\nstructures present in data into an inductive bias of the model class. To\nunderstand the power of quantum machine learning, it is therefore crucial to\nidentify the types of data structures that lend themselves naturally to quantum\nmodels. In this work we look to quantum contextuality -- a form of\nnonclassicality with links to computational advantage -- for answers to this\nquestion. We introduce a framework for studying contextuality in machine\nlearning, which leads us to a definition of what it means for a learning model\nto be contextual. From this, we connect a central concept of contextuality,\ncalled operational equivalence, to the ability of a model to encode a linearly\nconserved quantity in its label space. A consequence of this connection is that\ncontextuality is tied to expressivity: contextual model classes that encode the\ninductive bias are generally more expressive than their noncontextual\ncounterparts. To demonstrate this, we construct an explicit toy learning\nproblem -- based on learning the payoff behaviour of a zero-sum game -- for\nwhich this is the case. By leveraging tools from geometric quantum machine\nlearning, we then describe how to construct quantum learning models with the\nassociated inductive bias, and show through our toy problem that they\noutperform their corresponding classical surrogate models. This suggests that\nunderstanding learning problems of this form may lead to useful insights about\nthe power of quantum machine learning.\n",
    "query": "what is bias in machine learning",
    "docId": 1786299,
    "score": 37.10578918457031,
    "userScore": 2
  },
  {
    "title": "Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey",
    "paperAbstract": "  This paper provides a comprehensive survey of bias mitigation methods for\nachieving fairness in Machine Learning (ML) models. We collect a total of 341\npublications concerning bias mitigation for ML classifiers. These methods can\nbe distinguished based on their intervention procedure (i.e., pre-processing,\nin-processing, post-processing) and the technology they apply. We investigate\nhow existing bias mitigation methods are evaluated in the literature. In\nparticular, we consider datasets, metrics and benchmarking. Based on the\ngathered insights (e.g., what is the most popular fairness metric? How many\ndatasets are used for evaluating bias mitigation methods?). We hope to support\npractitioners in making informed choices when developing and evaluating new\nbias mitigation methods.\n",
    "query": "what is bias in machine learning",
    "docId": 1682966,
    "score": 34.6245231628418,
    "userScore": 3
  },
  {
    "title": "Vulnerability Under Adversarial Machine Learning: Bias or Variance?",
    "paperAbstract": "  Prior studies have unveiled the vulnerability of the deep neural networks in\nthe context of adversarial machine learning, leading to great recent attention\ninto this area. One interesting question that has yet to be fully explored is\nthe bias-variance relationship of adversarial machine learning, which can\npotentially provide deeper insights into this behaviour. The notion of bias and\nvariance is one of the main approaches to analyze and evaluate the\ngeneralization and reliability of a machine learning model. Although it has\nbeen extensively used in other machine learning models, it is not well explored\nin the field of deep learning and it is even less explored in the area of\nadversarial machine learning.\n  In this study, we investigate the effect of adversarial machine learning on\nthe bias and variance of a trained deep neural network and analyze how\nadversarial perturbations can affect the generalization of a network. We derive\nthe bias-variance trade-off for both classification and regression applications\nbased on two main loss functions: (i) mean squared error (MSE), and (ii)\ncross-entropy. Furthermore, we perform quantitative analysis with both\nsimulated and real data to empirically evaluate consistency with the derived\nbias-variance tradeoffs. Our analysis sheds light on why the deep neural\nnetworks have poor performance under adversarial perturbation from a\nbias-variance point of view and how this type of perturbation would change the\nperformance of a network. Moreover, given these new theoretical findings, we\nintroduce a new adversarial machine learning algorithm with lower computational\ncomplexity than well-known adversarial machine learning strategies (e.g., PGD)\nwhile providing a high success rate in fooling deep neural networks in lower\nperturbation magnitudes.\n",
    "query": "what is bias in machine learning",
    "docId": 1327860,
    "score": 33.99203872680664,
    "userScore": 2
  },
  {
    "title": "A Survey on Bias and Fairness in Machine Learning",
    "paperAbstract": "  With the widespread use of AI systems and applications in our everyday lives,\nit is important to take fairness issues into consideration while designing and\nengineering these types of systems. Such systems can be used in many sensitive\nenvironments to make important and life-changing decisions; thus, it is crucial\nto ensure that the decisions do not reflect discriminatory behavior toward\ncertain groups or populations. We have recently seen work in machine learning,\nnatural language processing, and deep learning that addresses such challenges\nin different subdomains. With the commercialization of these systems,\nresearchers are becoming aware of the biases that these applications can\ncontain and have attempted to address them. In this survey we investigated\ndifferent real-world applications that have shown biases in various ways, and\nwe listed different sources of biases that can affect AI applications. We then\ncreated a taxonomy for fairness definitions that machine learning researchers\nhave defined in order to avoid the existing bias in AI systems. In addition to\nthat, we examined different domains and subdomains in AI showing what\nresearchers have observed with regard to unfair outcomes in the\nstate-of-the-art methods and how they have tried to address them. There are\nstill many future directions and solutions that can be taken to mitigate the\nproblem of bias in AI systems. We are hoping that this survey will motivate\nresearchers to tackle these issues in the near future by observing existing\nwork in their respective fields.\n",
    "query": "what is bias in machine learning",
    "docId": 1167805,
    "score": 33.990745544433594,
    "userScore": 2
  },
  {
    "title": "On Adversarial Bias and the Robustness of Fair Machine Learning",
    "paperAbstract": "  Optimizing prediction accuracy can come at the expense of fairness. Towards\nminimizing discrimination against a group, fair machine learning algorithms\nstrive to equalize the behavior of a model across different groups, by imposing\na fairness constraint on models. However, we show that giving the same\nimportance to groups of different sizes and distributions, to counteract the\neffect of bias in training data, can be in conflict with robustness. We analyze\ndata poisoning attacks against group-based fair machine learning, with the\nfocus on equalized odds. An adversary who can control sampling or labeling for\na fraction of training data, can reduce the test accuracy significantly beyond\nwhat he can achieve on unconstrained models. Adversarial sampling and\nadversarial labeling attacks can also worsen the model's fairness gap on test\ndata, even though the model satisfies the fairness constraint on training data.\nWe analyze the robustness of fair machine learning through an empirical\nevaluation of attacks on multiple algorithms and benchmark datasets.\n",
    "query": "what is bias in machine learning",
    "docId": 1303183,
    "score": 33.949989318847656,
    "userScore": 3
  },
  {
    "title": "Bias Discovery in Machine Learning Models for Mental Health",
    "paperAbstract": "  Fairness and bias are crucial concepts in artificial intelligence, yet they\nare relatively ignored in machine learning applications in clinical psychiatry.\nWe computed fairness metrics and present bias mitigation strategies using a\nmodel trained on clinical mental health data. We collected structured data\nrelated to the admission, diagnosis, and treatment of patients in the\npsychiatry department of the University Medical Center Utrecht. We trained a\nmachine learning model to predict future administrations of benzodiazepines on\nthe basis of past data. We found that gender plays an unexpected role in the\npredictions-this constitutes bias. Using the AI Fairness 360 package, we\nimplemented reweighing and discrimination-aware regularization as bias\nmitigation strategies, and we explored their implications for model\nperformance. This is the first application of bias exploration and mitigation\nin a machine learning model trained on real clinical psychiatry data.\n",
    "query": "what is bias in machine learning",
    "docId": 1656505,
    "score": 33.2841911315918,
    "userScore": 2
  },
  {
    "title": "The Futility of Bias-Free Learning and Search",
    "paperAbstract": "  Building on the view of machine learning as search, we demonstrate the\nnecessity of bias in learning, quantifying the role of bias (measured relative\nto a collection of possible datasets, or more generally, information resources)\nin increasing the probability of success. For a given degree of bias towards a\nfixed target, we show that the proportion of favorable information resources is\nstrictly bounded from above. Furthermore, we demonstrate that bias is a\nconserved quantity, such that no algorithm can be favorably biased towards many\ndistinct targets simultaneously. Thus bias encodes trade-offs. The probability\nof success for a task can also be measured geometrically, as the angle of\nagreement between what holds for the actual task and what is assumed by the\nalgorithm, represented in its bias. Lastly, finding a favorably biasing\ndistribution over a fixed set of information resources is provably difficult,\nunless the set of resources itself is already favorable with respect to the\ngiven task and algorithm.\n",
    "query": "what is bias in machine learning",
    "docId": 1150546,
    "score": 32.31707763671875,
    "userScore": 2
  },
  {
    "title": "Multiscale Mechanical Consequences of Ocean Acidification for Cold-Water\n  Corals",
    "paperAbstract": "  Ocean acidification is a threat to deep-sea corals and could lead to dramatic\nand rapid loss of the reef framework habitat they build. Weakening of\nstructurally critical parts of the coral reef framework can lead to physical\nhabitat collapse on an ecosystem scale, reducing the potential for biodiversity\nsupport. The mechanism underpinning crumbling and collapse of corals can be\ndescribed via a combination of laboratory-scale experiments and mathematical\nand computational models. We synthesise data from electron back-scatter\ndiffraction, micro-computed tomography, and micromechanical experiments,\nsupplemented by molecular dynamics and continuum micromechanics simulations to\npredict failure of coral structures under increasing porosity and dissolution.\nResults reveal remarkable mechanical properties of cold-water coral skeletons\nof 462 MPa compressive strength and 45-67 GPa stiffness. This is 10 times\nstronger than concrete, twice as strong than ultrahigh performance fibre\nreinforced concrete, or nacre. Contrary to what would be expected, CWCs\nskeletons retain their strength despite a loss of stiffness and even when\nsynthesised under future oceanic conditions. Our models capture the impact of\ncorrosive waters on exposed skeletons and illustrate how small modifications in\ntheir skeleton lead to significantly increased risk of crumbling coral habitat.\nThis new understanding, combined with projections of how seawater chemistry\nwill change over the coming decades, will help support future conservation and\nmanagement efforts of these vulnerable marine ecosystems by identifying which\necosystems are at risk and when they will be at risk, allowing assessment of\nthe impact upon associated biodiversity.\n",
    "query": "Ocean acidification",
    "docId": 1539844,
    "score": 36.28349304199219,
    "userScore": 3
  },
  {
    "title": "Modeling the seasonal variability and the governing factors of Ocean\n  Acidification over the Bay of Bengal region",
    "paperAbstract": "  The Bay of Bengal (BoB) is a high recipient of freshwater flux from rivers\nand precipitation, making the region strongly stratified. The strong\nstratification results in a thick barrier layer formation, which inhibits\nvertical mixing making this region a low-productive zone. In the present study,\nwe attempt to model the pH of the BoB region and understand the role of\ndifferent governing factors such as sea-surface temperature (SST), sea-surface\nsalinity (SSS), dissolved inorganic carbon (DIC), and total alkalinity (TALK)\non the seasonality of sea-surface pH. We run a set of sensitivity experiments\nto understand the role of each of the governing factors. The results show that\nthe SST, SSS, and DIC are the principal drivers affecting the sea-surface pH,\nwhile TALK plays a buffering role. The SST and DIC are consistently found to be\nopposite to each other. The pre-monsoon season (MAM) has shown to have an\nalmost equal contribution from all the drivers. In the pre-monsoon season, the\nSST and DIC are balanced by TALK and SSS. The role of SSS is significantly\ndominant in the second half of the year. Both SST and SSS counter the role of\nDIC in the southwest monsoon season. The strong stratification plays an\nessential role in modulating the pH of the BoB region. The thickness of the\nbarrier layer formed in the sub-surface layers positively affects the\nsea-surface pH. The northern BoB is found to be more alkaline than the southern\nBoB. Our study highlights the complexity of ocean acidification in the BoB\nregion compared to the other part of the world ocean.\n",
    "query": "Ocean acidification",
    "docId": 1661826,
    "score": 35.88319396972656,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "Seawater pH and Anthropogenic Carbon Dioxide",
    "paperAbstract": "  In 2005, the Royal Society published a report titled \"Ocean acidification due\nto increasing atmospheric carbon dioxide\". The report's principal\nconclusion-that average ocean pH could decrease by 0.5 units by 2100-is\ndemonstrated here to be consistent with a linear extrapolation of very limited\ndata. It is also shown that current understanding of ocean mixing, and of the\nrelationship between pH and atmospheric carbon dioxide concentration, cannot\njustify such an extrapolation.\n",
    "query": "Ocean acidification",
    "docId": 89175,
    "score": 26.66083526611328,
    "userScore": 2
  },
  {
    "title": "Towards a Physically Motivated Planetary Accounting Framework",
    "paperAbstract": "  In this work we present a physically motivated planetary Accounting Framework\nfor the Earth System. We show that the impact of the human activity in terms of\nthe Planetary Boundary variables can be accounted for in our Landau-Ginzburg\nphase transition physical formulation. We then use the interaction between\nclimate change and ocean acidification mechanisms to exemplify the relation of\nthe concentration and flux of substances of the Planetary Boundaries variables,\nas proposed by the accounting framework of Kate and Newman, with the underlying\nthermodynamical transformation, quantifiable by the Landau-Ginzburg inspired\nmodel. In this work we present a physically motivated planetary Accounting\nFramework for the Earth System. We show that the impact of the human activity\nin terms of the Planetary Boundary variables can be accounted for in our\nLandau-Ginzburg phase transition physical formulation. We then use the\ninteraction between climate change and ocean acidification mechanisms to\nexemplify the relation of the concentration and flux of substances of the\nPlanetary Boundaries variables, as proposed by the accounting framework of Kate\nand Newman, with the underlying thermodynamical transformation, quantifiable by\nthe Landau-Ginzburg inspired model.\n",
    "query": "Ocean acidification",
    "docId": 1155071,
    "score": 24.393905639648438,
    "userScore": 1
  },
  {
    "title": "Predictive Model for Gross Community Production Rate of Coral Reefs\n  using Ensemble Learning Methodologies",
    "paperAbstract": "  Coral reefs play a vital role in maintaining the ecological balance of the\nmarine ecosystem. Various marine organisms depend on coral reefs for their\nexistence and their natural processes. Coral reefs provide the necessary\nhabitat for reproduction and growth for various exotic species of the marine\necosystem. In this article, we discuss the most important parameters which\ninfluence the lifecycle of coral and coral reefs such as ocean acidification,\ndeoxygenation and other physical parameters such as flow rate and surface area.\nOcean acidification depends on the amount of dissolved Carbon dioxide (CO2).\nThis is due to the release of H+ ions upon the reaction of the dissolved CO2\ngases with the calcium carbonate compounds in the ocean. Deoxygenation is\nanother problem that leads to hypoxia which is characterized by a lesser amount\nof dissolved oxygen in water than the required amount for the existence of\nmarine organisms. In this article, we highlight the importance of physical\nparameters such as flow rate which influence gas exchange, heat dissipation,\nbleaching sensitivity, nutrient supply, feeding, waste and sediment removal,\ngrowth and reproduction. In this paper, we also bring out these important\nparameters and propose an ensemble machine learning-based model for analyzing\nthese parameters and provide better rates that can help us to understand and\nsuitably improve the ocean composition which in turn can eminently improve the\nsustainability of the marine ecosystem, mainly the coral reefs\n",
    "query": "Ocean acidification",
    "docId": 1558106,
    "score": 24.381431579589844,
    "userScore": 1
  },
  {
    "title": "Ocean Terracing",
    "paperAbstract": "  Artworks can improve humanity ability to apply macro-engineering principles\nwhich skirt or correct oceanographic problems impairing the economic usefulness\nof coastal land, the overhead airshed, and seawater temperature and salinity\nstability. A new form of Art, Ocean Art, is here proposed which centers on\ndeliberate terracing of appropriate regions of our world ocean; a proposed\nexample of macro-engineered useful Ocean Art is the technically possible 21-st\nCentury terracing of the Mediterranean Sea. Ocean Art is applicable worldwide\nto places that might be practically improved by its judicious employment. Such\nOcean Art may constitute an entirely unique category of solutions to coastal\ndisaster prevention planning.\n",
    "query": "Ocean acidification",
    "docId": 2199638,
    "score": 24.23366928100586,
    "userScore": 1
  },
  {
    "title": "Ocean Circulation on Enceladus With a High Versus Low Salinity Ocean",
    "paperAbstract": "  Previous studies that have considered the ocean circulation on Enceladus have\ngenerally assumed the salinity to be Earth-like. However, according to\nobservations and geochemical constraints, the salinity of Enceladus' ocean is\nlikely to be lower, and importantly, it is probably low enough to reverse the\nsign of thermal expansivity. We investigate the ocean circulation and\nstratification of Enceladus' ocean using a combination of theoretical arguments\nand simulations using the MITgcm. We find that, if the salinity is high, the\nwhole ocean is unstratified, and convection dominates the entire ocean.\nHowever, if the salinity is low enough, there exists a stratified layer in the\nupper ocean, whose thickness depends on the magnitude of the turbulent vertical\ndiffusivity, which remains poorly constrained. Such a layer can suppress the\nvertical flux of heat and tracers, thereby affecting the heat flux to the ice\nshell and leading to a vertical tracer mixing time scale across the stratified\nlayer of at least hundreds of years. This time scale is inconsistent with a\nprevious estimate of vertical ocean mixing of several years, based on the size\nof detected silica nanoparticles in the plumes, leading us to conclude that\neither the salinity of Enceladus' ocean is higher than previously suggested or\nthe interpretation of silica nanoparticle observations has to be reconsidered.\n",
    "query": "Ocean acidification",
    "docId": 1414272,
    "score": 24.065994262695312,
    "userScore": 1
  },
  {
    "title": "Metered reagent injection into microfluidic continuous flow sampling for\n  conductimetric ocean dissolved inorganic carbon sensing",
    "paperAbstract": "  Continuous and autonomous measurement of total dissolved inorganic carbon\n(TCO2) in the oceans is critical for modelling important climate change factors\nsuch as ocean uptake of atmospheric CO2 and ocean acidification. Miniaturised\nchemical analysis systems are therefore required which are small enough for\nintegration into the existing Argo ocean float network for long-term unattended\ndepth profiling of dissolved CO2 with the accuracy of laboratory bench\nanalysers. A microfluidic conductivity-based approach offers the potential for\nsuch miniaturisation. Reagent payload for >3 yr operation is a critical\nparameter. The precise injection of acid into sample, liberating CO2 from\nseawater, is addressed here. Laser etched microfluidic snake channel\nrestrictors and asymmetric Y meters were fabricated to adjust the metering\nratio between seawater and acid simulants. Laser etching conditions were varied\nto create a range of channel dimensions down to ~75 microns. Channel flow\nversus pressure measurements were used to determine hydrodynamic resistances\nwhich were compared with finite element simulations using a range of\ncross-section profiles and areas. Microfluidic metering circuits were\nconstructed from variable resistance snake channels and dimensionally symmetric\nor asymmetric Y-junctions. Sample to acid volume ratios (meter ratio) up to\n100:1 have been achieved with 300 microns wide snake channel for lengths > 1m.\nAt the highest pattern resolution, this would require a footprint of > 600 mm2\n(6 x10-4 m2). Circuits based solely on asymmetric Y-junctions gave meter ratios\nup to 16:1 with a footprint cost of < 40 mm2 and precision values of ~0.2%.\nFurther design and fabrication refinements will be required to ensure the\nstructural and dimensional integrity of such small channels in future\nintegration of metering units into full TCO2 analysis microfluidic circuits.\n",
    "query": "Ocean acidification",
    "docId": 1171883,
    "score": 23.49811553955078,
    "userScore": 2
  },
  {
    "title": "CONet: A Cognitive Ocean Network",
    "paperAbstract": "  The scientific and technological revolution of the Internet of Things has\nbegun in the area of oceanography. Historically, humans have observed the ocean\nfrom an external viewpoint in order to study it. In recent years, however,\nchanges have occurred in the ocean, and laboratories have been built on the\nseafloor. Approximately 70.8% of the Earth's surface is covered by oceans and\nrivers. The Ocean of Things is expected to be important for disaster\nprevention, ocean-resource exploration, and underwater environmental\nmonitoring. Unlike traditional wireless sensor networks, the Ocean Network has\nits own unique features, such as low reliability and narrow bandwidth. These\nfeatures will be great challenges for the Ocean Network. Furthermore, the\nintegration of the Ocean Network with artificial intelligence has become a\ntopic of increasing interest for oceanology researchers. The Cognitive Ocean\nNetwork (CONet) will become the mainstream of future ocean science and\nengineering developments. In this article, we define the CONet. The\ncontributions of the paper are as follows: (1) a CONet architecture is proposed\nand described in detail; (2) important and useful demonstration applications of\nthe CONet are proposed; and (3) future trends in CONet research are presented.\n",
    "query": "Ocean acidification",
    "docId": 1075800,
    "score": 23.186552047729492,
    "userScore": 1
  },
  {
    "title": "A review of the ocean-atmosphere interactions during tropical cyclones\n  in the north Indian Ocean",
    "paperAbstract": "  The north Indian Ocean accounts for 6% of the global tropical cyclones\nannually. Despite the small fraction of cyclones, some of the most devastating\ncyclones have formed in this basin, causing extensive damage to the life and\nproperty in the north Indian Ocean rim countries. In this review article, we\nhighlight the advancement in research in terms of ocean-atmosphere interaction\nduring cyclones in the north Indian Ocean and identify the gap areas where our\nunderstanding is still lacking.\n",
    "query": "Ocean acidification",
    "docId": 1392262,
    "score": 22.99873161315918,
    "userScore": 1
  },
  {
    "title": "Review of COVID-19 Antibody Therapies",
    "paperAbstract": "  Under the global health emergency caused by coronavirus disease 2019\n(COVID-19), efficient and specific therapies are urgently needed. Compared with\ntraditional small-molecular drugs, antibody therapies are relatively easy to\ndevelop and as specific as vaccines in targeting severe acute respiratory\nsyndrome coronavirus 2 (SARS-CoV-2), and thus attract much attention in the\npast few months. This work reviews seven existing antibodies for SARS-CoV-2\nspike (S) protein with three-dimensional (3D) structures deposited in the\nProtein Data Bank. Five antibody structures associated with SARS-CoV are\nevaluated for their potential in neutralizing SARS-CoV-2. The interactions of\nthese antibodies with the S protein receptor-binding domain (RBD) are compared\nwith those of angiotensin-converting enzyme 2 (ACE2) and RBD complexes. Due to\nthe orders of magnitude in the discrepancies of experimental binding\naffinities, we introduce topological data analysis (TDA), a variety of network\nmodels, and deep learning to analyze the binding strength and therapeutic\npotential of the aforementioned fourteen antibody-antigen complexes. The\ncurrent COVID-19 antibody clinical trials, which are not limited to the S\nprotein target, are also reviewed.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 1305098,
    "score": 35.160980224609375,
    "userScore": 1
  },
  {
    "title": "VDDB: a comprehensive resource and machine learning platform for\n  antiviral drug discovery",
    "paperAbstract": "  Virus infection is one of the major diseases that seriously threaten human\nhealth. To meet the growing demand for mining and sharing data resources\nrelated to antiviral drugs and to accelerate the design and discovery of new\nantiviral drugs, we presented an open-access antiviral drug resource and\nmachine learning platform (VDDB), which, to the best of our knowledge, is the\nfirst comprehensive dedicated resource for experimentally verified potential\ndrugs/molecules based on manually curated data. Currently, VDDB highlights 848\nclinical vaccines, 199 clinical antibodies, as well as over 710,000 small\nmolecules targeting 39 medically important viruses including SARS-CoV-2.\nFurthermore, VDDB stores approximately 3 million records of pharmacological\ndata for these collected potential antiviral drugs/molecules, involving 314\ncell infection-based phenotypic and 234 target-based genotypic assays. Based on\nthese annotated pharmacological data, VDDB allows users to browse, search and\ndownload reliable information about these collects for various viruses of\ninterest. In particular, VDDB also integrates 57 cell infection- and 117\ntarget-based associated high-accuracy machine learning models to support\nvarious antivirals identification-related tasks, such as compound activity\nprediction, virtual screening, drug repositioning and target fishing. VDDB is\nfreely accessible at http://vddb.idruglab.cn.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 1719236,
    "score": 33.934478759765625,
    "userScore": 1
  },
  {
    "title": "Machine Learning Methods for Shark Detection",
    "paperAbstract": "  This essay reviews human observer-based methods employed in shark spotting in\nMuizenberg Beach. It investigates Machine Learning methods for automated shark\ndetection with the aim of enhancing human observation. A questionnaire and\ninterview were used to collect information about shark spotting, the motivation\nof the actual Shark Spotter program and its limitations. We have defined a list\nof desirable properties for our model and chosen the adequate mathematical\ntechniques. The preliminary results of the research show that we can expect to\nextract useful information from shark images despite the geometric\ntransformations that sharks perform, its features do not change. To conclude,\nwe have partially implemented our model; the remaining implementation requires\ndataset.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 1131745,
    "score": 32.43690872192383,
    "userScore": 1
  },
  {
    "title": "Prediction and mitigation of mutation threats to COVID-19 vaccines and\n  antibody therapies",
    "paperAbstract": "  Antibody therapeutics and vaccines are among our last resort to end the\nraging COVID-19 pandemic. They, however, are prone to over 5,000 mutations on\nthe spike (S) protein uncovered by a Mutation Tracker based on over 200,000\ngenome isolates. It is imperative to understand how mutations would impact\nvaccines and antibodies in the development. In this work, we study the\nmechanism, frequency, and ratio of mutations on the S protein. Additionally, we\nuse 56 antibody structures and analyze their 2D and 3D characteristics.\nMoreover, we predict the mutation-induced binding free energy (BFE) changes for\nthe complexes of S protein and antibodies or ACE2. By integrating genetics,\nbiophysics, deep learning, and algebraic topology, we reveal that most of 462\nmutations on the receptor-binding domain (RBD) will weaken the binding of S\nprotein and antibodies and disrupt the efficacy and reliability of antibody\ntherapies and vaccines. A list of 31 vaccine escape mutants is identified,\nwhile many other disruptive mutations are detailed as well. We also unveil that\nabout 65\\% existing RBD mutations, including those variants recently found in\nthe United Kingdom (UK) and South Africa, are binding-strengthen mutations,\nresulting in more infectious COVID-19 variants. We discover the disparity\nbetween the extreme values of RBD mutation-induced BFE strengthening and\nweakening of the bindings with antibodies and ACE2, suggesting that SARS-CoV-2\nis at an advanced stage of evolution for human infection, while the human\nimmune system is able to produce optimized antibodies. This discovery implies\nthe vulnerability of current vaccines and antibody drugs to new mutations. Our\npredictions were validated by comparison with more than 1,400 deep mutations on\nthe S protein RBD. Our results show the urgent need to develop new\nmutation-resistant vaccines and antibodies and to prepare for seasonal\nvaccinations.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 1362687,
    "score": 31.16276741027832,
    "userScore": 1
  },
  {
    "title": "N-terminal domain Increases Activation of Elephant Shark Glucocorticoid\n  and Mineralocorticoid Receptors",
    "paperAbstract": "  Cortisol, corticosterone and aldosterone activate full-length glucocorticoid\nreceptor (GR) from elephant shark, a cartilaginous fish belonging to the oldest\ngroup of jawed vertebrates. Activation by aldosterone a mineralocorticoid,\nindicates partial divergence of elephant shark GR from the MR. Progesterone\nactivates elephant shark MR, but not elephant shark GR. Progesterone inhibits\nsteroid binding to elephant shark GR, but not to human GR. Deletion of the\nN-terminal domain (NTD) from elephant shark GR (Truncated GR) reduced the\nresponse to corticosteroids, while truncated and full-length elephant shark MR\nhad similar responses to corticosteroids. Chimeras of elephant shark GR NTD\nfused to MR DBD+LBD had increased activation by corticosteroids and\nprogesterone compared to full-length elephant shark MR. Elephant shark MR NTD\nfused to GR DBD+LBD had similar activation as full-length elephant shark MR,\nindicating that activation of human GR by the NTD evolved early in GR\ndivergence from the MR.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 1202111,
    "score": 30.752716064453125,
    "userScore": 0
  },
  {
    "title": "The efficacy of antiviral drug, HIV viral load and the immune response",
    "paperAbstract": "  Developing antiviral drugs is an exigent task since viruses mutate to\novercome the effect of antiviral drugs. As a result, the efficacy of most\nantiviral drugs is short-lived. To include this effect, we modify the Neumann\nand Dahari model. Considering the fact that the efficacy of the antiviral drug\nvaries in time, the differential equations introduced in the previous model\nsystems are rewritten to study the correlation between the viral load and\nantiviral drug. The effect of antiviral drug that either prevents infection or\nstops the production of a virus is explored. First, the efficacy of the drug is\nconsidered to decreases monotonously as time progresses. In this case, our\nresult depicts that when the efficacy of the drug is low, the viral load\ndecreases and increases back in time revealing the effect of the antiviral\ndrugs is short-lived. On the other hand, for the antiviral drug with high\nefficacy, the viral load, as well as the number of infected cells, monotonously\ndecreases while the number of uninfected cells increases. The dependence of the\ncritical drug efficacy on time is also explored. Moreover, the correlation\nbetween viral load, the antiviral drug, and CTL response is also explored. In\nthis case, not only the dependence for the basic reproduction ratio on the\nmodel parameters is explored but also we analyze the critical drug efficacy as\na function of time. We show that the term related to the basic reproduction\nratio increases when the CTL response step up. A simple analytically solvable\nmathematical model is also presented to analyze the correlation between viral\nload and antiviral drugs.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 1414155,
    "score": 30.24028968811035,
    "userScore": 1
  },
  {
    "title": "Comparing antiviral strategies against COVID-19 via multiscale\n  within-host modelling",
    "paperAbstract": "  Within-host models of COVID-19 infection dynamics enable the merits of\ndifferent forms of antiviral therapy to be assessed in individual patients. A\nstochastic agent-based model of COVID-19 intracellular dynamics is introduced\nhere, that incorporates essential steps of the viral life cycle targeted by\ntreatment options. Integration of model predictions with an intercellular ODE\nmodel of within-host infection dynamics, fitted to patient data, generates a\ngeneric profile of disease progression in patients that have recovered in the\nabsence of treatment. This is contrasted with the profiles obtained after\nvariation of model parameters pertinent to the immune response, such as\neffector cell and antibody proliferation rates, mimicking disease progression\nin immunocompromised patients. These profiles are then compared with disease\nprogression in the presence of antiviral and convalescent plasma therapy\nagainst COVID-19 infections. The model reveals that using both therapies in\ncombination can be very effective in reducing the length of infection, but\nthese synergistic effects decline with a delayed treatment start. Conversely,\nearly treatment with either therapy alone can actually increase the duration of\ninfection, with infectious virions still present after the decline of other\nmarkers of infection. This suggests that usage of these treatments should\nremain carefully controlled in a clinical environment.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 1365287,
    "score": 29.785057067871094,
    "userScore": 1
  },
  {
    "title": "Shark: SQL and Rich Analytics at Scale",
    "paperAbstract": "  Shark is a new data analysis system that marries query processing with\ncomplex analytics on large clusters. It leverages a novel distributed memory\nabstraction to provide a unified engine that can run SQL queries and\nsophisticated analytics functions (e.g., iterative machine learning) at scale,\nand efficiently recovers from failures mid-query. This allows Shark to run SQL\nqueries up to 100x faster than Apache Hive, and machine learning programs up to\n100x faster than Hadoop. Unlike previous systems, Shark shows that it is\npossible to achieve these speedups while retaining a MapReduce-like execution\nengine, and the fine-grained fault tolerance properties that such engines\nprovide. It extends such an engine in several ways, including column-oriented\nin-memory storage and dynamic mid-query replanning, to effectively execute SQL.\nThe result is a system that matches the speedups reported for MPP analytic\ndatabases over MapReduce, while offering fault tolerance properties and complex\nanalytics capabilities that they lack.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 388422,
    "score": 29.376771926879883,
    "userScore": 0
  },
  {
    "title": "The Shark Random Swim (L\\'evy flight with memory)",
    "paperAbstract": "  The Elephant Random Walk (ERW), first introduced by Sch\\\"utz and Trimper\n(2004), is a one-dimensional simple random walk on $ \\mathbb{Z} $ having a\nmemory about the whole past. We study the Shark Random Swim, a random walk\nwhose steps are $ \\alpha $-stable distributed with memory about the whole past.\nIn contrast with the ERW, the steps of the Shark Random Swim have a heavy\ntailed distribution. Our aim in this work is to study the impact of the heavy\ntailed step distributions on the asymptotic behavior of the random walk. We\nshall see that, as for the ERW, the asymptotic behavior of the Shark Random\nSwim depends on its memory parameter $ p $, and that a phase transition can be\nobserved at the critical value $ p=\\frac{1}{\\alpha} $.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 901054,
    "score": 28.912343978881836,
    "userScore": 0
  },
  {
    "title": "Transcriptional Activation of Elephant Shark Mineralocorticoid Receptor\n  by Corticosteroids, Progesterone and Spironolactone",
    "paperAbstract": "  We report the analysis of activation by corticosteroids and progesterone of\nfull-length mineralocorticoid receptor (MR) from elephant shark, a\ncartilaginous fish belonging to the oldest group of jawed vertebrates. Based on\ntheir measured activities, aldosterone, cortisol, 11-deoxycorticosterone,\ncorticosterone, 11-deoxcortisol, progesterone and 19-norprogesterone are\npotential physiological mineralocorticoids. However, aldosterone, the\nphysiological mineralocorticoid in humans and other terrestrial vertebrates, is\nnot found in cartilaginous or ray-finned fishes. Because progesterone is a\nprecursor for corticosteroids that activate elephant shark MR, we propose that\nprogesterone was an ancestral ligand for elephant shark MR. Although\nprogesterone activates ray-finned fish MRs, progesterone does not activate\nhuman, amphibian or alligator MRs, suggesting that during the transition to\nterrestrial vertebrates, progesterone lost the ability to activate the MR.\nComparison of RNA-sequence analysis of elephant shark MR with that of human MR\nsuggests that MR expression in the human brain, heart, ovary, testis and other\nnon-epithelial tissues evolved in cartilaginous fishes. Together, these data\nsuggest that progesterone-activated MR may have unappreciated functions in\nelephant shark ovary and testis.\n",
    "query": "Shark antibodies antiviral therapies",
    "docId": 1016685,
    "score": 28.54749298095703,
    "userScore": 0
  },
  {
    "title": "Predicting China's CPI by Scanner Big Data",
    "paperAbstract": "  Scanner big data has potential to construct Consumer Price Index (CPI). This\nwork utilizes the scanner data of supermarket retail sales, which are provided\nby China Ant Business Alliance (CAA), to construct the Scanner-data Food\nConsumer Price Index (S-FCPI) in China, and the index reliability is verified\nby other macro indicators, especially by China's CPI. And not only that, we\nbuild multiple machine learning models based on S-FCPI to quantitatively\npredict the CPI growth rate in months, and qualitatively predict those\ndirections and levels. The prediction models achieve much better performance\nthan the traditional time series models in existing research. This work paves\nthe way to construct and predict price indexes through using scanner big data\nin China. S-FCPI can not only reflect the changes of goods prices in higher\nfrequency and wider geographic dimension than CPI, but also provide a new\nperspective for monitoring macroeconomic operation, predicting inflation and\nunderstanding other economic issues, which is beneficial supplement to China's\nCPI.\n",
    "query": "what is CPI and GDP",
    "docId": 1755547,
    "score": 31.55698013305664,
    "userScore": 2
  },
  {
    "title": "Research on CPI Prediction Based on Natural Language Processing",
    "paperAbstract": "  In the past, the seed keywords for CPI prediction were often selected based\non empirical summaries of research and literature studies, which were prone to\nselect omitted and invalid variables. In this paper, we design a keyword\nexpansion technique for CPI prediction based on the cutting-edge NLP model,\nPANGU. We improve the CPI prediction ability using the corresponding web search\nindex. Compared with the unsupervised pre-training and supervised downstream\nfine-tuning natural language processing models such as BERT and NEZHA, the\nPANGU model can be expanded to obtain more reliable CPI-generated keywords by\nits excellent zero-sample learning capability without the limitation of the\ndownstream fine-tuning data set. Finally, this paper empirically tests the\nkeyword prediction ability obtained by this keyword expansion method with\nhistorical CPI data.\n",
    "query": "what is CPI and GDP",
    "docId": 1805463,
    "score": 31.384492874145508,
    "userScore": 1
  },
  {
    "title": "Influence of corruption on economic growth rate and foreign investments",
    "paperAbstract": "  In order to investigate whether government regulations against corruption can\naffect the economic growth of a country, we analyze the dependence between\nGross Domestic Product (GDP) per capita growth rates and changes in the\nCorruption Perceptions Index (CPI). For the period 1999-2004 on average for all\ncountries in the world, we find that an increase of CPI by one unit leads to an\nincrease of the annual GDP per capita by 1.7 %. By regressing only European\ntransition countries, we find that $\\Delta$CPI = 1 generates increase of the\nannual GDP per capita by 2.4 %. We also analyze the relation between foreign\ndirect investments received by different countries and CPI, and we find a\nstatistically significant power-law functional dependence between foreign\ndirect investment per capita and the country corruption level measured by the\nCPI. We introduce a new measure to quantify the relative corruption between\ncountries based on their respective wealth as measured by GDP per capita.\n",
    "query": "what is CPI and GDP",
    "docId": 28942,
    "score": 31.354402542114258,
    "userScore": 1
  },
  {
    "title": "The competitiveness versus the wealth of a country",
    "paperAbstract": "  Politicians world-wide frequently promise a better life for their citizens.\nWe find that the probability that a country will increase its {\\it per capita}\nGDP ({\\it gdp}) rank within a decade follows an exponential distribution with\ndecay constant $\\lambda = 0.12$. We use the Corruption Perceptions Index (CPI)\nand the Global Competitiveness Index (GCI) and find that the distribution of\nchange in CPI (GCI) rank follows exponential functions with approximately the\nsame exponent as $\\lambda$, suggesting that the dynamics of {\\it gdp}, CPI, and\nGCI may share the same origin. Using the GCI, we develop a new measure, which\nwe call relative competitiveness, to evaluate an economy's competitiveness\nrelative to its {\\it gdp}. For all European and EU countries during the\n2008-2011 economic downturn we find that the drop in {\\it gdp} in more\ncompetitive countries relative to {\\it gdp} was substantially smaller than in\nrelatively less competitive countries, which is valuable information for\npolicymakers.\n",
    "query": "what is CPI and GDP",
    "docId": 369977,
    "score": 30.91248321533203,
    "userScore": 2
  },
  {
    "title": "Logistic forecasting of GDP competitiveness",
    "paperAbstract": "  The GDP growth of national economies is modelled by the logistic function.\nApplying it on the GDP data of the World Bank till the year 2020, we forecast\nthe outcome of the competitive GDP growth of Japan, Germany, UK and India, all\nof whose current GDPs are very close to one another. Fulfilling one of the\npredictions, in 2022 the GDP of India has indeed overtaken the GDP of UK. Our\noverall forecast is that by 2047, the GDP of India will be greater than that of\nthe other three countries. We argue that when trade saturates, large and\npopulous countries (like India) have the benefit of high domestic consumption\nto propel their GDP growth.\n",
    "query": "what is CPI and GDP",
    "docId": 1742031,
    "score": 29.888225555419922,
    "userScore": 2
  },
  {
    "title": "Forecasting CPI Inflation Components with Hierarchical Recurrent Neural\n  Networks",
    "paperAbstract": "  We present a hierarchical architecture based on Recurrent Neural Networks\n(RNNs) for predicting disaggregated inflation components of the Consumer Price\nIndex (CPI). While the majority of existing research is focused mainly on\npredicting the inflation headline, many economic and financial entities are\nmore interested in its partial disaggregated components. To this end, we\ndeveloped the novel Hierarchical Recurrent Neural Network (HRNN) model that\nutilizes information from higher levels in the CPI hierarchy to improve\npredictions at the more volatile lower levels. Our evaluations, based on a\nlarge data-set from the US CPI-U index, indicate that the HRNN model\nsignificantly outperforms a vast array of well-known inflation prediction\nbaselines.\n",
    "query": "what is CPI and GDP",
    "docId": 1380668,
    "score": 29.26871109008789,
    "userScore": 2
  },
  {
    "title": "The Coronal Physics Investigator (CPI) Experiment for ISS: A New Vision\n  for Understanding Solar Wind Acceleration",
    "paperAbstract": "  In February 2011 we proposed a NASA Explorer Mission of Opportunity program\nto develop and operate a large-aperture ultraviolet coronagraph spectrometer\ncalled the Coronal Physics Investigator (CPI) as an attached International\nSpace Station (ISS) payload. The primary goal of this program is to identify\nand characterize the physical processes that heat and accelerate the primary\nand secondary components of the fast and slow solar wind. In addition, CPI can\nmake key measurements needed to understand CMEs. UVCS/SOHO allowed us to\nidentify what additional measurements need to be made to answer the fundamental\nquestions about how solar wind streams are produced, and CPI's next-generation\ncapabilities were designed specifically to make those measurements. Compared to\nprevious instruments, CPI provides unprecedented sensitivity, a wavelength\nrange extending from 25.7 to 126 nm, higher temporal resolution, and the\ncapability to measure line profiles of He II, N V, Ne VII, Ne VIII, Si VIII, S\nIX, Ar VIII, Ca IX, and Fe X, never before seen in coronal holes above 1.3\nsolar radii. CPI will constrain the properties and effects of coronal MHD waves\nby (1) observing many ions over a large range of charge and mass, (2) providing\nsimultaneous measurements of proton and electron temperatures to probe\nturbulent dissipation mechanisms, and (3) measuring amplitudes of low-frequency\ncompressive fluctuations. CPI is an internally occulted ultraviolet coronagraph\nthat provides the required high sensitivity without the need for a deployable\nboom, and with all technically mature hardware including an ICCD detector. A\nhighly experienced Explorer and ISS contractor, L-3 Com Integrated Optical\nSystems and Com Systems East, will provide the tracking and pointing system as\nwell as the instrument, and the integration to the ISS.\n",
    "query": "what is CPI and GDP",
    "docId": 257371,
    "score": 28.93873405456543,
    "userScore": 0
  },
  {
    "title": "GDP growth rate and population",
    "paperAbstract": "  Real GDP growth rate in developed countries is found to be a sum of two\nterms. The first term is the reciprocal value of the duration of the period of\nmean income growth with work experience, Tcr. The current value of Tcr in the\nUSA is 40 years. The second term is inherently related to population and\ndefined by the relative change in the number of people with a specific age (9\nyears in the USA), (1/2)*dN9(t) /N9(t), where N9(t) is the number of\n9-year-olds at time t. The Tcr grows as the square root of real GDP per capita.\nHence, evolution of real GDP is defined by only one parameter - the number of\npeople of the specific age. Predictions for the USA, the UK, and France are\npresented and discussed. A similar relationship is derived for real GDP per\ncapita. Annual increment of GDP per capita is also a combination of economic\ntrend term and the same specific age population term. The economic trend term\nduring last 55 years is equal to $400 (2002 US dollars) divided by the attained\nlevel of real GDP per capita. Thus, the economic trend term has an asymptotic\nvalue of zero. Inversion of the measured GDP values is used to recover the\ncorresponding change of the specific age population between 1955 and 2003. The\npopulation recovery method based on GDP potentially is of a higher accuracy\nthan routine censuses.\n",
    "query": "what is CPI and GDP",
    "docId": 93477,
    "score": 28.897125244140625,
    "userScore": 2
  },
  {
    "title": "Global dynamics of GDP and trade",
    "paperAbstract": "  We use the logistic equation to model the dynamics of the GDP and the trade\nof the six countries with the highest GDP in the world, namely, USA, China,\nJapan, Germany, UK and India. From the modelling of the economic data, which\nare made available by the World Bank, we predict the maximum values of the\ngrowth of GDP and trade, as well as the duration over which exponential growth\ncan be sustained. We set up the correlated growth of GDP and trade as the phase\nsolutions of an autonomous second-order dynamical system. GDP and trade are\nrelated to each other by a power law, whose exponent seems to differentiate the\nsix national economies into two types. Under conducive conditions for economic\ngrowth, our conclusions have general validity.\n",
    "query": "what is CPI and GDP",
    "docId": 1528083,
    "score": 28.86310577392578,
    "userScore": 2
  },
  {
    "title": "It's not the economy, stupid! How social capital and GDP relate to\n  happiness over time",
    "paperAbstract": "  What predicts the evolution over time of subjective well-being? We correlate\nthe trends of subjective well-being with the trends of social capital and/or\nGDP. We find that in the long and medium run social capital largely predicts\nthe trends of subjective wellbeing in our sample of countries. In the\nshort-term this relationship weakens. Indeed, in the short run, changes in\nsocial capital predict a much smaller portion of the changes in subjective\nwell-being than over longer periods. GDP follows a reverse path, thus\nconfirming the Easterlin paradox: in the short run GDP is more positively\ncorrelated to well-being than in the medium-term, while in the long run this\ncorrelation vanishes.\n",
    "query": "what is CPI and GDP",
    "docId": 572110,
    "score": 27.679012298583984,
    "userScore": 1
  },
  {
    "title": "Adaptive evolution of hybrid bacteria by horizontal gene transfer",
    "paperAbstract": "  Horizontal gene transfer is an important factor in bacterial evolution that\ncan act across species boundaries. Yet, we know little about rate and genomic\ntargets of cross-lineage gene transfer, and about its effects on the recipient\norganism's physiology and fitness. Here, we address these questions in a\nparallel evolution experiment with two Bacillus subtilis lineages of 7%\nsequence divergence. We observe rapid evolution of hybrid organisms: gene\ntransfer swaps ~12% of the core genome in just 200 generations, and 60% of core\ngenes are replaced in at least one population. By genomics, transcriptomics,\nfitness assays, and statistical modeling, we show that transfer generates\nadaptive evolution and functional alterations in hybrids. Specifically, our\nexperiments reveal a strong, repeatable fitness increase of evolved populations\nin the stationary growth phase. By genomic analysis of the transfer statistics\nacross replicate populations, we infer that selection on HGT has a broad\ngenetic basis: 40% of the observed transfers are adaptive. At the level of\nfunctional gene networks, we find signatures of negative and positive\nselection, consistent with hybrid incompatibilities and adaptive evolution of\nnetwork functions. Our results suggest that gene transfer navigates a complex\ncross-lineage fitness landscape, bridging epistatic barriers along multiple\nhigh-fitness paths.\n",
    "query": "genomics of adaptive evolution",
    "docId": 1275885,
    "score": 28.496726989746094,
    "userScore": 1
  },
  {
    "title": "Adaptive Coevolutionary Networks: A Review",
    "paperAbstract": "  Adaptive networks appear in many biological applications. They combine\ntopological evolution of the network with dynamics in the network nodes.\nRecently, the dynamics of adaptive networks has been investigated in a number\nof parallel studies from different fields, ranging from genomics to game\ntheory. Here we review these recent developments and show that they can be\nviewed from a unique angle. We demonstrate that all these studies are\ncharacterized by common themes, most prominently: complex dynamics and robust\ntopological self-organization based on simple local rules.\n",
    "query": "genomics of adaptive evolution",
    "docId": 24123,
    "score": 26.537952423095703,
    "userScore": 2
  },
  {
    "title": "de novo gene birth as an inevitable consequence of adaptive evolution",
    "paperAbstract": "  Phylostratigraphy suggests that new genes are continually born de novo from\nnon-genic sequences, and the genes that persist found new lineages,\ncontributing to the adaptive evolution of organisms. While recent evidence\nsupports the view that de novo gene birth is frequent and widespread, the\nmechanisms underlying this process are yet to be discovered. Here we\nhypothesize and examine a potential general mechanism of gene birth driven by\nthe accumulation of beneficial mutations at non-genic loci. To demonstrate this\npossibility, we model this mechanism within the boundaries set by current\nknowledge on mutation effects. Estimates from this analysis are in line with\nobservations of recurrent and extensive gene birth in genomics studies. Thus,\nwe propose that, rather than being inactive and silent, non-genic regions are\nlikely to be dynamic storehouses of potential genes.\n",
    "query": "genomics of adaptive evolution",
    "docId": 1523645,
    "score": 26.086700439453125,
    "userScore": 2
  },
  {
    "title": "Revolutionizing Genomics with Reinforcement Learning Techniques",
    "paperAbstract": "  In recent years, Reinforcement Learning (RL) has emerged as a powerful tool\nfor solving a wide range of problems, including decision-making and genomics.\nThe exponential growth of raw genomic data over the past two decades has\nexceeded the capacity of manual analysis, leading to a growing interest in\nautomatic data analysis and processing. RL algorithms are capable of learning\nfrom experience with minimal human supervision, making them well-suited for\ngenomic data analysis and interpretation. One of the key benefits of using RL\nis the reduced cost associated with collecting labeled training data, which is\nrequired for supervised learning. While there have been numerous studies\nexamining the applications of Machine Learning (ML) in genomics, this survey\nfocuses exclusively on the use of RL in various genomics research fields,\nincluding gene regulatory networks (GRNs), genome assembly, and sequence\nalignment. We present a comprehensive technical overview of existing studies on\nthe application of RL in genomics, highlighting the strengths and limitations\nof these approaches. We then discuss potential research directions that are\nworthy of future exploration, including the development of more sophisticated\nreward functions as RL heavily depends on the accuracy of the reward function,\nthe integration of RL with other machine learning techniques, and the\napplication of RL to new and emerging areas in genomics research. Finally, we\npresent our findings and conclude by summarizing the current state of the field\nand the future outlook for RL in genomics.\n",
    "query": "genomics of adaptive evolution",
    "docId": 1798202,
    "score": 25.44793701171875,
    "userScore": 1
  },
  {
    "title": "Big Data Technology Accelerate Genomics Precision Medicine",
    "paperAbstract": "  During genomics life science research, the data volume of whole genomics and\nlife science algorithm is going bigger and bigger, which is calculated as TB,\nPB or EB etc. The key problem will be how to store and analyze the data with\noptimized way. This paper demonstrates how Intel Big Data Technology and\nArchitecture help to facilitate and accelerate the genomics life science\nresearch in data store and utilization. Intel defines high performance\nGenomicsDB for variant call data query and Lustre filesystem with Hierarchal\nStorage Management for genomics data store. Based on these great technology,\nIntel defines genomics knowledge share and exchange architecture, which is\nlanded and validated in BGI China and Shanghai Children Hospital with very\npositive feedback. And these big data technology can definitely be scaled to\nmuch more genomics life science partners in the world.\n",
    "query": "genomics of adaptive evolution",
    "docId": 814453,
    "score": 25.170940399169922,
    "userScore": 1
  },
  {
    "title": "GenoML: Automated Machine Learning for Genomics",
    "paperAbstract": "  GenoML is a Python package automating machine learning workflows for genomics\n(genetics and multi-omics) with an open science philosophy. Genomics data\nrequire significant domain expertise to clean, pre-process, harmonize and\nperform quality control of the data. Furthermore, tuning, validation, and\ninterpretation involve taking into account the biology and possibly the\nlimitations of the underlying data collection, protocols, and technology.\nGenoML's mission is to bring machine learning for genomics and clinical data to\nnon-experts by developing an easy-to-use tool that automates the full\ndevelopment, evaluation, and deployment process. Emphasis is put on open\nscience to make workflows easily accessible, replicable, and transferable\nwithin the scientific community. Source code and documentation is available at\nhttps://genoml.com.\n",
    "query": "genomics of adaptive evolution",
    "docId": 1433366,
    "score": 24.808731079101562,
    "userScore": 1
  },
  {
    "title": "Deep Learning for Genomics: A Concise Overview",
    "paperAbstract": "  Advancements in genomic research such as high-throughput sequencing\ntechniques have driven modern genomic studies into \"big data\" disciplines. This\ndata explosion is constantly challenging conventional methods used in genomics.\nIn parallel with the urgent demand for robust algorithms, deep learning has\nsucceeded in a variety of fields such as vision, speech, and text processing.\nYet genomics entails unique challenges to deep learning since we are expecting\nfrom deep learning a superhuman intelligence that explores beyond our knowledge\nto interpret the genome. A powerful deep learning model should rely on\ninsightful utilization of task-specific knowledge. In this paper, we briefly\ndiscuss the strengths of different deep learning models from a genomic\nperspective so as to fit each particular task with a proper deep architecture,\nand remark on practical considerations of developing modern deep learning\narchitectures for genomics. We also provide a concise review of deep learning\napplications in various aspects of genomic research, as well as pointing out\npotential opportunities and obstacles for future genomics applications.\n",
    "query": "genomics of adaptive evolution",
    "docId": 940350,
    "score": 24.75944709777832,
    "userScore": 1
  },
  {
    "title": "Machine Learning Applications for Therapeutic Tasks with Genomics Data",
    "paperAbstract": "  Thanks to the increasing availability of genomics and other biomedical data,\nmany machine learning approaches have been proposed for a wide range of\ntherapeutic discovery and development tasks. In this survey, we review the\nliterature on machine learning applications for genomics through the lens of\ntherapeutic development. We investigate the interplay among genomics,\ncompounds, proteins, electronic health records (EHR), cellular images, and\nclinical texts. We identify twenty-two machine learning in genomics\napplications across the entire therapeutics pipeline, from discovering novel\ntargets, personalized medicine, developing gene-editing tools all the way to\nclinical trials and post-market studies. We also pinpoint seven important\nchallenges in this field with opportunities for expansion and impact. This\nsurvey overviews recent research at the intersection of machine learning,\ngenomics, and therapeutic development.\n",
    "query": "genomics of adaptive evolution",
    "docId": 1463730,
    "score": 24.705223083496094,
    "userScore": 1
  },
  {
    "title": "Population genomics on the fly: recent advances in Drosophila",
    "paperAbstract": "  Drosophila melanogaster, a small dipteran of African origin, represents one\nof the best-studied model organisms. Early work in this system has uniquely\nshed light on the basic principles of genetics and resulted in a versatile\ncollection of genetic tools that allow to uncover mechanistic links between\ngenotype and phenotype. Moreover, given its world-wide distribution in diverse\nhabitats and its moderate genome-size, Drosophila has proven very powerful for\npopulation genetics inference and was one of the first eukaryotes whose genome\nwas fully sequenced. In this book-chapter, we provide a brief historical\noverview of research in Drosophila and then focus on recent advances during the\ngenomic era. After describing different types and sources of genomic data, we\ndiscuss mechanisms of neutral evolution including the demographic history of\nDrosophila and the effects of recombination and biased gene conversion. Then,\nwe review recent advances in detecting genome-wide signals of selection, such\nas soft and hard selective sweeps. We further provide a brief introduction to\nbackground selection, selection of non-coding DNA and codon usage and focus on\nthe role of structural variants, such as transposable elements and chromosomal\ninversions, during the adaptive process. Finally, we discuss how genomic data\nhelps to dissect neutral and adaptive evolutionary mechanisms that shape\ngenetic and phenotypic variation in natural populations along environmental\ngradients. In summary, this book chapter serves as a starting point to\nDrosophila population genomics and provides an introduction to the system and\nan overview to data sources, important population genetic concepts and recent\nadvances in the field.\n",
    "query": "genomics of adaptive evolution",
    "docId": 1036097,
    "score": 24.636930465698242,
    "userScore": 2
  },
  {
    "title": "Data Management for High-Throughput Genomics",
    "paperAbstract": "  Today's sequencing technology allows sequencing an individual genome within a\nfew weeks for a fraction of the costs of the original Human Genome project.\nGenomics labs are faced with dozens of TB of data per week that have to be\nautomatically processed and made available to scientists for further analysis.\nThis paper explores the potential and the limitations of using relational\ndatabase systems as the data processing platform for high-throughput genomics.\nIn particular, we are interested in the storage management for high-throughput\nsequence data and in leveraging SQL and user-defined functions for data\nanalysis inside a database system. We give an overview of a database design for\nhigh-throughput genomics, how we used a SQL Server database in some\nunconventional ways to prototype this scenario, and we will discuss some\ninitial findings about the scalability and performance of such a more\ndatabase-centric approach.\n",
    "query": "genomics of adaptive evolution",
    "docId": 144132,
    "score": 24.352699279785156,
    "userScore": 1
  },
  {
    "title": "Molecular Hydrogen in High-Velocity Clouds",
    "paperAbstract": "  We present Far Ultraviolet Spectroscopic Explorer (FUSE) observations of\ninterstellar molecular hydrogen (H_2) in two Galactic high-velocity clouds\n(HVCs). Molecular hydrogen absorption is detected in the Magellanic Stream\n(abundance ~0.3 solar) toward the Seyfert galaxy Fairall 9 in the lowest three\nrotational states (J=0-2) at v(LSR)=+190 km/s, yielding a total H_2 column\ndensity of log N(H_2)=16.40(+0.26)(-0.53). In contrast, no H_2 absorption is\nseen in the high-velocity cloud Complex C (abundance ~0.1 solar) toward the\nquasar PG 1259+593 (log N(H_2)<13.96 at v(LSR)=-130 km/s) although both HVCs\nhave similar HI column densities on the order of log N(HI)~20. Weak H_2\nabsorption is detected in the Intermediate-Velocity Arch (IV Arch; abundance\n\\~1.0 solar) toward PG 1259+593 (log N(H_2)=14.10(+0.21)(-0.44) at v(LSR)=-55\nkm/s and log N(HI)=19.5). It thus appears that metal- and dust-poor halo clouds\nlike Complex C are not able to form and maintain widely distributed H_2,\nwhereas metal and dust-rich halo clouds like the IV Arch can maintain H_2 even\nat low HI column densities.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 1826429,
    "score": 37.95002365112305,
    "userScore": 2
  },
  {
    "title": "A FUSE Survey of Interstellar Molecular Hydrogen in Translucent Clouds",
    "paperAbstract": "  We report the first ensemble results from the FUSE survey of molecular\nhydrogen in lines of sight with A_V $\\gtrsim$ 1 mag. We have developed\ntechniques for fitting computed profiles to the low-J lines of H2, and thus\ndetermining column densities for J = 0 and J = 1, which contain $\\gtrsim$99% of\nthe total H2. From these column densities and ancillary data we have derived\nthe total H2 column densities, hydrogen molecular fractions, and kinetic\ntemperatures for 23 lines of sight. This is the first significant sample of\nmolecular hydrogen column densities of 10^21 cm^-2, measured through UV\nabsorption bands. We have also compiled a set of extinction data for these\nlines of sight, which sample a wide range of environments. We have searched for\ncorrelations of our H2-related quantities with previously published column\ndensities of other molecules and extinction parameters. We find strong\ncorrelations between H2 and molecules such as CH, CN, and CO, in general\nagreement with predictions of chemical models. We also find the expected\ncorrelations between hydrogen molecular fraction and various density indicators\nsuch as kinetic temperature, CN abundance, the steepness of the far-UV\nextinction rise, and the width of the 2175A bump. Despite the relatively large\nmolecular fractions, we do not see the values greater than 0.8 expected in\ntranslucent clouds. With the exception of a few lines of sight, we see little\nevidence for the presence of individual translucent clouds in our sample. We\nconclude that most of the lines of sight are actually composed of two or more\ndiffuse clouds similar to those found toward targets like zeta Oph. We suggest\na modification in terminology to distinguish between a \"translucent line of\nsight\" and a \"translucent cloud.\"\n",
    "query": "Molecular hydrogen clouds",
    "docId": 1830582,
    "score": 37.61042022705078,
    "userScore": 1
  },
  {
    "title": "Observing molecular hydrogen clouds and dark massive objects in galactic\n  halos",
    "paperAbstract": "  Molecular hydrogen clouds can contribute substantially to the galactic halo<\ndark matter and may lead to the birth of massive halo objects (MHOs) observed\nindirectly by microlensing. We present a method to detect these molecular\nclouds in the halo of M31 using the Doppler shift effect. We also consider the\npossibility to directly observe MHOs in the halo of M31 via their infrared\nemission.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 1873366,
    "score": 37.103885650634766,
    "userScore": 3
  },
  {
    "title": "Detection of hydrogen fluoride absorption in diffuse molecular clouds\n  with Herschel/HIFI: a ubiquitous tracer of molecular gas",
    "paperAbstract": "  We discuss the detection of absorption by interstellar hydrogen fluoride (HF)\nalong the sight line to the submillimeter continuum sources W49N and W51. We\nhave used Herschel's HIFI instrument in dual beam switch mode to observe the\n1232.4762 GHz J = 1 - 0 HF transition in the upper sideband of the band 5a\nreceiver. We detected foreground absorption by HF toward both sources over a\nwide range of velocities. Optically thin absorption components were detected on\nboth sight lines, allowing us to measure - as opposed to obtain a lower limit\non - the column density of HF for the first time. As in previous observations\nof HF toward the source G10.6-0.4, the derived HF column density is typically\ncomparable to that of water vapor, even though the elemental abundance of\noxygen is greater than that of fluorine by four orders of magnitude. We used\nthe rather uncertain N(CH)-N(H2) relationship derived previously toward diffuse\nmolecular clouds to infer the molecular hydrogen column density in the clouds\nexhibiting HF absorption. Within the uncertainties, we find that the abundance\nof HF with respect to H2 is consistent with the theoretical prediction that HF\nis the main reservoir of gas-phase fluorine for these clouds. Thus, hydrogen\nfluoride has the potential to become an excellent tracer of molecular hydrogen,\nand provides a sensitive probe of clouds of small H2 column density. Indeed,\nthe observations of hydrogen fluoride reported here reveal the presence of a\nlow column density diffuse molecular cloud along the W51 sight line, at an LSR\nvelocity of ~ 24kms-1, that had not been identified in molecular absorption\nline studies prior to the launch of Herschel.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 201386,
    "score": 36.671485900878906,
    "userScore": 2
  },
  {
    "title": "Hydrogen in diffuse molecular clouds in the Milky Way: Atomic column\n  densities and molecular fraction along prominent lines of sight",
    "paperAbstract": "  Recent submillimeter and far-infrared wavelength observations of absorption\nin the rotational ground-state lines of various simple molecules against\ndistant Galactic continuum sources have opened the possibility of studying the\nchemistry of diffuse molecular clouds throughout the Milky Way. In order to\ncalculate abundances, the column densities of molecular and atomic hydrogen,\nHI, must be known. We aim at determining the atomic hydrogen column densities\nfor diffuse clouds located on the sight lines toward a sample of prominent\nhigh-mass star-forming regions that were intensely studied with the HIFI\ninstrument onboard Herschel. Based on Jansky Very Large Array data, we employ\nthe 21 cm HI absorption-line technique to construct profiles of the HI opacity\nversus radial velocity toward our target sources. These profiles are combined\nwith lower resolution archival data of extended HI emission to calculate the HI\ncolumn densities of the individual clouds along the sight lines. We employ\nBayesian inference to estimate the uncertainties of the derived quantities. Our\nstudy delivers reliable estimates of the atomic hydrogen column density for a\nlarge number of diffuse molecular clouds at various Galactocentric distances.\nTogether with column densities of molecular hydrogen derived from its\nsurrogates observed with HIFI, the measurements can be used to characterize the\nclouds and investigate the dependence of their chemistry on the molecular\nfraction, for example.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 820550,
    "score": 36.559505462646484,
    "userScore": 3
  },
  {
    "title": "Directional Radiation and Photodissociation Regions in Molecular\n  Hydrogen Clouds",
    "paperAbstract": "  Some astrophysical observations of molecular hydrogen point to a broadening\nof the velocity distribution for molecules at excited rotational levels. This\neffect is observed in both Galactic and high redshift clouds. Analysis of H_2,\nHD, and CI absorption lines has revealed the broadening effect in the\nabsorption system of QSO 1232+082 (z_{abs}=2.33771). We analyze line broadening\nmechanisms by considering in detail the transfer of ultraviolet radiation (in\nthe resonance lines of the Lyman and Werner H_2 molecular bands) for various\nvelocity distributions at excited rotational levels. The mechanism we suggest\nincludes the saturation of the lines that populate excited rotational levels\n(radiative pumping) and manifests itself most clearly in the case of\ndirectional radiation in the medium. Based on the calculated structure of a\nmolecular hydrogen cloud in rotational level populations, we have considered an\nadditional mechanism that takes into account the presence of a\nphotodissociation region. Note that disregarding the broadening effects we\ninvestigated can lead to a significant systematic error when the data are\nprocessed.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 140690,
    "score": 35.33464431762695,
    "userScore": 2
  },
  {
    "title": "The formation of molecular clouds in spiral galaxies",
    "paperAbstract": "  We present Smoothed Particle Hydrodynamics (SPH) simulations of molecular\ncloud formation in spiral galaxies. These simulations model the response of a\nnon-self-gravitating gaseous disk to a galactic potential. The spiral shock\ninduces high densities in the gas, and considerable structure in the spiral\narms, which we identify as molecular clouds. We regard the formation of these\nstructures as due to the dynamics of clumpy shocks, which perturb the flow of\ngas through the spiral arms. In addition, the spiral shocks induce a large\nvelocity dispersion in the spiral arms, comparable with the magnitude of the\nvelocity dispersion observed in molecular clouds. We estimate the formation of\nmolecular hydrogen, by post-processing our results and assuming the gas is\nisothermal. Provided the gas is cold ($T\\le100$ K), the gas is compressed\nsufficiently in the spiral shock for molecular hydrogen formation to occur in\nthe dense spiral arm clumps. These molecular clouds are largely confined to the\nspiral arms, since most molecular gas is photodissociated to atomic hydrogen\nupon leaving the arms.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 1860772,
    "score": 35.253028869628906,
    "userScore": 3
  },
  {
    "title": "A FUSE Survey of Molecular Hydrogen in Intermediate-Velocity Clouds in\n  the Milky Way Halo",
    "paperAbstract": "  Far Ultraviolet Spectroscopic Explorer (FUSE) data is used to investigate the\nmolecular hydrogen (H_2) content of intermediate-velocity clouds (IVCs) in the\nlower halo of the Milky Way. We analyze interstellar absorption towards 56\n(mostly extragalactic) background sources to study H_2 absorption in the Lyman-\nand Werner bands in 61 IVC components at H I column densities >10^19 cm^-2. For\ndata with good S/N (~9 per resolution element and higher), H_2 in IVC gas is\nconvincingly detected in 14 cases at column densities varying between ~10^14\nand ~10^17 cm^-2. We find an additional 17 possible H_2 detections in IVCs in\nFUSE spectra with lower S/N. The molecular hydrogen fractions, f, vary between\n10^-6 and 10^-3, implying a dense, mostly neutral gas phase that is probably\nrelated to the Cold Neutral Medium (CNM) in these clouds. If the H_2 stays in\nformation-dissociation equlibrium, the CNM in these clouds can be characterized\nby compact (D~0.1 pc) filaments with volume densities on the order of n_H~30\ncm^-3. The relatively high detection rate of H_2 in IVC gas implies that the\nCNM in these clouds is ubiquitous. More dense regions with much higher\nmolecular fractions may exist, but it would be difficult to detect them in\nabsorption because of their small size.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 1834184,
    "score": 34.645389556884766,
    "userScore": 2
  },
  {
    "title": "Production of atomic hydrogen by cosmic rays in dark clouds",
    "paperAbstract": "  The presence of small amounts of atomic hydrogen, detected as absorption dips\nin the 21 cm line spectrum, is a well-known characteristic of dark clouds. The\nabundance of hydrogen atoms measured in the densest regions of molecular clouds\ncan be only explained by the dissociation of H$_2$ due to cosmic rays. We want\nto assess the role of Galactic cosmic rays in the formation of atomic hydrogen,\nby using recent developments in the characterisation of the low-energy spectra\nof cosmic rays and advances in the modelling of their propagation in molecular\nclouds. We model the attenuation of the interstellar cosmic rays entering a\ncloud and compute the dissociation rate of molecular hydrogen due to collisions\nwith cosmic-ray protons and electrons as well as fast hydrogen atoms. We\ncompare our results with the available observations. The cosmic-ray\ndissociation rate is entirely determined by secondary electrons produced in\nprimary ionisation collisions. These secondary particles constitute the only\nsource of atomic hydrogen at column densities above $\\sim10^{21}$ cm$^{-2}$. We\nalso find that the dissociation rate decreases with column density, while the\nratio between the dissociation and ionisation rates varies between about 0.6\nand 0.7. From comparison with observations we conclude that a relatively flat\nspectrum of interstellar cosmic-ray protons, as the one suggested by the most\nrecent Voyager 1 data, can only provide a lower bound for the observed atomic\nhydrogen fraction. An enhanced spectrum of low-energy protons is needed to\nexplain most of the observations. Our findings show that a careful description\nof molecular hydrogen dissociation by cosmic rays can explain the abundance of\natomic hydrogen in dark clouds. An accurate characterisation of this process at\nhigh densities is crucial for understanding the chemical evolution of\nstar-forming regions.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 1024184,
    "score": 34.605430603027344,
    "userScore": 2
  },
  {
    "title": "The Transition from Atomic to Molecular Hydrogen in Interstellar Clouds:\n  21cm Signature of the Evolution of Cold Atomic Hydrogen in Dense Clouds",
    "paperAbstract": "  We have investigated the time scale for formation of molecular clouds by\nexamining the conversion of HI to H2 using a time-dependent model. H2 formation\non dust grains and cosmic ray and photo destruction are included in\none-dimensional model slab clouds which incorporate time-independent density\nand temperature distributions. We calculate 21cm spectral line profiles seen in\nabsorption against a background provided by general Galactic HI emission, and\ncompare the model spectra with HI Narrow Self-Absorption, or HINSA, profiles\nabsorbed in a number of nearby molecular clouds. The time evolution of the HI\nand H2 densities is dramatic, with the atomic hydrogen disappearing in a wave\npropagating from the central, denser regions which have a shorter H2 formation\ntime scale, to the edges, where the density is lower and the time scale for H2\nformation longer. The model 21cm spectra are characterized by very strong\nabsorption at early times, when the HI column density through the model clouds\nis extremely large. The minimum time required for a cloud to have evolved to\nits observed configuration, based on the model spectra, is set by the\nrequirement that most of the HI in the outer portions of the cloud, which\notherwise overwhelms the narrow absorption, be removed. The characteristic time\nthat has elapsed since cloud compression and initiation of the HI to H2\nconversion is a few x 10^{14} s or ~ 10^7 yr. This sets a minimum time for the\nage of these molecular clouds and thus for the star formation that may take\nplace within them.\n",
    "query": "Molecular hydrogen clouds",
    "docId": 1866885,
    "score": 34.3972053527832,
    "userScore": 2,
    "inAnnoy": true
  },
  {
    "title": "A Common Gene Expression Signature Analysis Method for Multiple Types of\n  Cancer",
    "paperAbstract": "  Mining gene expression profiles has proven valuable for identifying\nsignatures serving as surrogates of cancer phenotypes. However, the\nsimilarities of such signatures across different cancer types have not been\nstrong enough to conclude that they represent a universal biological mechanism\nshared among multiple cancer types. Here we describe a network-based approach\nthat explores gene-to-gene connections in multiple cancer datasets while\nmaximizing the overall association of the subnetwork with clinical outcomes.\nWith the dataset of The Cancer Genome Atlas (TCGA), we studied the\ncharacteristics of common gene expression of three types of cancers: Rectum\nadenocarcinoma (READ), Breast invasive carcinoma (BRCA) and Colon\nadenocarcinoma (COAD). By analyzing several pairs of highly correlated genes\nafter filtering and clustering work, we found that the co-expressed genes\nacross multiple types of cancers point to particular biological mechanisms\nrelated to cancer cell progression , suggesting that they represent important\nattributes of cancer in need of being elucidated for potential applications in\ndiagnostic, prognostic and therapeutic products applicable to multiple cancer\ntypes.\n",
    "query": "Types of cancer",
    "docId": 1224275,
    "score": 30.763395309448242,
    "userScore": 2
  },
  {
    "title": "Identify Statistical Similarities and Differences Between the Deadliest\n  Cancer Types Through Gene Expression",
    "paperAbstract": "  Prognostic genes have been well studied within each type of cancer. However,\ninvestigations of the similarities and differences across cancer types are\nrare. In view of the optimal course of treatment, the classification of cancers\ninto subtypes is critical to the diagnosis. We examined the properties in gene\nco-expression networks using a patient-to-patient correlation network analysis\nand a weighted gene correlation network analysis (WGCNA) for five cancer types\nusing data generated by UC Irvine. We further analyze and compare the degree,\ncentrality and betweenness of the network for each cancer type and apply a\nmultinomial logistic regression to identify the critical subset of genes. Given\nthe cancer types provided, our study presents a view of emergent similarities\nand differences across cancer types.\n",
    "query": "Types of cancer",
    "docId": 1100233,
    "score": 29.60438346862793,
    "userScore": 2
  },
  {
    "title": "OncoNetExplainer: Explainable Predictions of Cancer Types Based on Gene\n  Expression Data",
    "paperAbstract": "  The discovery of important biomarkers is a significant step towards\nunderstanding the molecular mechanisms of carcinogenesis; enabling accurate\ndiagnosis for, and prognosis of, a certain cancer type. Before recommending any\ndiagnosis, genomics data such as gene expressions(GE) and clinical outcomes\nneed to be analyzed. However, complex nature, high dimensionality, and\nheterogeneity in genomics data make the overall analysis challenging.\nConvolutional neural networks(CNN) have shown tremendous success in solving\nsuch problems. However, neural network models are perceived mostly as `black\nbox' methods because of their not well-understood internal functioning.\nHowever, interpretability is important to provide insights on why a given\ncancer case has a certain type. Besides, finding the most important biomarkers\ncan help in recommending more accurate treatments and drug repositioning. In\nthis paper, we propose a new approach called OncoNetExplainer to make\nexplainable predictions of cancer types based on GE data. We used genomics data\nabout 9,074 cancer patients covering 33 different cancer types from the\nPan-Cancer Atlas on which we trained CNN and VGG16 networks using\nguided-gradient class activation maps++(GradCAM++). Further, we generate\nclass-specific heat maps to identify significant biomarkers and computed\nfeature importance in terms of mean absolute impact to rank top genes across\nall the cancer types. Quantitative and qualitative analyses show that both\nmodels exhibit high confidence at predicting the cancer types correctly giving\nan average precision of 96.25%. To provide comparisons with the baselines, we\nidentified top genes, and cancer-specific driver genes using gradient boosted\ntrees and SHapley Additive exPlanations(SHAP). Finally, our findings were\nvalidated with the annotations provided by the TumorPortal.\n",
    "query": "Types of cancer",
    "docId": 1174207,
    "score": 29.21158218383789,
    "userScore": 3
  },
  {
    "title": "Dataset of Segmented Nuclei in Hematoxylin and Eosin Stained\n  Histopathology Images of 10 Cancer Types",
    "paperAbstract": "  The distribution and appearance of nuclei are essential markers for the\ndiagnosis and study of cancer. Despite the importance of nuclear morphology,\nthere is a lack of large scale, accurate, publicly accessible nucleus\nsegmentation data. To address this, we developed an analysis pipeline that\nsegments nuclei in whole slide tissue images from multiple cancer types with a\nquality control process. We have generated nucleus segmentation results in\n5,060 Whole Slide Tissue images from 10 cancer types in The Cancer Genome\nAtlas. One key component of our work is that we carried out a multi-level\nquality control process (WSI-level and image patch-level), to evaluate the\nquality of our segmentation results. The image patch-level quality control used\nmanual segmentation ground truth data from 1,356 sampled image patches. The\ndatasets we publish in this work consist of roughly 5 billion quality\ncontrolled nuclei from more than 5,060 TCGA WSIs from 10 different TCGA cancer\ntypes and 1,356 manually segmented TCGA image patches from the same 10 cancer\ntypes plus additional 4 cancer types. Data is available at\nhttps://doi.org/10.7937/tcia.2019.4a4dkp9u\n",
    "query": "Types of cancer",
    "docId": 1245336,
    "score": 29.025779724121094,
    "userScore": 1
  },
  {
    "title": "A Deep Autoencoder System for Differentiation of Cancer Types Based on\n  DNA Methylation State",
    "paperAbstract": "  A Deep Autoencoder based content retrieval algorithm is proposed for\nprediction and differentiation of cancer types based on the presence of\nepigenetic patterns of DNA methylation identified in genetic regions known as\nCpG islands. The developed deep learning system uses a CpG island state\nclassification sub-system to complete sets of missing/incomplete island data in\ngiven human cell lines, and is then pipelined with an intricate set of\nstatistical and signal processing methods to accurately predict the presence of\ncancer and further differentiate the type and cell of origin in the event of a\npositive result. The proposed system was trained with previously reported data\nderived from four case groups of cancer cell lines, achieving overall\nSensitivity of 88.24%, Specificity of 83.33%, Accuracy of 84.75% and Matthews\nCorrelation Coefficient of 0.687. The ability to predict and differentiate\ncancer types using epigenetic events as the identifying patterns was\ndemonstrated in previously reported data sets from breast, lung, lymphoblastic\nleukemia and urological cancer cell lines, allowing the pipelined system to be\nrobust and adjustable to other cancer cell lines or epigenetic events.\n",
    "query": "Types of cancer",
    "docId": 1032430,
    "score": 28.124801635742188,
    "userScore": 2
  },
  {
    "title": "Deep learning-based survival prediction for multiple cancer types using\n  histopathology images",
    "paperAbstract": "  Prognostic information at diagnosis has important implications for cancer\ntreatment and monitoring. Although cancer staging, histopathological\nassessment, molecular features, and clinical variables can provide useful\nprognostic insights, improving risk stratification remains an active research\narea. We developed a deep learning system (DLS) to predict disease specific\nsurvival across 10 cancer types from The Cancer Genome Atlas (TCGA). We used a\nweakly-supervised approach without pixel-level annotations, and tested three\ndifferent survival loss functions. The DLS was developed using 9,086 slides\nfrom 3,664 cases and evaluated using 3,009 slides from 1,216 cases. In\nmultivariable Cox regression analysis of the combined cohort including all 10\ncancers, the DLS was significantly associated with disease specific survival\n(hazard ratio of 1.58, 95% CI 1.28-1.70, p<0.0001) after adjusting for cancer\ntype, stage, age, and sex. In a per-cancer adjusted subanalysis, the DLS\nremained a significant predictor of survival in 5 of 10 cancer types. Compared\nto a baseline model including stage, age, and sex, the c-index of the model\ndemonstrated an absolute 3.7% improvement (95% CI 1.0-6.5) in the combined\ncohort. Additionally, our models stratified patients within individual cancer\nstages, particularly stage II (p=0.025) and stage III (p<0.001). By developing\nand evaluating prognostic models across multiple cancer types, this work\nrepresents one of the most comprehensive studies exploring the direct\nprediction of clinical outcomes using deep learning and histopathology images.\nOur analysis demonstrates the potential for this approach to provide prognostic\ninformation in multiple cancer types, and even within specific pathologic\nstages. However, given the relatively small number of clinical events, we\nobserved wide confidence intervals, suggesting that future work will benefit\nfrom larger datasets.\n",
    "query": "Types of cancer",
    "docId": 1219250,
    "score": 27.98916244506836,
    "userScore": 2
  },
  {
    "title": "Bayesian Methods for the Analysis of Early-Phase Oncology Basket Trials\n  with Information Borrowing across Cancer Types",
    "paperAbstract": "  Research in oncology has changed the focus from histological properties of\ntumors in a specific organ to a specific genomic aberration potentially shared\nby multiple cancer types. This motivates the basket trial, which assesses the\nefficacy of treatment simultaneously on multiple cancer types that have a\ncommon aberration. Although the assumption of homogeneous treatment effects\nseems reasonable given the shared aberration, in reality, the treatment effect\nmay vary by cancer type, and potentially only a subgroup of the cancer types\nrespond to the treatment. Various approaches have been proposed to increase the\ntrial power by borrowing information across cancer types, which, however, tend\nto inflate the type I error rate. In this paper, we review some representative\nBayesian information borrowing methods for the analysis of early-phase basket\ntrials. We then propose a novel method called the Bayesian hierarchical model\nwith a correlated prior (CBHM), which conducts more flexible borrowing across\ncancer types according to sample similarity. We did simulation studies to\ncompare CBHM with independent analysis and three information borrowing\napproaches: the conventional Bayesian hierarchical model, the EXNEX approach\nand Liu's two-stage approach. Simulation results show that all information\nborrowing approaches substantially improve the power of independent analysis if\na large proportion of the cancer types truly respond to the treatment. Our\nproposed CBHM approach shows an advantage over the existing information\nborrowing approaches, with a power similar to that of EXNEX or Liu's approach,\nbut the potential to provide substantially better control of type I error rate.\n",
    "query": "Types of cancer",
    "docId": 1240430,
    "score": 27.69159698486328,
    "userScore": 1
  },
  {
    "title": "Learning from Thresholds: Fully Automated Classification of Tumor\n  Infiltrating Lymphocytes for Multiple Cancer Types",
    "paperAbstract": "  Deep learning classifiers for characterization of whole slide tissue\nmorphology require large volumes of annotated data to learn variations across\ndifferent tissue and cancer types. As is well known, manual generation of\ndigital pathology training data is time consuming and expensive. In this paper,\nwe propose a semi-automated method for annotating a group of similar instances\nat once, instead of collecting only per-instance manual annotations. This\nallows for a much larger training set, that reflects visual variability across\nmultiple cancer types and thus training of a single network which can be\nautomatically applied to each cancer type without human adjustment. We apply\nour method to the important task of classifying Tumor Infiltrating Lymphocytes\n(TILs) in H&E images. Prior approaches were trained for individual cancer\ntypes, with smaller training sets and human-in-the-loop threshold adjustment.\nWe utilize these thresholded results as large scale \"semi-automatic\"\nannotations. Combined with existing manual annotations, our trained deep\nnetworks are able to automatically produce better TIL prediction results in 12\ncancer types, compared to the human-in-the-loop approach.\n",
    "query": "Types of cancer",
    "docId": 1148496,
    "score": 27.641923904418945,
    "userScore": 1
  },
  {
    "title": "Bayesian Semi-nonnegative Tri-matrix Factorization to Identify Pathways\n  Associated with Cancer Types",
    "paperAbstract": "  Identifying altered pathways that are associated with specific cancer types\ncan potentially bring a significant impact on cancer patient treatment.\nAccurate identification of such key altered pathways information can be used to\ndevelop novel therapeutic agents as well as to understand the molecular\nmechanisms of various types of cancers better. Tri-matrix factorization is an\nefficient tool to learn associations between two different entities (e.g.,\ncancer types and pathways in our case) from data. To successfully apply\ntri-matrix factorization methods to biomedical problems, biological prior\nknowledge such as pathway databases or protein-protein interaction (PPI)\nnetworks, should be taken into account in the factorization model. However, it\nis not straightforward in the Bayesian setting even though Bayesian methods are\nmore appealing than point estimate methods, such as a maximum likelihood or a\nmaximum posterior method, in the sense that they calculate distributions over\nvariables and are robust against overfitting. We propose a Bayesian\n(semi-)nonnegative matrix factorization model for human cancer genomic data,\nwhere the biological prior knowledge represented by a pathway database and a\nPPI network is taken into account in the factorization model through a finite\ndependent Beta-Bernoulli prior. We tested our method on The Cancer Genome Atlas\n(TCGA) dataset and found that the pathways identified by our method can be used\nas a prognostic biomarkers for patient subgroup identification.\n",
    "query": "Types of cancer",
    "docId": 919119,
    "score": 27.118816375732422,
    "userScore": 1
  },
  {
    "title": "Noncoding RNAs and deep learning neural network discriminate\n  multi-cancer types",
    "paperAbstract": "  Detecting cancers at early stages can dramatically reduce mortality rates.\nTherefore, practical cancer screening at the population level is needed. Here,\nwe develop a comprehensive detection system to classify all common cancer\ntypes. By integrating artificial intelligence deep learning neural network and\nnoncoding RNA biomarkers selected from massive data, our system can accurately\ndetect cancer vs healthy object with 96.3% of AUC of ROC (Area Under Curve of a\nReceiver Operating Characteristic curve). Intriguinely, with no more than 6\nbiomarkers, our approach can easily discriminate any individual cancer type vs\nnormal with 99% to 100% AUC. Furthermore, a comprehensive marker panel can\nsimultaneously multi-classify all common cancers with a stable 78% of accuracy\nat heterological cancerous tissues and conditions. This provides a valuable\nframework for large scale cancer screening. The AI models and plots of results\nwere available in https://combai.org/ai/cancerdetection/\n",
    "query": "Types of cancer",
    "docId": 1431324,
    "score": 26.624784469604492,
    "userScore": 1
  },
  {
    "title": "Loss impresses human beings more than gain in the decision-making game",
    "paperAbstract": "  What happen in the brain when human beings play games with computers? Here a\nsimple zero-sum game was conducted to investigate how people make decision via\ntheir brain even they know that their opponent is a computer. There are two\nchoices (a low or high number) for people and also two strategies for the\ncomputer (red color or green color). When the number selected by the human\nsubject meet the red color, the person loses the score which is equal to the\nnumber. On the contrary, the person gains the number of score if the computer\nchooses a green color for the number selected by the human being. Both the\nhuman subject and the computer give their choice at the same time, and subjects\nhave been told that the computer make its decision randomly on the red color or\ngreen color. During the experiments, the signal of electroencephalograph (EEG)\nobtained from brain of subjects was recorded. From the analysis of EEG, we find\nthat people mind the loss more than the gain, and the phenomenon becoming\nobvious when the gap between loss and gain grows. In addition, the signal of\nEEG is clearly distinguishable before making different decisions. It is\nobserved that significant negative waves in the entire brain region when the\nparticipant has a greater expectation for the outcome, and these negative waves\nare mainly concentrated in the forebrain region in the brain of human beings.\n",
    "query": "Human beings evolution",
    "docId": 866407,
    "score": 32.401126861572266,
    "userScore": 0
  },
  {
    "title": "Human Niche Evolution: pathways, choices and outcomes",
    "paperAbstract": "  Humankind has spread worldwide supported by cultural and technological\nknowledge, but the environmental sustainability on the human niche evolution\ndepends on a new human beings relationship with the biosphere. Human lifestyles\nnowadays are very Antropocentric and in many ways deleterious to the other life\nforms. Here we try to identify future scenarios, where the less deleterious is\nthe Natural-Technological Model that points the urgent need to change the\nevolutionary direction of the human niche seeking the resumption of original\necological relations. New cultural habits and novel technologies, thereby,\nwould reverse the current anthropogenic impacts. The middle way is the\nBio-Anthropogenic Model that predicts the success of the emerging ecosystems\nand the symbiotic relationship of humans and anthropogenic-favored species,\nhybrids, aliens and genetically modified organisms. For such, we must also\nchange our way of life and adopt new conscious ways of consumption aiming at\nthe socio-environmental good. Lastly, the Wear Out Model, which depends only on\nmaintaining current patterns of human expansion. The lack of investments on new\ntechnologies and new cultural habits, added to the current patterns of human\nniche evolution that are based on the massive exploitation of world resources,\nwill lead to a fearsome scenario with a precarious global health, biodiversity\nlosses and food scarcity. This theoretical models indicates some pathways and\ncan help us to choose a better future.\n",
    "query": "Human beings evolution",
    "docId": 1584628,
    "score": 28.48196029663086,
    "userScore": 1
  },
  {
    "title": "Digital Beings as an option to study gut flora evolution and adaptation",
    "paperAbstract": "  In this work, we introduce a computational model for the study of the\nhost-bacteria interaction and the influence of the intestinal microbiota on the\nbehavior and feeding pattern of an individual. The model is based on digital\nentities, which we've called Digital Beings (DBs), modeled using dynamic\nsystems and genetic algorithms. We have successfully tested the use of the DBs\nby reproducing observation in previously made studies using rats and humans.\nAmong these studies, we highlight those on how the bacteria in an individual's\nstomach could influence their eating behavior and how a controlled and\ncontinuous diet can affect the longevity of a certain population. Our results\npoint that the Digital Beings can be used as a tool for supporting the devising\nof experiments and corroborating with theoretical hypotheses, reducing the\nnumber of in vivo tests.\n",
    "query": "Human beings evolution",
    "docId": 1174598,
    "score": 28.27487564086914,
    "userScore": 2
  },
  {
    "title": "Understanding Human Intelligence through Human Limitations",
    "paperAbstract": "  Recent progress in artificial intelligence provides the opportunity to ask\nthe question of what is unique about human intelligence, but with a new\ncomparison class. I argue that we can understand human intelligence, and the\nways in which it may differ from artificial intelligence, by considering the\ncharacteristics of the kind of computational problems that human minds have to\nsolve. I claim that these problems acquire their structure from three\nfundamental limitations that apply to human beings: limited time, limited\ncomputation, and limited communication. From these limitations we can derive\nmany of the properties we associate with human intelligence, such as rapid\nlearning, the ability to break down problems into parts, and the capacity for\ncumulative cultural evolution.\n",
    "query": "Human beings evolution",
    "docId": 1355553,
    "score": 27.84848976135254,
    "userScore": 1
  },
  {
    "title": "Cogniculture: Towards a Better Human-Machine Co-evolution",
    "paperAbstract": "  Research in Artificial Intelligence is breaking technology barriers every\nday. New algorithms and high performance computing are making things possible\nwhich we could only have imagined earlier. Though the enhancements in AI are\nmaking life easier for human beings day by day, there is constant fear that AI\nbased systems will pose a threat to humanity. People in AI community have\ndiverse set of opinions regarding the pros and cons of AI mimicking human\nbehavior. Instead of worrying about AI advancements, we propose a novel idea of\ncognitive agents, including both human and machines, living together in a\ncomplex adaptive ecosystem, collaborating on human computation for producing\nessential social goods while promoting sustenance, survival and evolution of\nthe agents' life cycle. We highlight several research challenges and technology\nbarriers in achieving this goal. We propose a governance mechanism around this\necosystem to ensure ethical behaviors of all cognitive agents. Along with a\nnovel set of use-cases of Cogniculture, we discuss the road map ahead for this\njourney.\n",
    "query": "Human beings evolution",
    "docId": 922323,
    "score": 27.524791717529297,
    "userScore": 0
  },
  {
    "title": "Atomic beings and the discovery of gravity",
    "paperAbstract": "  We aim to bring a new perspective about some aspects of the current research\nin Cosmology. We start with a brief introduction about the main developments of\nthe field in the last century; then we introduce an analogy that shall\nelucidate the main difficulties that observational sciences involve, which\nmight be part of the issue related to some of the contemporary cosmological\nproblems. The analogy investigates how microscopic beings could ever discover\nand understand gravitational phenomena.\n",
    "query": "Human beings evolution",
    "docId": 678611,
    "score": 25.173812866210938,
    "userScore": 0
  },
  {
    "title": "The ABBE Corpus: Animate Beings Being Emotional",
    "paperAbstract": "  Emotion detection is an established NLP task of demonstrated utility for text\nunderstanding. However, basic emotion detection leaves out key information,\nnamely, who is experiencing the emotion in question. For example, it may be the\nauthor, the narrator, or a character; or the emotion may correspond to\nsomething the audience is supposed to feel, or even be unattributable to a\nspecific being, e.g., when emotions are being discussed per se. We provide the\nABBE corpus -- Animate Beings Being Emotional -- a new double-annotated corpus\nof texts that captures this key information for one class of emotion\nexperiencer, namely, animate beings in the world described by the text. Such a\ncorpus is useful for developing systems that seek to model or understand this\nspecific type of expressed emotion. Our corpus contains 30 chapters, comprising\n134,513 words, drawn from the Corpus of English Novels, and contains 2,010\nunique emotion expressions attributable to 2,227 animate beings. The emotion\nexpressions are categorized according to Plutchik's 8-category emotion model,\nand the overall inter-annotator agreement for the annotations was 0.83 Cohen's\nKappa, indicating excellent agreement. We describe in detail our annotation\nscheme and procedure, and also release the corpus for use by other researchers.\n",
    "query": "Human beings evolution",
    "docId": 1595990,
    "score": 25.117225646972656,
    "userScore": 0
  },
  {
    "title": "New Method for Localization and Human Being Detection using UWB\n  Technology: Helpful Solution for Rescue Robots",
    "paperAbstract": "  Two challenges for rescue robots are to detect human beings and to have an\naccurate positioning system. In indoor positioning, GPS receivers cannot be\nused due to the reflections or attenuation caused by obstacles. To detect human\nbeings, sensors such as thermal camera, ultrasonic and microphone can be\nembedded on the rescue robot. The drawback of these sensors is the detection\nrange. These sensors have to be in close proximity to the victim in order to\ndetect it. UWB technology is then very helpful to ensure precise localization\nof the rescue robot inside the disaster site and detect human beings.\n  We propose a new method to both detect human beings and locate the rescue\nrobot at the same time. To achieve these goals we optimize the design of UWB\npulses based on B-splines. The spectral effectiveness is optimized so the\nsymbols are easier to detect and the mitigation with noise is reduced. Our\npositioning system performs to locate the rescue robot with an accuracy about 2\ncentimeters. During some tests we discover that UWB signal characteristics\nabruptly change after passing through a human body. Our system uses this\nparticular signature to detect human body.\n",
    "query": "Human beings evolution",
    "docId": 485515,
    "score": 24.803136825561523,
    "userScore": 0
  },
  {
    "title": "Evolution of Human-like Social Grooming Strategies regarding Richness\n  and Group Size",
    "paperAbstract": "  Human beings tend to cooperate with close friends, therefore they have to\nconstruct strong social relationships to recieve cooperation from others.\nTherefore they should have acquired their strategies of social relationship\nconstruction through an evolutionary process. The behavior of social\nrelationship construction is know as \"social grooming.\" In this paper, we show\nthat there are four classes including a human-like strategy in evolutionary\ndynamics of social grooming strategies based on an evolutionary game\nsimulation. Social relationship strengths (as measured by frequency of social\ngrooming) often show a much skewed distribution (a power law distribution). It\nmay be due to time costs constraints on social grooming, because the costs are\ntoo large to ignore for having many strong social relationships. Evolution of\nhumans' strategies of construction of social relationships may explain the\norigin of human intelligence based on a social brain hypothesis. We constructed\nan individual-based model to explore the evolutionary dynamics of social\ngrooming strategies. The model is based on behavior to win over others by\nstrengthening social relationships with cooperators. The results of\nevolutionary simulations show the four classes of evolutionary dynamics. The\nresults depend on total resources and the ratio of each cooperator's resource\nto the number of cooperators. One of the four classes is similar to a human\nstrategy, i.e. the strategies based on the Yule--Simon process of power law.\n",
    "query": "Human beings evolution",
    "docId": 874142,
    "score": 24.582794189453125,
    "userScore": 2
  },
  {
    "title": "Human-Centered Autonomous Vehicle Systems: Principles of Effective\n  Shared Autonomy",
    "paperAbstract": "  Building effective, enjoyable, and safe autonomous vehicles is a lot harder\nthan has historically been considered. The reason is that, simply put, an\nautonomous vehicle must interact with human beings. This interaction is not a\nrobotics problem nor a machine learning problem nor a psychology problem nor an\neconomics problem nor a policy problem. It is all of these problems put into\none. It challenges our assumptions about the limitations of human beings at\ntheir worst and the capabilities of artificial intelligence systems at their\nbest. This work proposes a set of principles for designing and building\nautonomous vehicles in a human-centered way that does not run away from the\ncomplexity of human nature but instead embraces it. We describe our development\nof the Human-Centered Autonomous Vehicle (HCAV) as an illustrative case study\nof implementing these principles in practice.\n",
    "query": "Human beings evolution",
    "docId": 1033022,
    "score": 24.01363754272461,
    "userScore": 0
  },
  {
    "title": "The Falling Factorial Basis and Its Statistical Applications",
    "paperAbstract": "  We study a novel spline-like basis, which we name the \"falling factorial\nbasis\", bearing many similarities to the classic truncated power basis. The\nadvantage of the falling factorial basis is that it enables rapid, linear-time\ncomputations in basis matrix multiplication and basis matrix inversion. The\nfalling factorial functions are not actually splines, but are close enough to\nsplines that they provably retain some of the favorable properties of the\nlatter functions. We examine their application in two problems: trend filtering\nover arbitrary input points, and a higher-order variant of the two-sample\nKolmogorov-Smirnov test.\n",
    "query": "expansion of the falling factorial",
    "docId": 521466,
    "score": 43.31834030151367,
    "userScore": 3
  },
  {
    "title": "Some Explicit Formulas for Sums Involving the Binomial Coefficients with\n  the Falling Factorial",
    "paperAbstract": "  Spivey presented a new approach to evaluate combinatorial sums by using\nfinite differences. We present some closed forms for sums involving the\nbinomial coefficients, Fibonacci and Lucas numbers in terms of the falling\nfactorial.\n",
    "query": "expansion of the falling factorial",
    "docId": 731223,
    "score": 37.02899169921875,
    "userScore": 2
  },
  {
    "title": "Higher Derivatives of the Falling Factorial and Related Generalizations\n  of the Stirling and Harmonic Numbers",
    "paperAbstract": "  Through a brute-force approach to calculating the higher derivatives of the\nfalling factorial function, a number of interesting quantities were obtained\nand analyzed. In particular, it was found that a quantity that can be described\nas the \"elementary symmetric harmonic sum\" is a natural way to describe the\nsolutions to such higher derivatives. The relationship of this type of\ngeneralized harmonic number to other quantities discussed in the literature,\nsuch as the r-Stirling numbers, was described in detail.\n",
    "query": "expansion of the falling factorial",
    "docId": 491968,
    "score": 34.99785232543945,
    "userScore": 2
  },
  {
    "title": "A finite sum involving generalized falling factorial polynomials and\n  degenerate Eulerian polynomials",
    "paperAbstract": "  The aim of this paper is twofold. Firstly, we investigate a finite sum\ninvolving the generalized falling factorial polynomials, in some special cases\nof which we express it in terms of the degenerate Stirling numbers of the\nsecond kind, the degenerate Bernoulli polynomials and the degenerate\nFrobenius-Euler polynomials. Secondly, we consider the degenerate Eulerian\npolynomials and deduce the generating function and a recurrence relation for\nthem.\n",
    "query": "expansion of the falling factorial",
    "docId": 1580815,
    "score": 34.21598815917969,
    "userScore": 2
  },
  {
    "title": "Falling Factorials, Generating Functions, and Conjoint Ranking Tables",
    "paperAbstract": "  We investigate the coefficients generated by expressing the falling factorial\n$(xy)_k$ as a linear combination of falling factorial products $(x)_l (y)_m$\nfor $l,m =1,...,k$. Algebraic and combinatoric properties of these coefficients\nare discussed, including recurrence relations, closed-form formulae, relations\nwith Stirling numbers, and a combinatorial characterization in terms of\nconjoint ranking tables.\n",
    "query": "expansion of the falling factorial",
    "docId": 88906,
    "score": 32.279541015625,
    "userScore": 2
  },
  {
    "title": "On the Influence of Momentum Conservation upon the Scaling Behaviour of\n  Factorial Moments in High Energy Multiparticle Production",
    "paperAbstract": "  The experimental results on the falling down of scaled factorial moments in\nazimuthal variable $\\phi$ is studied in some detail. It is shown that this\nphenomenon may be referred to the influence of transverse momentum\nconservation. The existing experimental data from DELPHI, EMU08, NA22 and UA1\nare successfully explained. Various methods are proposed to partly eliminate\nthis influence and rule out the 'falling down' of factorial moments.\n",
    "query": "expansion of the falling factorial",
    "docId": 2053294,
    "score": 30.30419921875,
    "userScore": 2
  },
  {
    "title": "Calculation of some determinants using the s-shifted factorial",
    "paperAbstract": "  Several determinants with gamma functions as elements are evaluated. This\nkind of determinants are encountered in the computation of the probability\ndensity of the determinant of random matrices. The s-shifted factorial is\ndefined as a generalization for non-negative integers of the power function,\nthe rising factorial (or Pochammer's symbol) and the falling factorial. It is a\nspecial case of polynomial sequence of the binomial type studied in\ncombinatorics theory. In terms of the gamma function, an extension is defined\nfor negative integers and even complex values. Properties, mainly composition\nlaws and binomial formulae, are given. They are used to evaluate families of\ngeneralized Vandermonde determinants with s-shifted factorials as elements,\ninstead of power functions.\n",
    "query": "expansion of the falling factorial",
    "docId": 2111902,
    "score": 29.391298294067383,
    "userScore": 0
  },
  {
    "title": "A Littlewood-Richardson Rule for factorial Schur functions",
    "paperAbstract": "  We give a combinatorial rule for calculating the coefficients in the\nexpansion of a product of two factorial Schur functions. It is a special case\nof a more general rule which also gives the coefficients in the expansion of a\nskew factorial Schur function. Multiplication rules for the Capelli operators\nand quantum immanants are also given.\n",
    "query": "expansion of the falling factorial",
    "docId": 2203273,
    "score": 28.72976303100586,
    "userScore": 0
  },
  {
    "title": "The asymptotic expansion for the factorial and Lagrange inversion\n  formula",
    "paperAbstract": "  We obtain an explicit simple formula for the coefficients of the asymptotic\nexpansion for the factorial of a natural number,in terms of derivatives of\npowers of an elementary function. The unique explicit expression for the\ncoefficients that appears to be known is that in the book by L. Comtet, which\nis given in terms of sums of associated Stirling numbers of the first kind. By\nconsidering the bivariate generating function of the associated Stirling\nnumbers of the second kind, another expression for the coefficients in terms of\nthem follows also from our analysis. Comparison with Comtet's expression yields\ncombinatorial identities between associated Stirling numbers of first and\nsecond kind. It suggests by analogy another possible formula for the\ncoefficients, in terms of a function involving the logarithm, that in fact\nproves to be true. The resulting coefficients, as well as the first ones are\nidentified via the Lagrange inversion formula as the odd coefficients of the\ninverse of a pair of formal series, which permits us to obtain also some\nrecurrences.\n",
    "query": "expansion of the falling factorial",
    "docId": 174653,
    "score": 27.699199676513672,
    "userScore": 0,
    "inAnnoy": true
  },
  {
    "title": "Uniform Factorial Decay Estimate for the Remainder of Rough Taylor\n  Expansion",
    "paperAbstract": "  We establish an uniform factorial decay estimate for the Taylor approximation\nof solutions to controlled differential equations. Its proof requires a\nfactorial decay estimate for controlled paths which is interesting in its own\nright.\n",
    "query": "expansion of the falling factorial",
    "docId": 598776,
    "score": 27.610637664794922,
    "userScore": 0
  },
  {
    "title": "Negative probabilities, II: What they are and what they are for",
    "paperAbstract": "  A signed probability distribution may extend a given traditional probability\nfrom observable events to all events. We formalize and illustrate this\napproach. We also illustrate its limitation. We argue that the right question\nis not what negative probabilities are but what they are for.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 1007588,
    "score": 24.225210189819336,
    "userScore": 0
  },
  {
    "title": "Definitively Identifying an Inherent Limitation to Actual Cognition",
    "paperAbstract": "  A century ago, discoveries of a serious kind of logical error made separately\nby several leading mathematicians led to acceptance of a sharply enhanced\nstandard for rigor within what ultimately became the foundation for Computer\nScience. By 1931, Godel had obtained a definitive and remarkable result: an\ninherent limitation to that foundation. The resulting limitation is not\napplicable to actual human cognition, to even the smallest extent, unless both\nof these extremely brittle assumptions hold: humans are infallible reasoners\nand reason solely via formal inference rules. Both assumptions are contradicted\nby empirical data from well-known Cognitive Science experiments. This article\ninvestigates how a novel multi-part methodology recasts computability theory\nwithin Computer Science to obtain a definitive limitation whose application to\nhuman cognition avoids assumptions contradicting empirical data. The limitation\napplies to individual humans, to finite sets of humans, and more generally to\nany real-world entity.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 1131446,
    "score": 23.802675247192383,
    "userScore": 0
  },
  {
    "title": "What is Quantum Computation?",
    "paperAbstract": "  Quantum computation is a rapidly progressing field today. What are its\nprinciples? In what sense is it distinct from conventional computation? What\nare its advantages and disadvantages? What type of problems can it address? How\npractical is it to make a quantum computer? I summarise some of the important\nconcepts of quantum computation, in an attempt to answer these questions. A\ndeeper understanding of them would pave the way for future development.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 2226132,
    "score": 23.78379249572754,
    "userScore": 1
  },
  {
    "title": "Evaluating holonomic quantum computation: beyond adiabatic limitation",
    "paperAbstract": "  The proposal of the optical scheme for holonomic quantum computation is\nevaluated based on dynamical resolution to the system beyond adiabatic\nlimitation. The time-dependent Schr\\\"{o}dinger equation is exactly solved by\nvirtue of the cranking representation and gauge transformation approach.\nBesides providing rigorous confirmation to holonomies of the geometrical\nprediction that holds for the ideally adiabatic situation, the dynamical\nresolution enables one to evaluate elaborately the amplitude of the\nnonadiabatic deviation, so that the errors induced to the quantum computation\ncan be explicitly estimated.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 2210244,
    "score": 23.51161003112793,
    "userScore": 1
  },
  {
    "title": "Fundamental Limitation on the Detectability of Entanglement",
    "paperAbstract": "  Entanglement detection is essential in quantum information science and\nquantum many-body physics. It has been proved that entanglement exists almost\nsurely for a random quantum state, while the realizations of effective\nentanglement criteria usually consume exponential resources, and efficient\ncriteria often perform poorly without prior knowledge. This fact implies a\nfundamental limitation might exist in the detectability of entanglement. In\nthis work, we formalize this limitation as a fundamental trade-off between the\nefficiency and effectiveness of entanglement criteria via a systematic method\nto theoretically evaluate the detection capability of entanglement criteria.\nFor a system coupled to an environment, we prove that any entanglement\ncriterion needs exponentially many observables to detect the entanglement\neffectively when restricted to single-copy operations. Otherwise, the detection\ncapability of the criterion will decay double-exponentially. Furthermore, if\nmulti-copy joint measurements are allowed, the effectiveness of entanglement\ndetection can be exponentially improved, which implies a quantum advantage in\nentanglement detection problems.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 1693230,
    "score": 23.09756851196289,
    "userScore": 2
  },
  {
    "title": "What is quantum in quantum randomness?",
    "paperAbstract": "  It is often said that quantum and classical randomness are of different\nnature, the former being ontological and the latter epistemological. However,\nso far the question of \"What is quantum in quantum randomness\", i.e. what is\nthe impact of quantization and discreteness on the nature of randomness,\nremains to answer. In a first part, we explicit the differences between quantum\nand classical randomness within a recently proposed ontology for quantum\nmechanics based on contextual objectivity. In this view, quantum randomness is\nthe result of contextuality and quantization. We show that this approach\nstrongly impacts the purposes of quantum theory as well as its areas of\napplication. In particular, it challenges current programs inspired by\nclassical reductionism, aiming at the emergence of the classical world from a\nlarge number of quantum systems. In a second part, we analyze quantum physics\nand thermodynamics as theories of randomness, unveiling their mutual\ninfluences. We finally consider new technological applications of quantum\nrandomness opened in the emerging field of quantum thermodynamics.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 966500,
    "score": 22.478378295898438,
    "userScore": 1
  },
  {
    "title": "Gravitational Mass, Its Mechanics - What It Is; How It Operates",
    "paperAbstract": "  The earlier paper, Inertial Mass, Its Mechanics - What It Is; How It\nOperates, developed the mechanics of inertial mass. The present paper is for\nthe purpose of equivalently developing gravitation.\n  The behavior of gravitation is well known, as described by Newton's Law of\nGravitation. But just what gravitational mass is, how gravitational behavior\ncomes about, what in material reality produces the effects of gravitational\nmass, has been little understood. The only extant hypotheses involve the\nunsuccessful efforts to develop \"quantum gravitation\" and to tie it into the\nrest of quantum mechanics, and the equally failed attempts to detect\n\"gravitons\" and \"gravitational waves\" in spite of very substantial efforts.\n  From a starting point of only the limitation on the speed of light, the\nnecessity of conservation, and the impossibility of an infinity in material\nreality, the present paper presents a new and comprehensive analysis of the\nphenomenon gravitational mass:\n  - how it appears in particles,\n  - how the Newtonian gravitational behavior arises from that, and\n  - how the values of inertial mass and gravitational mass are identical, or,\nin other words, the mechanics of gravitational mass and gravitation.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 2201696,
    "score": 21.019411087036133,
    "userScore": 1
  },
  {
    "title": "A limitation on the KPT interpolation",
    "paperAbstract": "  We prove a limitation on a variant of the KPT theorem proposed for\npropositional proof systems by Pich and Santhanam (2020), for all proof systems\nthat prove the disjointness of two NP sets that are hard to distinguish.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 1267218,
    "score": 20.844581604003906,
    "userScore": 0
  },
  {
    "title": "What is Statistics?; The Answer by Quantum Language",
    "paperAbstract": "  Since the problem: \"What is statistics?\" is most fundamental in sceince, in\norder to solve this problem, there is every reason to believe that we have to\nstart from the proposal of a worldview. Recently we proposed measurement theory\n(i.e., quantum language, or the linguistic interpretation of quantum\nmechanics), which is characterized as the linguistic turn of the Copenhagen\ninterpretation of quantum mechanics. This turn from physics to language does\nnot only extend quantum theory to classical theory but also yield the quantum\nmechanical world view (i.e., the (quantum) linguistic world view, and thus, a\nform of quantum thinking, in other words, quantum philosophy). Thus, we believe\nthat the quantum lingistic formulation of statistics gives an answer to the\nquestion: \"What is statistics?\". In this paper, this will be done through the\nstudies of inference interval, statistical hypothesis testing, Fisher maximum\nlikelihood method, Bayes method and regression analysis in meaurement theory.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 353621,
    "score": 20.814411163330078,
    "userScore": 0
  },
  {
    "title": "Limitation of capsule networks",
    "paperAbstract": "  A recently proposed method in deep learning groups multiple neurons to\ncapsules such that each capsule represents an object or part of an object.\nRouting algorithms route the output of capsules from lower-level layers to\nupper-level layers. In this paper, we prove that state-of-the-art routing\nprocedures decrease the expressivity of capsule networks. More precisely, it is\nshown that EM-routing and routing-by-agreement prevent capsule networks from\ndistinguishing inputs and their negative counterpart. Therefore, only symmetric\nfunctions can be expressed by capsule networks, and it can be concluded that\nthey are not universal approximators. We also theoretically motivate and\nempirically show that this limitation affects the training of deep capsule\nnetworks negatively. Therefore, we present an incremental improvement for\nstate-of-the-art routing algorithms that solves the aforementioned limitation\nand stabilizes the training of capsule networks.\n",
    "query": "What is the limitation of quantum mechanics?",
    "docId": 1127180,
    "score": 20.635700225830078,
    "userScore": 0
  }
]
