[{
        "title": "Black Rings in (Anti)-deSitter space",
        "paperAbstract": "  We construct solutions for thin black rings in Anti-deSitter and deSitter\nspacetimes using approximate methods. Black rings in AdS exist with arbitrarily\nlarge radius and satisfy a bound |J| \\leq LM, which they saturate as their\nradius becomes infinitely large. For angular momentum near the maximum, they\nhave larger area than rotating AdS black holes. Thin black rings also exist in\ndeSitter space, with rotation velocities varying between zero and a maximum,\nand with a radius that is always strictly below the Hubble radius. Our general\nanalysis allows us to include black Saturns as well, which we discuss briefly.\nWe present a simple physical argument why supersymmetric AdS black rings must\nnot be expected: they do not possess the necessary pressure to balance the AdS\npotential. We discuss the possible existence or absence of `large AdS black\nrings\u0027 and their implications for a dual hydrodynamic description. An analysis\nof the physical properties of rotating AdS black holes is also included.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 67967,
        "score": 17.367794036865234
    },
    {
        "title": "Black Holes as Dark Matter",
        "paperAbstract": "  While the energy of the universe has been established to be about 0.04\nbaryons, 0.24 dark matter and 0.72 dark energy, the cosmological entropy is\nalmost entirely, about $(1 - 10^{-15})$, from black holes and only $10^{-15}$\nfrom everything else. This identification of all dark matter as black holes is\nnatural in statistical mechanics. Cosmological history of dark matter is\ndiscussed.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 133869,
        "score": 15.658559799194336
    },
    {
        "title": "Maxwell\u0027s equal area law for charged Anti-deSitter black holes",
        "paperAbstract": "  In this paper we present the construction of the Maxwell equal area law in\nthe Hawking temperature graph for a charged black hole in Anti-deSitter\nbackground. We are able to find exact solution for the corresponding isotherm\nand entropies for \"gaseous\" (large) black holes and \"liquid\" (near-extremal)\nblack holes. Isothermal construction removes the unphysical, negative heat\ncapacity, regions. Furthermore, extremal black holes turn out to be dual to\n\"un-shrinkable\" molecules of Van der Waals real fluid, which may explain their\nthermodynamical stability.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 430647,
        "score": 14.335614204406738
    },
    {
        "title": "Anti-DeSitter Spaces and Nonextreme Black Holes",
        "paperAbstract": "  At low energy the near horizon geometry of nonextreme black holes in four\ndimensions exhibits an effective SL(2,R)_L x SL(2,R)_R symmetry. The parameters\nof the corresponding induced conformal field theory gives the correct\nexpression for the black hole entropy. The resulting spectrum of the\nSchwarzchild black hole is compared with another proposal.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 2105013,
        "score": 14.291274070739746
    },
    {
        "title": "Phase transitions of regular Schwarzschild-Anti-deSitter black holes",
        "paperAbstract": "  We study a solution of the Einstein\u0027s equations generated by a\nself-gravitating, anisotropic, static, non-singular matter fluid. The resulting\nSchwarzschild like solution is regular and accounts for smearing effects of\nnoncommutative fluctuations of the geometry. We call this solution regular\nSchwarzschild spacetime. In the presence of an Anti-deSitter cosmological term,\nthe regularized metric offers an extension of the Hawking-Page transition into\na van der Waals-like phase diagram. Specifically the regular\nSchwarzschild-Anti-deSitter geometry undergoes a first order small/large black\nhole transition similar to the liquid/gas transition of a real fluid. In the\npresent analysis we have considered the cosmological constant as a dynamical\nquantity and its variation is included in the first law of black hole\nthermodynamics.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 595965,
        "score": 14.13358211517334
    },
    {
        "title": "On the Penrose inequality in anti-deSitter space",
        "paperAbstract": "  For asymptotically flat spacetimes the Penrose inequality gives an initial\ndata test for the weak cosmic censorship hypothesis. We give a formulation of\nthis inequality for asymptotically anti-deSitter (AAdS) spacetimes, and show\nthat the inequality holds for time asymmetric data in spherical symmetry. Our\nanalysis is motivated by the constant-negative-spatial-curvature form of the\nAdS black hole metric.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 887261,
        "score": 13.714751243591309
    },
    {
        "title": "Schottky Anomaly of deSitter Black Holes",
        "paperAbstract": "  The interplay of black hole and cosmological horizons introduces distinctive\nthermodynamic behavior for deSitter black holes, including well-known upper\nbounds for the mass and entropy. We point to a new such feature, a Schottky\npeak in the heat capacity of Schwarzschild-deSitter (SdS) black holes. With\nthis behavior in mind, we explore statistical models for the underlying quantum\ndegrees of freedom of SdS holes. While a simple two-state spin model gives\nSchottky behavior, in order to capture the non-equilibrium nature of the SdS\nsystem we consider a system with a large number of non-interacting spins. We\nexamine to what extent constrained states of this system reproduce the\nthermodynamic properties of the black hole. We also review results of a recent\nstudy of particle production in SdS spacetimes in light of the Schottky anomaly\nand our spin models.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 1144784,
        "score": 13.460054397583008
    },
    {
        "title": "Dark Matter Jets of Rotating Black Holes",
        "paperAbstract": "  We present a novel approach which produces Dark Matter jets along the\nrotation axis of Kerr black holes utilizing the Penrose process. The properties\nof these jets are investigated, as well as their potential to create Dark\nMatter overdensities in the solar system and in the vicinity of the black hole.\nWe discover a highly collimated and long-range Dark Matter jet with a density\nthat is most sensitive to the mass and distance to the black hole.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 1663920,
        "score": 13.228050231933594
    },
    {
        "title": "Identification of All Dark Matter as Black Holes",
        "paperAbstract": "  For the universe I use dimensionless entropy $S/k \u003d \\ln \\Omega$ for which the\nmost convenient unit is the googol ($10^{100}$) and identify all dark matter as\nblack holes whereupon the present entropy is about a thousand googols. While\nthe energy of the universe has been established to be about 0.04 baryons, 0.24\ndark matter and 0.72 dark energy, the cosmological entropy is almost entirely,\nabout $(1 - 10^{-15})$, from black holes and only $10^{-15}$ from everything\nelse. This identification of all dark matter as black holes is natural in\nstatistical mechanics.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 125228,
        "score": 13.190013885498047
    },
    {
        "title": "Dark energy - dark matter - and black holes: The music of the universe",
        "paperAbstract": "  Here we review the recent evidence for dark energy, dark matter and black\nholes as components of an expanding universe, for the vantage point of a\nnon-expert; we speculate on a specific DM particle.\n",
        "query": "dark matter and black holes  anti-desitter space",
        "docId": 1857613,
        "score": 13.000394821166992
    },
    {
        "title": "Room-Temperature Superconductivity",
        "paperAbstract": "  This is the first book on the subject of room-temperature superconductivity.\nThe main purpose of the book is twofold. First, to show that, under suitable\nconditions, superconductivity can occur above room temperature. Secondly, to\npresent general guidelines on how to synthesize a room temperature\nsuperconductor. The book begins with an introduction into the physics of the\nsuperconducting state and superconducting materials. The mechanisms of\nconventional, half-conventional and unconventional superconductivity are\ndiscussed in the following chapters. The last three chapters of the book are\ndevoted to room temperature superconductivity. In Chapter 2, an attempt to\nreview the basic properties of the superconducting state independently of any\nspecific mechanism is made for the first time. In addition, four principles of\nsuperconductivity valid for any type of superconductivity are introduced in\nChapter 4. The book is mainly addressed to specialists in materials science and\nin the field of superconductivity. At the same time, students will also benefit\nfrom reading the first nine chapters of the book.\n",
        "query": "room temperature super conductor",
        "docId": 1945581,
        "score": 10.079328536987305
    },
    {
        "title": "Design for a Room Temperature Superconductor",
        "paperAbstract": "  The vision of ``room temperature superconductivity\u0027\u0027 has appeared\nintermittently but prominently in the literature since 1964, when W. A. Little\nand V. L. Ginzburg began working on the `problem of high temperature\nsuperconductivity\u0027 around the same time. Since that time the prospects for room\ntemperature superconductivity have varied from gloom (around 1980) to glee (the\nyears immediately after the discovery of HTS), to wait-and-see (the current\nfeeling). Recent discoveries have clarified old issues, making it possible to\nconstruct the blueprint for a viable room temperature superconductor.\n",
        "query": "room temperature super conductor",
        "docId": 1943581,
        "score": 9.319879531860352
    },
    {
        "title": "Coupling two laser-cooled ions via a room-temperature conductor",
        "paperAbstract": "  We demonstrate coupling between the motions of two independently trapped ions\nwith a separation distance of 620 $\\mu$m. The ion-ion interaction is enhanced\nvia a room-temperature electrically floating metallic wire which connects two\nsurface traps. Tuning the motion of both ions into resonance, we show flow of\nenergy with a coupling rate of 11 Hz. Quantum-coherent coupling is hindered by\nstrong surface electric-field noise in our device. Our ion wire-ion system\ndemonstrates that room-temperature conductors can be used to mediate and tune\ninteractions between independently trapped charges over distances beyond those\nachievable with free-space dipole-dipole coupling. This technology may be used\nto sympathetically cool or entangle remotely trapped charges and enable\ncoupling between disparate physical systems.\n",
        "query": "room temperature super conductor",
        "docId": 1494863,
        "score": 9.229804992675781
    },
    {
        "title": "Polariton condensates at room temperature",
        "paperAbstract": "  We review the recent developments of the polariton physics in microcavities\nfeaturing the exciton-photon strong coupling at room-temperature, and leading\nto the achievement of room-temperature polariton condensates. Such cavities\nembed active layers with robust excitons that present a large binding energy\nand a large oscillator strength, i.e. wide bandgap inorganic or organic\nsemiconductors, or organic molecules. These various systems are compared, in\nterms of figures of merit and of common features related to their strong\noscillator strength. The various demonstrations of polariton laser are\ncompared, as well as their condensation phase diagrams. The room-temperature\noperation indeed allows a detailed investigation of the thermodynamic and\nout-of-equilibrium regimes of the condensation process. The crucial role of the\nspatial dynamics of the condensate formation is discussed, as well as the\ndebated issue of the mechanism of stimulated relaxation from the reservoir to\nthe condensate under non-resonant excitation. Finally the prospects of\npolariton devices are presented.\n",
        "query": "room temperature super conductor",
        "docId": 714514,
        "score": 8.728954315185547
    },
    {
        "title": "Enhanced Radiation ? from (Super) Conductor by Dark Matter Axion",
        "paperAbstract": "  In our previous paper we have shown that enhanced radiations arise from\n(super) conductor by dark matter axion under strong magnetic field. We have\nrecalculated the radiation by carefully treating boundary conditions between\nvacuum and the conductor. We show that the radiation is never enhanced. We\ninterpret it such that electromagnetic field induced by axion collides the\nconductor and it is reflected by the conductor. The reflecting wave is the\nradiation from the conductor. It is reasonable that the amplitude of the\nreflection wave is identical to that of the incoming wave, i.e. radiation\ninduced by axion.\n",
        "query": "room temperature super conductor",
        "docId": 1556667,
        "score": 8.653924942016602
    },
    {
        "title": "Novel approach to Room Temperature Superconductivity problem",
        "paperAbstract": "  A long-standing problem of observing Room Temperature Superconductivity is\nfinally solved by a novel approach. Instead of increasing the critical\ntemperature Tc of a superconductor, the temperature of the room was decreased\nto an appropriate Tc value. We consider this approach more promising for\nobtaining a large number of materials possessing Room Temperature\nSuperconductivity in the near future.\n",
        "query": "room temperature super conductor",
        "docId": 1264676,
        "score": 8.635948181152344
    },
    {
        "title": "Proposal of room-temperature diamond maser",
        "paperAbstract": "  Lasers have revolutionized optical science and technology, but their\nmicrowave counterpart, maser, has not realized its great potential due to its\ndemanding work conditions (high-vacuum for gas maser and liquid-helium\ntemperature for solid-state maser). Room-temperature solid-state maser is\nhighly desirable, but under such conditions the lifetimes of emitters (usually\nelectron spins) are usually too short (~ns) for population inversion. The only\nroom-temperature solid-state maser is based on a pentacene-doped p-terphenyl\ncrystal, which has long spin lifetime (~0.1 ms). This maser, however, operates\nonly in the pulse mode and the material is unstable. Here we propose\nroom-temperature maser based on nitrogen-vacancy (NV) centres in diamond, which\nfeature long spin lifetimes at room temperature (~10 ms), high optical pump\nefficiency, and material stability. We demonstrate that under readily\naccessible conditions, room-temperature diamond maser is feasible.\nRoom-temperature diamond maser may facilitate a broad range of microwave\ntechnologies.\n",
        "query": "room temperature super conductor",
        "docId": 662548,
        "score": 8.519661903381348
    },
    {
        "title": "The Regularity of the Conductor",
        "paperAbstract": "  We bound the Castelnuovo-Mumford regularity and syzygies of the ideal of the\nsingular set of a plane curve, and more generally of the conductor scheme of\ncertain projectively Gorenstein varieties.\n",
        "query": "room temperature super conductor",
        "docId": 410092,
        "score": 8.464476585388184
    },
    {
        "title": "Room-Temperature Skyrmion Thermopower in Fe3Sn2",
        "paperAbstract": "  We present first room-temperature thermoelectric signature of the skyrmion\nlattice. This was observed in Fe3Sn2, a Kagome Dirac crystal with massive Dirac\nfermions that features high-temperature skyrmion phase. The room-temperature\nskyrmion lattice shows magnetic-field dependence of the wavevector whereas\nthermopower is dominated by the electronic diffusion mechanism, allowing for\nthe skyrmionic bubble lattice detection. Our results pave the way for the\nfuture skyrmion-based devices based on the manipulation of the thermal\ngradient.\n",
        "query": "room temperature super conductor",
        "docId": 1334241,
        "score": 8.307734489440918
    },
    {
        "title": "A room temperature optomechanical squeezer",
        "paperAbstract": "  One of the noise sources that currently limits gravitational wave (GW)\ndetectors comes from the quantum nature of the light causing uncertain\namplitude and phase. Phase uncertainty limits the precision of an\ninterferometric measurement. This measurement is also subject to quantum\nback-action, caused by the radiation pressure force fluctuations produced by\nthe amplitude uncertainty (QRPN). In order to lower this quantum noise, GW\ndetectors plan to use squeezed light injection. In this thesis, I focus on\nusing radiation-pressure-mediated optomechanical (OM) interaction to generate\nsqueezed light. Creating squeezed states by using OM interaction enables\nwavelength-independent squeezed light sources that may also be more compact and\nrobust than traditionally used non-linear crystals. We analyze the system with\nrealistic imperfections (losses \u0026 classical noise), and use the concepts to\ndesign an experiment to obtain the most possible squeezing in a broad\naudio-frequency band at room temperature. This involves an optimization for the\noptical properties of the cavity and the mechanical properties of the\noscillator. We then show its experimental implementation, and subsequent\nobservation of QRPN as well as OM squeezing. These are the first ever direct\nobservations of a room temperature oscillator\u0027s motion being overwhelmed by\nvacuum fluctuations. This is shown in the low frequency band, which is relevant\nto GW detectors, but poses its own technical challenges, and hence has not been\ndone before. Being in the back-action dominated regime along with optimized\noptical properties has also enabled us to observe OM squeezing. That is the\nfirst direct observation of quantum noise suppression in a room temperature OM\nsystem. It is also the first direct evidence of quantum correlations in the\naudio frequency band, in a broad band at non-resonant frequencies.\n",
        "query": "room temperature super conductor",
        "docId": 1308837,
        "score": 8.245442390441895
    },
    {
        "title": "Quantum Computational Supremacy",
        "paperAbstract": "  The field of quantum algorithms aims to find ways to speed up the solution of\ncomputational problems by using a quantum computer. A key milestone in this\nfield will be when a universal quantum computer performs a computational task\nthat is beyond the capability of any classical computer, an event known as\nquantum supremacy. This would be easier to achieve experimentally than\nfull-scale quantum computing, but involves new theoretical challenges. Here we\npresent the leading proposals to achieve quantum supremacy, and discuss how we\ncan reliably compare the power of a classical computer to the power of a\nquantum computer.\n",
        "query": "quantum computer supremacy ",
        "docId": 1027458,
        "score": 13.035778045654297
    },
    {
        "title": "The Road to Quantum Computational Supremacy",
        "paperAbstract": "  We present an idiosyncratic view of the race for quantum computational\nsupremacy. Google\u0027s approach and IBM challenge are examined. An unexpected\nside-effect of the race is the significant progress in designing fast classical\nalgorithms. Quantum supremacy, if achieved, won\u0027t make classical computing\nobsolete.\n",
        "query": "quantum computer supremacy ",
        "docId": 919955,
        "score": 10.938274383544922
    },
    {
        "title": "On the meaning of \"quantum supremacy\" experiments",
        "paperAbstract": "  The recently reported experimental results claiming \"quantum supremacy\"\nachieved by Google quantum device are critically discussed. The Google team\nconstructed a quantum chaotic system based on Josephson junction technology\nwhich cannot be reliably simulated by the present day supercomputers. However,\nthe similar \"supremacy\" can be realized for properly designed micro-mechanical\ndevices, like periodically forced Duffing oscillator, using the available\ntechnology of quartz clocks. It is also reminded that classical and quantum\nchaotic systems behave in a similar way. Therefore, in this case, one should\nspeak rather about the \"analog supremacy\" than \"quantum supremacy\" what means\nthat even now mechanical analog computers can outperform supercomputers when\nthe computational task can be reduced to sampling of ergodic measures generated\nby chaotic systems.\n",
        "query": "quantum computer supremacy ",
        "docId": 1226204,
        "score": 10.487651824951172
    },
    {
        "title": "Noise Threshold of Quantum Supremacy",
        "paperAbstract": "  Demonstrating quantum supremacy, a complexity-guaranteed quantum advantage\nagainst over the best classical algorithms by using less universal quantum\ndevices, is an important near-term milestone for quantum information\nprocessing. Here we develop a threshold theorem for quantum supremacy with\nnoisy quantum circuits in the pre-threshold region, where quantum error\ncorrection does not work directly. We show that, even in such a region, we can\nvirtually simulate quantum error correction by postselection. This allows us to\nshow that the output sampled from the noisy quantum circuits (without\npostselection) cannot be simulated efficiently by classical computers based on\na stable complexity theoretical conjecture, i.e., non-collapse of the\npolynomial hierarchy. By applying this to fault-tolerant quantum computation\nwith the surface codes, we obtain the threshold value $2.84\\%$ for quantum\nsupremacy, which is much higher than the standard threshold $0.75\\%$ for\nuniversal fault-tolerant quantum computation with the same circuit-level noise\nmodel. Moreover, contrast to the standard noise threshold, the origin of\nquantum supremacy in noisy quantum circuits is quite clear; the threshold is\ndetermined purely by the threshold of magic state distillation, which is\nessential to gain a quantum advantage.\n",
        "query": "quantum computer supremacy ",
        "docId": 778979,
        "score": 10.387914657592773
    },
    {
        "title": "Quantum supremacy and random circuits",
        "paperAbstract": "  As Moore\u0027s law reaches its limits, quantum computers are emerging with the\npromise of dramatically outperforming classical computers. We have witnessed\nthe advent of quantum processors with over $50$ quantum bits (qubits), which\nare expected to be beyond the reach of classical simulation. Quantum supremacy\nis the event at which the old Extended Church-Turing Thesis is overturned: A\nquantum computer performs a task that is practically impossible for any\nclassical (super)computer. The demonstration requires both a solid theoretical\nguarantee and an experimental realization. The lead candidate is Random Circuit\nSampling (RCS), which is the task of sampling from the output distribution of\nrandom quantum circuits. Google recently announced a $53-$qubit experimental\ndemonstration of RCS. Soon after, classical algorithms appeared that challenge\nthe supremacy of random circuits by estimating their outputs. How hard is it to\nclassically simulate the output of random quantum circuits?\n  We prove that estimating the output probabilities of random quantum circuits\nis formidably hard ($\\#P$-Hard) for any classical computer. This makes RCS the\nstrongest candidate for demonstrating quantum supremacy relative to all other\nproposals. The robustness to the estimation error that we prove may serve as a\nnew hardness criterion for the performance of classical algorithms. To achieve\nthis, we introduce the Cayley path interpolation between any two gates of a\nquantum computation and convolve recent advances in quantum complexity and\ninformation with probability and random matrices. Furthermore, we apply\nalgebraic geometry to generalize the well-known Berlekamp-Welch algorithm that\nis widely used in coding theory and cryptography. Our results imply that there\nis an exponential hardness barrier for the classical simulation of most quantum\ncircuits.\n",
        "query": "quantum computer supremacy ",
        "docId": 1176248,
        "score": 10.356671333312988
    },
    {
        "title": "Quantum supremacy and quantum phase transitions",
        "paperAbstract": "  Demonstrating the ability of existing quantum platforms to perform certain\ncomputational tasks intractable to classical computers represents a cornerstone\nin quantum computing. Despite the growing number of such proposed \"quantum\nsupreme\" tasks, it remains an important challenge to identify their direct\napplications. In this work, we describe how the approach proposed in Ref.\n[arXiv:2002.11946] for demonstrating quantum supremacy in generic driven analog\nmany-body systems, such as those found in cold atom and ion setups, can be\nextended to explore dynamical quantum phase transitions. We show how key\nquantum supremacy signatures, such as the distance between the output\ndistribution and the expected Porter Thomas distribution at the supremacy\nregime, can be used as effective order parameters. We apply this approach to a\nperiodically driven disordered 1D Ising model and show that we can accurately\ncapture the transition between the driven thermalized and many-body localized\nphases. This approach also captures the transition towards the Floquet\nprethermalized regime for high-frequency driving. Revisiting quantum phases of\nmatter under the light of the recent discussions about quantum supremacy draws\na link between complexity theory and analog many-body systems.\n",
        "query": "quantum computer supremacy ",
        "docId": 1394337,
        "score": 10.101765632629395
    },
    {
        "title": "Quantum Sampling Problems, BosonSampling and Quantum Supremacy",
        "paperAbstract": "  There is a large body of evidence for the potential of greater computational\npower using information carriers that are quantum mechanical over those\ngoverned by the laws of classical mechanics. But the question of the exact\nnature of the power contributed by quantum mechanics remains only partially\nanswered. Furthermore, there exists doubt over the practicality of achieving a\nlarge enough quantum computation that definitively demonstrates quantum\nsupremacy. Recently the study of computational problems that produce samples\nfrom probability distributions has added to both our understanding of the power\nof quantum algorithms and lowered the requirements for demonstration of fast\nquantum algorithms. The proposed quantum sampling problems do not require a\nquantum computer capable of universal operations and also permit physically\nrealistic errors in their operation. This is an encouraging step towards an\nexperimental demonstration of quantum algorithmic supremacy. In this paper, we\nwill review sampling problems and the arguments that have been used to deduce\nwhen sampling problems are hard for classical computers to simulate. Two\nclasses of quantum sampling problems that demonstrate the supremacy of quantum\nalgorithms are BosonSampling and IQP Sampling. We will present the details of\nthese classes and recent experimental progress towards demonstrating quantum\nsupremacy in BosonSampling.\n",
        "query": "quantum computer supremacy ",
        "docId": 817655,
        "score": 10.07851791381836
    },
    {
        "title": "Quantum supremacy in driven quantum many-body systems",
        "paperAbstract": "  A crucial milestone in the field of quantum simulation and computation is to\ndemonstrate that a quantum device can compute certain tasks that are impossible\nto reproduce by a classical computer with any reasonable resources. Such a\ndemonstration is referred to as quantum supremacy. One of the most important\nquestions is to identify setups that exhibit quantum supremacy and can be\nimplemented with current quantum technology. The two standard candidates are\nboson sampling and random quantum circuits. Here, we show that quantum\nsupremacy can be obtained in generic periodically-driven quantum many-body\nsystems. Our analysis is based on the eigenstate thermalization hypothesis and\nstrongly-held conjectures in complexity theory. To illustrate our work, We give\nexamples of simple disordered Ising chains driven by global magnetic fields and\nBose-Hubbard chains with modulated hoppings. Our proposal opens the way for a\nlarge class of quantum platforms to demonstrate and benchmark quantum\nsupremacy.\n",
        "query": "quantum computer supremacy ",
        "docId": 1249369,
        "score": 9.95889663696289
    },
    {
        "title": "Comment on the Quantum Supremacy Claim by Google",
        "paperAbstract": "  Quantum computation promises to execute certain computational tasks on time\nscales much faster than any known algorithm on an existing classical computer,\nfor example calculating the prime factors of large integers. Recently a\nresearch team from Google claimed to have carried out such a task with a\nquantum computer, demonstrating in practice a case of this so-called quantum\nsupremacy. Here we argue that this claim was not justified. Unlike other\ncomments, our criticism is concerned with the missing verification of the\noutput data of the quantum computation.\n",
        "query": "quantum computer supremacy ",
        "docId": 1522677,
        "score": 9.854836463928223
    },
    {
        "title": "Statistical Aspects of the Quantum Supremacy Demonstration",
        "paperAbstract": "  The notable claim of quantum supremacy presented by Google\u0027s team in 2019\nconsists of demonstrating the ability of a quantum circuit to generate, albeit\nwith considerable noise, bitstrings from a distribution that is considered hard\nto simulate on classical computers. Verifying that the generated data is indeed\nfrom the claimed distribution and assessing the circuit\u0027s noise level and its\nfidelity is a purely statistical undertaking. The objective of this paper is to\nexplain the relations between quantum computing and some of the statistical\naspects involved in demonstrating quantum supremacy in terms that are\naccessible to statisticians, computer scientists, and mathematicians. Starting\nwith the statistical analysis in Google\u0027s demonstration, which we explain, we\nstudy various estimators of the fidelity, and different approaches to testing\nthe distributions generated by the quantum computer. We propose different noise\nmodels, and discuss their implications. A preliminary study of the Google data,\nfocusing mostly on circuits of 12 and 14 qubits is discussed throughout the\npaper.\n",
        "query": "quantum computer supremacy ",
        "docId": 1332899,
        "score": 9.7107572555542
    },
    {
        "title": "Spooky Action at a Distance",
        "paperAbstract": "  This article studies quantum mechanical entanglement. We begin by\nillustrating why entanglement implies action at a distance. We then introduce a\nsimple criterion for determining when a pure quantum state is entangled.\nFinally, we present a measure for the amount of entanglement for a pure state.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 1291665,
        "score": 19.101093292236328
    },
    {
        "title": "Bounding the speed of `spooky action at a distance\u0027",
        "paperAbstract": "  In the well-known EPR paper, Einstein et al. called the nonlocal correlation\nin quantum entanglement as `spooky action at a distance\u0027. If the spooky action\ndoes exist, what is its speed? All previous experiments along this direction\nhave locality loopholes and thus can be explained without having to invoke any\n`spooky action\u0027 at all. Here, we strictly closed the locality loopholes by\nobserving a 12-hour continuous violation of Bell inequality and concluded that\nthe lower bound speed of `spooky action\u0027 was four orders of magnitude of the\nspeed of light if the Earth\u0027s speed in any inertial reference frame was less\nthan 10^(-3) times of the speed of light.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 412271,
        "score": 16.756654739379883
    },
    {
        "title": "Testing spooky action at a distance",
        "paperAbstract": "  In science, one observes correlations and invents theoretical models that\ndescribe them. In all sciences, besides quantum physics, all correlations are\ndescribed by either of two mechanisms. Either a first event influences a second\none by sending some information encoded in bosons or molecules or other\nphysical carriers, depending on the particular science. Or the correlated\nevents have some common causes in their common past. Interestingly, quantum\nphysics predicts an entirely different kind of cause for some correlations,\nnamed entanglement. This new kind of cause reveals itself, e.g., in\ncorrelations that violate Bell inequalities (hence cannot be described by\ncommon causes) between space-like separated events (hence cannot be described\nby classical communication). Einstein branded it as spooky action at a\ndistance. A real spooky action at a distance would require a faster than light\ninfluence defined in some hypothetical universally privileged reference frame.\nHere we put stringent experimental bounds on the speed of all such hypothetical\ninfluences. We performed a Bell test during more than 24 hours between two\nvillages separated by 18 km and approximately east-west oriented, with the\nsource located precisely in the middle. We continuously observed 2-photon\ninterferences well above the Bell inequality threshold. Taking advantage of the\nEarth\u0027s rotation, the configuration of our experiment allowed us to determine,\nfor any hypothetically privileged frame, a lower bound for the speed of this\nspooky influence. For instance, if such a privileged reference frame exists and\nis such that the Earth\u0027s speed in this frame is less than 10^-3 that of the\nspeed of light, then the speed of this spooky influence would have to exceed\nthat of light by at least 4 orders of magnitude.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 79448,
        "score": 16.302291870117188
    },
    {
        "title": "There Is No Action at a Distance in Quantum Mechanics, Spooky or\n  Otherwise",
        "paperAbstract": "  I feel compelled to respond to the frequent references to spooky action at a\ndistance that often accompany reports of experiments investigating entangled\nquantum mechanical states. Most, but not all, of these articles have appeared\nin the popular press. As an experimentalist I have great admiration for such\nexperiments and the concomitant advances in quantum information and quantum\ncomputing, but accompanying claims of action at a distance are quite simply\nnonsense. Some physicists and philosophers of science have bought into the\nstory by promoting the nonlocal nature of quantum mechanics. In 1964, John Bell\nproved that classical hidden variable theories cannot reproduce the predictions\nof quantum mechanics unless they employ some type of action at a distance. I\nhave no problem with this conclusion. Unfortunately, Bell later expanded his\nanalysis and mistakenly deduced that quantum mechanics and by implication\nnature herself are nonlocal. In addition, some of these articles present\nEinstein in caricature, a tragic figure who neither understood quantum\nmechanics nor believed it to be an accurate theory of nature. Consequently, the\ncurrent experiments have proven him wrong. This is also nonsense.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 993565,
        "score": 15.451288223266602
    },
    {
        "title": "Extracting Spooky-activation-at-a-distance from Considerations of\n  Entanglement",
        "paperAbstract": "  Following an early claim by Nelson \u0026 McEvoy \\cite{Nelson:McEvoy:2007}\nsuggesting that word associations can display `spooky action at a distance\nbehaviour\u0027, a serious investigation of the potentially quantum nature of such\nassociations is currently underway. This paper presents a simple quantum model\nof a word association system. It is shown that a quantum model of word\nentanglement can recover aspects of both the Spreading Activation equation and\nthe Spooky-activation-at-a-distance equation, both of which are used to model\nthe activation level of words in human memory.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 105616,
        "score": 14.681378364562988
    },
    {
        "title": "How Does Nature Accomplish Spooky Action at a Distance?",
        "paperAbstract": "  The enigmatic nonlocal quantum correlation that was famously derided by\nEinstein as \"spooky action at a distance\" has now been experimentally\ndemonstrated to be authentic. The quantum entanglement and nonlocal\ncorrelations emerged as inevitable consequences of John Bell\u0027s epochal paper on\nBell\u0027s inequality. However, in spite of some extraordinary applications as well\nas attempts to explain the reason for quantum nonlocality, a satisfactory\naccount of how Nature accomplishes this astounding phenomenon is yet to emerge.\nA cogent mechanism for the occurrence of this incredible event is presented in\nterms of a plausible quantum mechanical Einstein-Rosen bridge.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 1781304,
        "score": 13.971644401550293
    },
    {
        "title": "Comment on: Testing the speed of \u0027spooky action at a distance\u0027",
        "paperAbstract": "  In a recent experiment, Salart et al. addressed the important issues of the\nspeed of hypothetical communication and of reference frames in Bell-type\nexperiments. The authors report that they \"performed a Bell experiment using\nentangled photons\" and conclude from their experimental results that \"to\nmaintain an explanation based on spooky action at a distance we would have to\nassume that the spooky action propagates at speeds even greater than the bounds\nobtained in our experiment\", exceeding the speed of light by orders of\nmagnitude. Here we show that, analyzing the experimental procedure,\nexplanations with subluminal or even no communication at all exist for the\nexperiment.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 90031,
        "score": 13.946325302124023
    },
    {
        "title": "Invariance of Spooky Action at a Distance in Quantum Entanglement under\n  Lorentz Transformation",
        "paperAbstract": "  We study the mechanism by which the particle-antiparticle entangled state\ncollapses instantaneously at a distance. By making two key assumptions, we are\nable to show not only that instantaneous collapse of a wave function at a\ndistance is possible but also that it is an invariant quantity under Lorentz\ntransformation and compatible with relativity. In addition, we will be able to\ndetect in which situation a many-body entangled system exhibits the maximum\ncollapse speed among its entangled particles. Finally we suggest that every\nforce in nature acts via entanglement.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 440855,
        "score": 13.516603469848633
    },
    {
        "title": "Entanglement Swapping and Action at a Distance",
        "paperAbstract": "  A 2015 experiment by Hanson and Delft colleagues provided further\nconfirmation that the quantum world violates the Bell inequalities, being the\nfirst Bell test to close two known experimental loopholes simultaneously. The\nexperiment was also taken to provide new evidence of \u0027spooky action at a\ndistance\u0027. Here we argue for caution about the latter claim. The Delft\nexperiment relies on entanglement swapping, and our main claim is that this\ngeometry introduces an additional loophole in the argument from violation of\nthe Bell inequalities to action at a distance: the apparent action at a\ndistance may be an artifact of \u0027collider bias\u0027. In the absence of\nretrocausality, the sensitivity of such experiments to this \u0027Collider Loophole\u0027\n(CL) depends on the temporal relation between the entanglement swapping\nmeasurement C and the two measurements A and B between which we seek to infer a\ncausal connection. CL looms large if the C is in the future of A and B, but not\nif C is in the past. The Delft experiment itself is the intermediate case, in\nwhich the separation is spacelike. We argue that this leaves it vulnerable to\nCL, unable to establish conclusively that it avoids it. An Appendix discusses\nthe implications of permitting retrocausality for the issue of causal influence\nacross entanglement swapping measurements.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 1409112,
        "score": 13.41561222076416
    },
    {
        "title": "Spooky action at a global distance: analysis of space-based entanglement\n  distribution for the quantum internet",
        "paperAbstract": "  Recent experimental breakthroughs in satellite quantum communications have\nopened up the possibility of creating a global quantum internet using satellite\nlinks. This approach appears to be particularly viable in the near term, due to\nthe lower attenuation of optical signals from satellite to ground, and due to\nthe currently short coherence times of quantum memories. The latter prevents\nground-based entanglement distribution using atmospheric or optical-fiber links\nat high rates over long distances. In this work, we propose a global-scale\nquantum internet consisting of a constellation of orbiting satellites that\nprovides a continuous, on-demand entanglement distribution service to ground\nstations. The satellites can also function as untrusted nodes for the purpose\nof long-distance quantum-key distribution. We develop a technique for\ndetermining optimal satellite configurations with continuous coverage that\nbalances both the total number of satellites and entanglement-distribution\nrates. Using this technique, we determine various optimal satellite\nconfigurations for a polar-orbit constellation, and we analyze the resulting\nsatellite-to-ground loss and achievable entanglement-distribution rates for\nmultiple ground station configurations. We also provide a comparison between\nthese entanglement-distribution rates and the rates of ground-based quantum\nrepeater schemes. Overall, our work provides the theoretical tools and the\nexperimental guidance needed to make a satellite-based global quantum internet\na reality.\n",
        "query": "spooky action at  distance and quantum entanglement and encryption",
        "docId": 1218574,
        "score": 12.913517951965332
    },
    {
        "title": "Faster Shortest Path Algorithm for H-Minor Free Graphs with Negative\n  Edge Weights",
        "paperAbstract": "  Let $H$ be a fixed graph and let $G$ be an $H$-minor free $n$-vertex graph\nwith integer edge weights and no negative weight cycles reachable from a given\nvertex $s$. We present an algorithm that computes a shortest path tree in $G$\nrooted at $s$ in $\\tilde{O}(n^{4/3}\\log L)$ time, where $L$ is the absolute\nvalue of the smallest edge weight. The previous best bound was\n$\\tilde{O}(n^{\\sqrt{11.5}-2}\\log L) \u003d O(n^{1.392}\\log L)$. Our running time\nmatches an earlier bound for planar graphs by Henzinger et al.\n",
        "query": "shortest path on negative graph weights",
        "docId": 205807,
        "score": 12.757720947265625
    },
    {
        "title": "Finding an induced path that is not a shortest path",
        "paperAbstract": "  We give a polynomial-time algorithm that, with input a graph $G$ and two\nvertices $u,v$ of $G$, decides whether there is an induced $uv$-path that is\nlonger than the shortest $uv$-path.\n",
        "query": "shortest path on negative graph weights",
        "docId": 1292656,
        "score": 12.154322624206543
    },
    {
        "title": "Shortest-Path-Preserving Rounding",
        "paperAbstract": "  Various applications of graphs, in particular applications related to finding\nshortest paths, naturally get inputs with real weights on the edges. However,\nfor algorithmic or visualization reasons, inputs with integer weights would\noften be preferable or even required. This raises the following question: given\nan undirected graph with non-negative real weights on the edges and an error\nthreshold $\\varepsilon$, how efficiently can we decide whether we can round all\nweights such that shortest paths are maintained, and the change of weight of\neach shortest path is less than $\\varepsilon$? So far, only for path-shaped\ngraphs a polynomial-time algorithm was known. In this paper we prove, by\nreduction from 3-SAT, that, in general, the problem is NP-hard. However, if the\ngraph is a tree with $n$ vertices, the problem can be solved in $O(n^2)$ time.\n",
        "query": "shortest path on negative graph weights",
        "docId": 1127057,
        "score": 12.109578132629395
    },
    {
        "title": "A Survey of Shortest-Path Algorithms",
        "paperAbstract": "  A shortest-path algorithm finds a path containing the minimal cost between\ntwo vertices in a graph. A plethora of shortest-path algorithms is studied in\nthe literature that span across multiple disciplines. This paper presents a\nsurvey of shortest-path algorithms based on a taxonomy that is introduced in\nthe paper. One dimension of this taxonomy is the various flavors of the\nshortest-path problem. There is no one general algorithm that is capable of\nsolving all variants of the shortest-path problem due to the space and time\ncomplexities associated with each algorithm. Other important dimensions of the\ntaxonomy include whether the shortest-path algorithm operates over a static or\na dynamic graph, whether the shortest-path algorithm produces exact or\napproximate answers, and whether the objective of the shortest-path algorithm\nis to achieve time-dependence or is to only be goal directed. This survey\nstudies and classifies shortest-path algorithms according to the proposed\ntaxonomy. The survey also presents the challenges and proposed solutions\nassociated with each category in the taxonomy.\n",
        "query": "shortest path on negative graph weights",
        "docId": 845585,
        "score": 12.093049049377441
    },
    {
        "title": "A scalable method to find the shortest path in a graph with circuits of\n  memristors",
        "paperAbstract": "  Finding the shortest path in a graph has applications to a wide range of\noptimization problems. However, algorithmic methods scale with the size of the\ngraph in terms of time and energy. We propose a method to solve the shortest\npath problem using circuits of nanodevices called memristors and validate it on\ngraphs of different sizes and topologies. It is both valid for an\nexperimentally derived memristor model and robust to device variability. The\ntime and energy of the computation scale with the length of the shortest path\nrather than with the size of the graph, making this method particularly\nattractive for solving large graphs with small path lengths.\n",
        "query": "shortest path on negative graph weights",
        "docId": 1024693,
        "score": 11.348836898803711
    },
    {
        "title": "SPAGAN: Shortest Path Graph Attention Network",
        "paperAbstract": "  Graph convolutional networks (GCN) have recently demonstrated their potential\nin analyzing non-grid structure data that can be represented as graphs. The\ncore idea is to encode the local topology of a graph, via convolutions, into\nthe feature of a center node. In this paper, we propose a novel GCN model,\nwhich we term as Shortest Path Graph Attention Network (SPAGAN). Unlike\nconventional GCN models that carry out node-based attentions within each layer,\nthe proposed SPAGAN conducts path-based attention that explicitly accounts for\nthe influence of a sequence of nodes yielding the minimum cost, or shortest\npath, between the center node and its higher-order neighbors. SPAGAN therefore\nallows for a more informative and intact exploration of the graph structure and\nfurther {a} more effective aggregation of information from distant neighbors\ninto the center node, as compared to node-based GCN methods. We test SPAGAN on\nthe downstream classification task on several standard datasets, and achieve\nperformances superior to the state of the art. Code is publicly available at\nhttps://github.com/ihollywhy/SPAGAN.\n",
        "query": "shortest path on negative graph weights",
        "docId": 1407206,
        "score": 11.292086601257324
    },
    {
        "title": "Shortest Path Networks for Graph Property Prediction",
        "paperAbstract": "  Most graph neural network models rely on a particular message passing\nparadigm, where the idea is to iteratively propagate node representations of a\ngraph to each node in the direct neighborhood. While very prominent, this\nparadigm leads to information propagation bottlenecks, as information is\nrepeatedly compressed at intermediary node representations, which causes loss\nof information, making it practically impossible to gather meaningful signals\nfrom distant nodes. To address this, we propose shortest path message passing\nneural networks, where the node representations of a graph are propagated to\neach node in the shortest path neighborhoods. In this setting, nodes can\ndirectly communicate between each other even if they are not neighbors,\nbreaking the information bottleneck and hence leading to more adequately\nlearned representations. Our framework generalizes message passing neural\nnetworks, resulting in a class of more expressive models, including some recent\nstate-of-the-art models. We verify the capacity of a basic model of this\nframework on dedicated synthetic experiments, and on real-world graph\nclassification and regression benchmarks, and obtain state-of-the art results.\n",
        "query": "shortest path on negative graph weights",
        "docId": 1661423,
        "score": 11.145437240600586
    },
    {
        "title": "Generalized Shortest Path Kernel on Graphs",
        "paperAbstract": "  We consider the problem of classifying graphs using graph kernels. We define\na new graph kernel, called the generalized shortest path kernel, based on the\nnumber and length of shortest paths between nodes. For our example\nclassification problem, we consider the task of classifying random graphs from\ntwo well-known families, by the number of clusters they contain. We verify\nempirically that the generalized shortest path kernel outperforms the original\nshortest path kernel on a number of datasets. We give a theoretical analysis\nfor explaining our experimental results. In particular, we estimate\ndistributions of the expected feature vectors for the shortest path kernel and\nthe generalized shortest path kernel, and we show some evidence explaining why\nour graph kernel outperforms the shortest path kernel for our graph\nclassification problem.\n",
        "query": "shortest path on negative graph weights",
        "docId": 670449,
        "score": 11.083035469055176
    },
    {
        "title": "Semi-dynamic shortest-path tree algorithms for directed graphs with\n  arbitrary weights",
        "paperAbstract": "  Given a directed graph $G$ with arbitrary real-valued weights, the single\nsource shortest-path problem (SSSP) asks for, given a source $s$ in $G$,\nfinding a shortest path from $s$ to each vertex $v$ in $G$. A classical SSSP\nalgorithm detects a negative cycle of $G$ or constructs a shortest-path tree\n(SPT) rooted at $s$ in $O(mn)$ time, where $m,n$ are the numbers of edges and\nvertices in $G$ respectively. In many practical applications, new constraints\ncome from time to time and we need to update the SPT frequently. Given an SPT\n$T$ of $G$, suppose the weight on a certain edge is modified. We show by\nrigorous proof that the well-known {\\sf Ball-String} algorithm for positively\nweighted graphs can be adapted to solve the dynamic SPT problem for directed\ngraphs with arbitrary weights. Let $n_0$ be the number of vertices that are\naffected (i.e., vertices that have different distances from $s$ or different\nparents in the input and output SPTs) and $m_0$ the number of edges incident to\nan affected vertex. The adapted algorithms terminate in $O(m_0+n_0 \\log n_0)$\ntime, either detecting a negative cycle (only in the decremental case) or\nconstructing a new SPT $T\u0027$ for the updated graph. We show by an example that\nthe output SPT $T\u0027$ may have more than necessary edge changes to $T$. To remedy\nthis, we give a general method for transforming $T\u0027$ into an SPT with minimal\nedge changes in time $O(n_0)$ provided that $G$ has no cycles with zero length.\n",
        "query": "shortest path on negative graph weights",
        "docId": 1094142,
        "score": 10.814776420593262
    },
    {
        "title": "Constrained Shortest Path Search with Graph Convolutional Neural\n  Networks",
        "paperAbstract": "  Planning for Autonomous Unmanned Ground Vehicles (AUGV) is still a challenge,\nespecially in difficult, off-road, critical situations. Automatic planning can\nbe used to reach mission objectives, to perform navigation or maneuvers. Most\nof the time, the problem consists in finding a path from a source to a\ndestination, while satisfying some operational constraints. In a graph without\nnegative cycles, the computation of the single-pair shortest path from a start\nnode to an end node is solved in polynomial time. Additional constraints on the\nsolution path can however make the problem harder to solve. This becomes the\ncase when we need the path to pass through a few mandatory nodes without\nrequiring a specific order of visit. The complexity grows exponentially with\nthe number of mandatory nodes to visit. In this paper, we focus on shortest\npath search with mandatory nodes on a given connected graph. We propose a\nhybrid model that combines a constraint-based solver and a graph convolutional\nneural network to improve search performance. Promising results are obtained on\nrealistic scenarios.\n",
        "query": "shortest path on negative graph weights",
        "docId": 1509793,
        "score": 10.788212776184082
    },
    {
        "title": "Super-Identity Convolutional Neural Network for Face Hallucination",
        "paperAbstract": "  Face hallucination is a generative task to super-resolve the facial image\nwith low resolution while human perception of face heavily relies on identity\ninformation. However, previous face hallucination approaches largely ignore\nfacial identity recovery. This paper proposes Super-Identity Convolutional\nNeural Network (SICNN) to recover identity information for generating faces\nclosed to the real identity. Specifically, we define a super-identity loss to\nmeasure the identity difference between a hallucinated face and its\ncorresponding high-resolution face within the hypersphere identity metric\nspace. However, directly using this loss will lead to a Dynamic Domain\nDivergence problem, which is caused by the large margin between the\nhigh-resolution domain and the hallucination domain. To overcome this\nchallenge, we present a domain-integrated training approach by constructing a\nrobust identity metric for faces from these two domains. Extensive experimental\nevaluations demonstrate that the proposed SICNN achieves superior visual\nquality over the state-of-the-art methods on a challenging task to\nsuper-resolve 12$\\times$14 faces with an 8$\\times$ upscaling factor. In\naddition, SICNN significantly improves the recognizability of\nultra-low-resolution faces.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 1046961,
        "score": 10.407425880432129
    },
    {
        "title": "Reverse Prevention Sampling for Misinformation Mitigation in Social\n  Networks",
        "paperAbstract": "  In this work, we consider misinformation propagating through a social network\nand study the problem of its prevention. In this problem, a \"bad\" campaign\nstarts propagating from a set of seed nodes in the network and we use the\nnotion of a limiting (or \"good\") campaign to counteract the effect of\nmisinformation. The goal is to identify a set of $k$ users that need to be\nconvinced to adopt the limiting campaign so as to minimize the number of people\nthat adopt the \"bad\" campaign at the end of both propagation processes.\n  This work presents \\emph{RPS} (Reverse Prevention Sampling), an algorithm\nthat provides a scalable solution to the misinformation mitigation problem. Our\ntheoretical analysis shows that \\emph{RPS} runs in $O((k + l)(n + m)(\\frac{1}{1\n- \\gamma}) \\log n / \\epsilon^2 )$ expected time and returns a $(1 - 1/e -\n\\epsilon)$-approximate solution with at least $1 - n^{-l}$ probability (where\n$\\gamma$ is a typically small network parameter and $l$ is a confidence\nparameter). The time complexity of \\emph{RPS} substantially improves upon the\npreviously best-known algorithms that run in time $\\Omega(m n k \\cdot\nPOLY(\\epsilon^{-1}))$. We experimentally evaluate \\emph{RPS} on large datasets\nand show that it outperforms the state-of-the-art solution by several orders of\nmagnitude in terms of running time. This demonstrates that misinformation\nmitigation can be made practical while still offering strong theoretical\nguarantees.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 998370,
        "score": 9.41158676147461
    },
    {
        "title": "Deep Cascaded Bi-Network for Face Hallucination",
        "paperAbstract": "  We present a novel framework for hallucinating faces of unconstrained poses\nand with very low resolution (face size as small as 5pxIOD). In contrast to\nexisting studies that mostly ignore or assume pre-aligned face spatial\nconfiguration (e.g. facial landmarks localization or dense correspondence\nfield), we alternatingly optimize two complementary tasks, namely face\nhallucination and dense correspondence field estimation, in a unified\nframework. In addition, we propose a new gated deep bi-network that contains\ntwo functionality-specialized branches to recover different levels of texture\ndetails. Extensive experiments demonstrate that such formulation allows\nexceptional hallucination quality on in-the-wild low-res faces with significant\npose and illumination variations.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 752597,
        "score": 8.749765396118164
    },
    {
        "title": "FH-GAN: Face Hallucination and Recognition using Generative Adversarial\n  Network",
        "paperAbstract": "  There are many factors affecting visual face recognition, such as low\nresolution images, aging, illumination and pose variance, etc. One of the most\nimportant problem is low resolution face images which can result in bad\nperformance on face recognition. Most of the general face recognition\nalgorithms usually assume a sufficient resolution for the face images. However,\nin practice many applications often do not have sufficient image resolutions.\nThe modern face hallucination models demonstrate reasonable performance to\nreconstruct high-resolution images from its corresponding low resolution\nimages. However, they do not consider identity level information during\nhallucination which directly affects results of the recognition of low\nresolution faces. To address this issue, we propose a Face Hallucination\nGenerative Adversarial Network (FH-GAN) which improves the quality of low\nresolution face images and accurately recognize those low quality images.\nConcretely, we make the following contributions: 1) we propose FH-GAN network,\nan end-to-end system, that improves both face hallucination and face\nrecognition simultaneously. The novelty of this proposed network depends on\nincorporating identity information in a GAN-based face hallucination algorithm\nvia combining a face recognition network for identity preserving. 2) We also\npropose a new face hallucination network, namely Dense Sparse Network (DSNet),\nwhich improves upon the state-of-art in face hallucination. 3) We demonstrate\nbenefits of training the face recognition and GAN-based DSNet jointly by\nreporting good result on face hallucination and recognition.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 1124973,
        "score": 8.29685115814209
    },
    {
        "title": "Detection and Mitigation of Rare Subclasses in Deep Neural Network\n  Classifiers",
        "paperAbstract": "  Regions of high-dimensional input spaces that are underrepresented in\ntraining datasets reduce machine-learnt classifier performance, and may lead to\ncorner cases and unwanted bias for classifiers used in decision making systems.\nWhen these regions belong to otherwise well-represented classes, their presence\nand negative impact are very hard to identify. We propose an approach for the\ndetection and mitigation of such rare subclasses in deep neural network\nclassifiers. The new approach is underpinned by an easy-to-compute commonality\nmetric that supports the detection of rare subclasses, and comprises methods\nfor reducing the impact of these subclasses during both model training and\nmodel exploitation. We demonstrate our approach using two well-known datasets,\nMNIST\u0027s handwritten digits and Kaggle\u0027s cats/dogs, identifying rare subclasses\nand producing models which compensate for subclass rarity. In addition we\ndemonstrate how our run-time approach increases the ability of users to\nidentify samples likely to be misclassified at run-time.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 1211374,
        "score": 8.289848327636719
    },
    {
        "title": "HOB-CNN: Hallucination of Occluded Branches with a Convolutional Neural\n  Network for 2D Fruit Trees",
        "paperAbstract": "  Orchard automation has attracted the attention of researchers recently due to\nthe shortage of global labor force. To automate tasks in orchards such as\npruning, thinning, and harvesting, a detailed understanding of the tree\nstructure is required. However, occlusions from foliage and fruits can make it\nchallenging to predict the position of occluded trunks and branches. This work\nproposes a regression-based deep learning model, Hallucination of Occluded\nBranch Convolutional Neural Network (HOB-CNN), for tree branch position\nprediction in varying occluded conditions. We formulate tree branch position\nprediction as a regression problem towards the horizontal locations of the\nbranch along the vertical direction or vice versa. We present comparative\nexperiments on Y-shaped trees with two state-of-the-art baselines, representing\ncommon approaches to the problem. Experiments show that HOB-CNN outperform the\nbaselines at predicting branch position and shows robustness against varying\nlevels of occlusion. We further validated HOB-CNN against two different types\nof 2D trees, and HOB-CNN shows generalization across different trees and\nrobustness under different occluded conditions.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 1690714,
        "score": 8.152029991149902
    },
    {
        "title": "Self-Enhanced Convolutional Network for Facial Video Hallucination",
        "paperAbstract": "  As a domain-specific super-resolution problem, facial image hallucination has\nenjoyed a series of breakthroughs thanks to the advances of deep convolutional\nneural networks. However, the direct migration of existing methods to video is\nstill difficult to achieve good performance due to its lack of alignment and\nconsistency modelling in temporal domain. Taking advantage of high inter-frame\ndependency in videos, we propose a self-enhanced convolutional network for\nfacial video hallucination. It is implemented by making full usage of preceding\nsuper-resolved frames and a temporal window of adjacent low-resolution frames.\nSpecifically, the algorithm first obtains the initial high-resolution inference\nof each frame by taking into consideration a sequence of consecutive\nlow-resolution inputs through temporal consistency modelling. It further\nrecurrently exploits the reconstructed results and intermediate features of a\nsequence of preceding frames to improve the initial super-resolution of the\ncurrent frame by modelling the coherence of structural facial features across\nframes. Quantitative and qualitative evaluations demonstrate the superiority of\nthe proposed algorithm against state-of-the-art methods. Moreover, our\nalgorithm also achieves excellent performance in the task of general video\nsuper-resolution in a single-shot setting.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 1209730,
        "score": 8.139925003051758
    },
    {
        "title": "VHDL Modeling of Intrusion Detection \u0026 Prevention System (IDPS) A Neural\n  Network Approach",
        "paperAbstract": "  The rapid development and expansion of World Wide Web and network systems\nhave changed the computing world in the last decade and also equipped the\nintruders and hackers with new facilities for their destructive purposes. The\ncost of temporary or permanent damages caused by unauthorized access of the\nintruders to computer systems has urged different organizations to increasingly\nimplement various systems to monitor data flow in their network. The systems\nare generally known as Intrusion Detection System (IDS).Our objective is to\nimplement an artificial network approach to the design of intrusion detection\nand prevention system and finally convert the designed model to a VHDL (Very\nHigh Speed Integrated Circuit Hardware Descriptive Language) code. This feature\nenables the system to suggest proper actions against possible attacks. The\npromising results of the present study show the potential applicability of ANNs\nfor developing practical IDSs.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 502800,
        "score": 8.034110069274902
    },
    {
        "title": "Face Hallucination via Split-Attention in Split-Attention Network",
        "paperAbstract": "  Recently, convolutional neural networks (CNNs) have been widely employed to\npromote the face hallucination due to the ability to predict high-frequency\ndetails from a large number of samples. However, most of them fail to take into\naccount the overall facial profile and fine texture details simultaneously,\nresulting in reduced naturalness and fidelity of the reconstructed face, and\nfurther impairing the performance of downstream tasks (e.g., face detection,\nfacial recognition). To tackle this issue, we propose a novel external-internal\nsplit attention group (ESAG), which encompasses two paths responsible for\nfacial structure information and facial texture details, respectively. By\nfusing the features from these two paths, the consistency of facial structure\nand the fidelity of facial details are strengthened at the same time. Then, we\npropose a split-attention in split-attention network (SISN) to reconstruct\nphotorealistic high-resolution facial images by cascading several ESAGs.\nExperimental results on face hallucination and face recognition unveil that the\nproposed method not only significantly improves the clarity of hallucinated\nfaces, but also encourages the subsequent face recognition performance\nsubstantially. Codes have been released at\nhttps://github.com/mdswyz/SISN-Face-Hallucination.\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 1367905,
        "score": 8.01999282836914
    },
    {
        "title": "Quantum neural network",
        "paperAbstract": "  It is suggested that a quantum neural network (QNN), a type of artificial\nneural network, can be built using the principles of quantum information\nprocessing. The input and output qubits in the QNN can be implemented by\noptical modes with different polarization, the weights of the QNN can be\nimplemented by optical beam splitters and phase shifters\n",
        "query": "neural network hallucination prevention and mitigation",
        "docId": 2207916,
        "score": 7.9931640625
    },
    {
        "title": "Quantum annealing",
        "paperAbstract": "  Brief description on the state of the art of some local optimization methods:\nQuantum annealing Quantum annealing (also known as alloy, crystallization or\ntempering) is analogous to simulated annealing but in substitution of thermal\nactivation by quantum tunneling. The class of algorithmic methods for quantum\nannealing (dubbed: \u0027QA\u0027), sometimes referred by the italian school as Quantum\nStochastic Optimization (\u0027QSO\u0027), is a promising metaheuristic tool for solving\nlocal search problems in multivariable optimization contexts.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 515518,
        "score": 11.85772705078125
    },
    {
        "title": "Statistical Analysis of Quantum Annealing",
        "paperAbstract": "  Quantum computers use quantum resources to carry out computational tasks and\nmay outperform classical computers in solving certain computational problems.\nSpecial-purpose quantum computers such as quantum annealers employ quantum\nadiabatic theorem to solve combinatorial optimization problems. In this paper,\nwe compare classical annealings such as simulated annealing and quantum\nannealings that are done by the D-Wave machines both theoretically and\nnumerically. We show that if the classical and quantum annealing are\ncharacterized by equivalent Ising models, then solving an optimization problem,\ni.e., finding the minimal energy of each Ising model, by the two annealing\nprocedures, are mathematically identical. For quantum annealing, we also derive\nthe probability lower-bound on successfully solving an optimization problem by\nmeasuring the system at the end of the annealing procedure. Moreover, we\npresent the Markov chain Monte Carlo (MCMC) method to realize quantum annealing\nby classical computers and investigate its statistical properties. In the\nnumerical section, we discuss the discrepancies between the MCMC based\nannealing approaches and the quantum annealing approach in solving optimization\nproblems.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 1410596,
        "score": 11.413368225097656
    },
    {
        "title": "Comparative Study of the Performance of Quantum Annealing and Simulated\n  Annealing",
        "paperAbstract": "  Relations of simulated annealing and quantum annealing are studied by a\nmapping from the transition matrix of classical Markovian dynamics of the Ising\nmodel to a quantum Hamiltonian and vice versa. It is shown that these two\noperators, the transition matrix and the Hamiltonian, share the eigenvalue\nspectrum. Thus, if simulated annealing with slow temperature change does not\nencounter a difficulty caused by an exponentially long relaxation time at a\nfirst-order phase transition, the same is true for the corresponding process of\nquantum annealing in the adiabatic limit. One of the important differences\nbetween the classical-to-quantum mapping and the converse quantum-to-classical\nmapping is that the Markovian dynamics of a short-range Ising model is mapped\nto a short-range quantum system, but the converse mapping from a short-range\nquantum system to a classical one results in long-range interactions. This\nleads to a difference in efficiencies that simulated annealing can be\nefficiently simulated by quantum annealing but the converse is not necessarily\ntrue. We conclude that quantum annealing is easier to implement and is more\nflexible than simulated annealing. We also point out that the present mapping\ncan be extended to accommodate explicit time dependence of temperature, which\nis used to justify the quantum-mechanical analysis of simulated annealing by\nSomma, Batista, and Ortiz. Additionally, an alternative method to solve the\nnon-equilibrium dynamics of the one-dimensional Ising model is provided through\nthe classical-to-quantum mapping.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 558811,
        "score": 11.27418327331543
    },
    {
        "title": "Optimizing Schedules for Quantum Annealing",
        "paperAbstract": "  Classical and quantum annealing are two heuristic optimization methods that\nsearch for an optimal solution by slowly decreasing thermal or quantum\nfluctuations. Optimizing annealing schedules is important both for performance\nand fair comparisons between classical annealing, quantum annealing, and other\nalgorithms. Here we present a heuristic approach for the optimization of\nannealing schedules for quantum annealing and apply it to 3D Ising spin glass\nproblems. We find that if both classical and quantum annealing schedules are\nsimilarly optimized, classical annealing outperforms quantum annealing for\nthese problems when considering the residual energy obtained in slow annealing.\nHowever, when performing many repetitions of fast annealing, simulated quantum\nannealing is seen to outperform classical annealing for our benchmark problems.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 843961,
        "score": 10.356666564941406
    },
    {
        "title": "Pulsed quantum annealing",
        "paperAbstract": "  We propose a modified quantum annealing protocol, i. e., pulsed quantum\nannealing} (PQA), in order to increase the success probability by a pulse\napplication during the quantum annealing process. It is well known that the\nsuccess probability of the conventional quantum annealing is reduced due to the\nLandau-Zener transitions. By applying a pulse to the system, we modulate the\nsuccess probability and increase it, compared to the conventional quantum\nannealing, by optimizing the pulse parameters. We demonstrate our findings for\na single qubit both numerically and analytically. The analytical model is based\non the tranfer matrix approach and it is in good agreement with the full\nnumerical results. We also investigate the PQA protocol for multi-qubit cases\n$i. e.,$ random spin-glass instances, and we present an overall increase of the\nsuccess probability over the conventional quantum annealing, by optimizing the\npulse parameters. Our results indicate that PQA can be used to design future\nhigh-performance quantum annealing machines, especially for hard instances that\nthe conventional QA protocol behaves poorly.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 994157,
        "score": 10.1229248046875
    },
    {
        "title": "Quantum Annealing and Computation",
        "paperAbstract": "  We introduce and review briefly the phenomenon of quantum annealing and\nanalog computation. The role of quantum fluctuation (tunneling) in random\nsystems with rugged (free) energy landscapes having macroscopic barriers are\ndiscussed to demonstrate the quantum advantage in the search for the ground\nstate(s) through annealing. Quantum annealing as a physical (analog) process to\nsearch for the optimal solutions of computationally hard problems are also\ndiscussed.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 1628701,
        "score": 10.03860092163086
    },
    {
        "title": "Assessing the performance of quantum annealing with nonlinear driving",
        "paperAbstract": "  Current generation quantum annealers have already proven to be successful\nproblem-solvers. Yet, quantum annealing is still very much in its infancy, with\nsuboptimal applicability. For instance, to date it is still an open question\nwhich annealing protocol causes the fewest diabatic excitations for a given\neigenspectrum, and even whether there is a universally optimal strategy.\nTherefore, in this paper, we report analytical and numerical studies of the\ndiabatic excitations arising from nonlinear protocols applied to the transverse\nfield Ising chain, the exactly solvable model that serves as a quantum\nannealing playground. Our analysis focuses on several driving schemes that\ninhibit or facilitate the dynamic phases discussed in a previous work. Rather\nremarkably, we find that the paradigmatic Kibble-Zurek behavior can be\nsuppressed with ``pauses\u0027\u0027 in the evolution, both for crossing and for stopping\nat the quantum critical point of the system.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 1629871,
        "score": 9.893782615661621
    },
    {
        "title": "Performance of two different quantum annealing correction codes",
        "paperAbstract": "  Quantum annealing is a promising approach for solving optimization problems,\nbut like all other quantum information processing methods, it requires error\ncorrection to ensure scalability. In this work we experimentally compare two\nquantum annealing correction codes in the setting of antiferromagnetic chains,\nusing two different quantum annealing processors. The lower temperature\nprocessor gives rise to higher success probabilities. The two codes differ in a\nnumber of interesting and important ways, but both require four physical qubits\nper encoded qubit. We find significant performance differences, which we\nexplain in terms of the effective energy boost provided by the respective\nredundantly encoded logical operators of the two codes. The code with the\nhigher energy boost results in improved performance, at the expense of a lower\ndegree encoded graph. Therefore, we find that there exists an important\ntradeoff between encoded connectivity and performance for quantum annealing\ncorrection codes.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 649441,
        "score": 9.786705017089844
    },
    {
        "title": "Faster annealing schedules for quantum annealing",
        "paperAbstract": "  New annealing schedules for quantum annealing are proposed based on the\nadiabatic theorem. These schedules exhibit faster decrease of the excitation\nprobability than a linear schedule. To derive this conclusion, the asymptotic\nform of the excitation probability for quantum annealing is explicitly obtained\nin the limit of long annealing time. Its first-order term, which is inversely\nproportional to the square of the annealing time, is shown to be determined\nonly by the information at the initial and final times. Our annealing schedules\nmake it possible to drop this term, thus leading to a higher order (smaller)\nexcitation probability. We verify these results by solving numerically the\ntime-dependent Schrodinger equation for small size systems\n",
        "query": "performance analysis of quantum annealing",
        "docId": 2222494,
        "score": 9.740880012512207
    },
    {
        "title": "Quantum Annealing for Clustering",
        "paperAbstract": "  This paper studies quantum annealing (QA) for clustering, which can be seen\nas an extension of simulated annealing (SA). We derive a QA algorithm for\nclustering and propose an annealing schedule, which is crucial in practice.\nExperiments show the proposed QA algorithm finds better clustering assignments\nthan SA. Furthermore, QA is as easy as SA to implement.\n",
        "query": "performance analysis of quantum annealing",
        "docId": 547341,
        "score": 9.657524108886719
    },
    {
        "title": "Achieving short high-quality gate-all-around structures for horizontal\n  nanowire field-effect transistors",
        "paperAbstract": "  We introduce a fabrication method for gate-all-around nanowire field-effect\ntransistors. Single nanowires were aligned perpendicular to underlying bottom\ngates using a resist-trench alignment technique. Top gates were then defined\naligned to the bottom gates to form gate-all-around structures. This approach\novercomes significant limitations in minimal obtainable gate length and\ngate-length control in previous horizontal wrap-gated nanowire transistors that\narise because the gate is defined by wet etching. In the method presented here\ngate-length control is limited by the resolution of the\nelectron-beam-lithography process. We demonstrate the versatility of our\napproach by fabricating a device with an independent bottom gate, top gate, and\ngate-all-around structure as well as a device with three independent\ngate-all-around structures with 300 nm, 200 nm, and 150 nm gate length. Our\nmethod enables us to achieve sub-threshold swings as low as 38 mV/dec at 77 K\nfor a 150 nm gate length.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 1034546,
        "score": 12.679426193237305
    },
    {
        "title": "The Difficulty of Gate Control in Molecular Transistors",
        "paperAbstract": "  The electrostatic gating effects on molecular transistors are investigated\nusing the density functional theory (DFT) combined with the nonequilibrium\nGreen\u0027s function (NEGF) method. When molecular energy levels are away from the\nFermi energy they can be linearly shifted by the gate voltage, which is\nconsistent with recent experimental observations [Nature 462, 1039 (2009)].\nHowever, when they move near to the Fermi energy (turn-on process), the shifts\nbecome extremely small and almost independent of the gate voltage. The fact\nthat the conductance may be beyond the gate control in the \"ON\" state will\nchallenge the implementation of molecular transistors.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 290308,
        "score": 10.16099739074707
    },
    {
        "title": "Low-noise top-gate graphene transistors",
        "paperAbstract": "  We report results of experimental investigation of the low-frequency noise in\nthe top-gate graphene transistors. The back-gate graphene devices were modified\nvia addition of the top gate separated by 20 nm of HfO2 from the single-layer\ngraphene channels. The measurements revealed low flicker noise levels with the\nnormalized noise spectral density close to 1/f (f is the frequency) and Hooge\nparameter below 2 x 10^-3. The analysis of the noise spectral density\ndependence on the top and bottom gate biases helped us to elucidate the noise\nsources in these devices and develop a strategy for the electronic noise\nreduction. The obtained results are important for all proposed graphene\napplications in electronics and sensors.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 141075,
        "score": 9.380428314208984
    },
    {
        "title": "III-V Gate-all-around Nanowire MOSFET Process Technology: From 3D to 4D",
        "paperAbstract": "  In this paper, we have experimentally demonstrated, for the first time, III-V\n4D transistors with vertically stacked InGaAs nanowire (NW) channels and\ngate-all-around (GAA) architecture. Novel process technology enabling the\ntransition from 3D to 4D structure has been developed and summarized. The\nsuccessful fabrication of InGaAs lateral and vertical NW arrays has led to 4x\nincrease in MOSFET drive current. The top-down technology developed in this\npaper has opened a viable pathway towards future low-power logic and RF\ntransistors with high-density III-V NWs.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 393841,
        "score": 9.19263744354248
    },
    {
        "title": "InAs nanowire transistors with multiple, independent wrap-gate segments",
        "paperAbstract": "  We report a method for making horizontal wrap-gate nanowire transistors with\nup to four independently controllable wrap-gated segments. While the step up to\ntwo independent wrap-gates requires a major change in fabrication methodology,\na key advantage to this new approach, and the horizontal orientation more\ngenerally, is that achieving more than two wrap-gate segments then requires no\nextra fabrication steps. This is in contrast to the vertical orientation, where\na significant subset of the fabrication steps needs to be repeated for each\nadditional gate. We show that cross-talk between adjacent wrap-gate segments is\nnegligible despite separations less than 200 nm. We also demonstrate the\nability to make multiple wrap-gate transistors on a single nanowire using the\nexact same process. The excellent scalability potential of horizontal wrap-gate\nnanowire transistors makes them highly favourable for the development of\nadvanced nanowire devices and possible integration with vertical wrap-gate\nnanowire transistors in 3D nanowire network architectures.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 621961,
        "score": 8.903533935546875
    },
    {
        "title": "Self-consistent Capacitance-Voltage Characterization of Gate-all-around\n  Graded Nanowire Transistor",
        "paperAbstract": "  This paper presents a self-consistent numerical model for calculating the\ncharge profile and gate capacitance and therefore obtaining C-V\ncharacterization for a gate-all-around graded nanowire MOSFET with a high\nmobility axially graded In0.75Ga0.25As + In0.53Ga0.47As channel incorporating\nstrain and atomic layer deposited Al2O3/20nm Ti gate. C-V characteristics with\nintroduction and variation of In-composition grading and also grading in doping\nconcentration are explored.Finite element method has been used to solve\nPoisson\u0027s equation and Schr\\\"odinger\u0027s equation self-consistently considering\nwave function penetration and other quantum effects to calculate gate\ncapacitance and charge profile for different gate biases. The device parameters\nare taken from a recently introduced experimental device.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 534140,
        "score": 8.797852516174316
    },
    {
        "title": "Compact spin qubits using the common gate structure of fin field-effect\n  transistors",
        "paperAbstract": "  The sizes of commercial transistors are of nanometer order, and there have\nalready been many proposals of spin qubits using conventional complementary\nmetal oxide semiconductor (CMOS) transistors. However, the previously proposed\nspin qubits require many wires to control a small number of qubits. This causes\na significant \u0027jungle of wires\u0027 problem when the qubits are integrated into a\nchip. Herein, to reduce the complicated wiring, we theoretically consider spin\nqubits embedded into fin field-effect transistor (FinFET) devices such that the\nspin qubits share the common gate electrode of the FinFET. The interactions\nbetween qubits occur via the Ruderman Kittel Kasuya Yosida (RKKY) interaction\nvia the channel of the FinFET. The compensation for the compact implementation\nrequires high-density current lines in a small space. The possibility of a\nquantum annealing machine is discussed in addition to the quantum computers of\nthe current proposals.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 1346123,
        "score": 8.785562515258789
    },
    {
        "title": "Field Effect Transistors on Rubrene Single Crystals with Parylene Gate\n  Insulator",
        "paperAbstract": "  We report on fabrication and characterization of the organic field effect\ntransistors (OFETs) on the surface of single crystals of rubrene. The parylene\npolymer film has been used as the gate insulator. At room temperature, these\nOFETs exhibit the p-type conductivity with the field effect mobility up to 1\ncm^2/Vs and the on/off ratio ~ 10^4. The temperature dependence of the mobility\nis discussed.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 1913630,
        "score": 8.63346004486084
    },
    {
        "title": "A Pseudo 2D-analytical Model of Dual Material Gate All-Around Nanowire\n  Tunneling FET",
        "paperAbstract": "  In this paper, we have worked out a pseudo two dimensional (2D) analytical\nmodel for surface potential and drain current of a long channel p-type Dual\nMaterial Gate (DMG) Gate All-Around (GAA) nanowire Tunneling Field Effect\nTransistor (TFET). The model incorporates the effect of drain voltage, gate\nmetal work functions, thickness of oxide and silicon nanowire radius. The model\ndoes not assume a fully depleted channel. With the help of this model we have\ndemonstrated the accumulation of charge at the interface of the two gates. The\naccuracy of the model is tested using the 3D device simulator Silvaco Atlas.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 534285,
        "score": 8.340182304382324
    },
    {
        "title": "Comparison of Josephson vortex flow transistors with different gate line\n  configurations",
        "paperAbstract": "  We performed numerical simulations and experiments on Josephson vortex flow\ntransistors based on parallel arrays of YBa2Cu3O(7-x) grain boundary junctions\nwith a cross gate-line allowing to operate the same devices in two different\nmodes named Josephson fluxon transistor (JFT) and Josephson fluxon-antifluxon\ntransistor (JFAT). The simulations yield a general expression for the current\ngain vs. number of junctions and normalized loop inductance and predict higher\ncurrent gain for the JFAT. The experiments are in good agreement with\nsimulations and show improved coupling between gate line and junctions for the\nJFAT as compared to the JFT.\n",
        "query": "gate all around transistors  vs FinFET",
        "docId": 1900543,
        "score": 8.34015941619873
    },
    {
        "title": "On modular forms for some noncongruence arithmetic subgroups",
        "paperAbstract": "  In this paper, we consider modular forms for finite index subgroups of the\nmodular group whose Fourier coefficients are algebraic. It is well-known that\nthe Fourier coefficients of any holomorphic modular form for a congruence\nsubgroup (with algebraic coefficients) have bounded denominators. It was\nobserved by Atkin and Swinnerton-Dyer that this is no longer true for modular\nforms for noncongruence subgroups and they pointed out that unbounded\ndenominator property is a clear distinction between modular forms for\nnoncongruence and congruence modular forms. It is an open question whether\ngenuine noncongruence modular forms (with algebraic coefficients) always\nsatisfy the unbounded denominator property. Here, we give a partial positive\nanswer to the above open question by constructing special finite index\nsubgroups of SL_2(Z) called character groups and discuss the properties of\nmodular forms for some groups of this kind.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 2154967,
        "score": 13.772109031677246
    },
    {
        "title": "The Modular number, Congruence number, and Multiplicity One",
        "paperAbstract": "  Let $N$ be a positive integer and let $f$ be a newform of weight 2 on\n$\\Gamma_0(N)$. In earlier joint work with K. Ribet and W. Stein, we introduced\nthe notions of the modular number and the congruence number of the quotient\nabelian variety $A_f$ of $J_0(N)$ associated to the newform $f$. These\ninvariants are analogs of the notions of the modular degree and congruence\nprimes respectively associated to elliptic curves. We show that if $p$ is a\nprime such that every maximal ideal of the Hecke algebra of characteristic $p$\nthat contains the annihilator ideal of $f$ satisfies multiplicity one, then the\nmodular number and the congruence number have the same $p$-adic valuation.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 90755,
        "score": 13.746867179870605
    },
    {
        "title": "Higher Commutator Theory for Congruence Modular Varieties",
        "paperAbstract": "  We develop the basic properties of the higher commutator for congruence\nmodular varieties.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 782434,
        "score": 13.122957229614258
    },
    {
        "title": "A Database of Modular Forms on Noncongruence Subgroups",
        "paperAbstract": "  We present a database of several hundred modular forms up to and including\nweight six on noncongruence subgroups of index $\\leq 17$. In addition, our\ndatabase contains expressions for the Belyi map for genus zero subgroups and\nequations of the corresponding elliptic curves for genus one subgroups and\nnumerical approximations of noncongruence Eisenstein series to 1500 digits\nprecision.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 1773199,
        "score": 12.602295875549316
    },
    {
        "title": "Moduli Interpretations for Noncongruence Modular Curves",
        "paperAbstract": "  We define the notion of a $G$-structure for elliptic curves, where $G$ is a\nfinite 2-generated group. When $G$ is abelian, a $G$-structure is the same as a\nclassical congruence level structure. There is a natural action of\n$\\text{SL}_2(\\mathbb{Z})$ on these level structures. If $\\Gamma$ is a\nstabilizer of this action, then the quotient of the upper half plane by\n$\\Gamma$ parametrizes isomorphism classes of elliptic curves equipped with\n$G$-structures. When $G$ is \"sufficiently\" nonabelian, the stabilizers $\\Gamma$\nare noncongruence. As a result we realize noncongruence modular curves as\nmoduli spaces of elliptic curves equipped with nonabelian $G$-structures. As\napplications we describe links to the Inverse Galois Problem, and show how our\nmoduli interpretations explains the bad primes for the Unbounded Denominators\nConjecture, and allows us to translate the conjecture into the language of\ngeometry and Galois theory.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 669644,
        "score": 12.541845321655273
    },
    {
        "title": "Experimental finding of modular forms for noncongruence subgroups",
        "paperAbstract": "  In this paper we will use experimental and computational methods to find\nmodular forms for non-congruence subgroups, and the modular forms for\ncongruence subgroups that they are associated with via the\nAtkin--Swinnerton-Dyer correspondence. We also prove a generalization of a\ncriterion due to Ligozat for an eta-quotient to be a modular function.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 148803,
        "score": 11.852951049804688
    },
    {
        "title": "Atkin and Swinnerton-Dyer congruences and noncongruence modular forms",
        "paperAbstract": "  Atkin and Swinnerton-Dyer congruences are special congruence recursions\nsatisfied by coefficients of noncongruence modular forms. These are in some\nsense $p$-adic analogues of Hecke recursion satisfied by classic Hecke\neigenforms. They actually appeared in different context and sometimes can be\nobtained using the theory of formal groups. In this survey paper, we introduce\nthe Atkin and Swinnerton-Dyer congruences, and discuss some recent progress on\nthis topic.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 417885,
        "score": 11.81291675567627
    },
    {
        "title": "On the computation of modular forms on noncongruence subgroups",
        "paperAbstract": "  We present two approaches that can be used to compute modular forms on\nnoncongruence subgroups. The first approach uses Hejhal\u0027s method for which we\nimprove the arbitrary precision solving techniques so that the algorithm\nbecomes about up to two orders of magnitude faster in practical computations.\nThis allows us to obtain high precision numerical estimates of the Fourier\ncoefficients from which the algebraic expressions can be identified using the\nLLL algorithm. The second approach is restricted to genus zero subgroups and\nuses efficient methods to compute the Belyi map from which the modular forms\ncan be constructed.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 1689263,
        "score": 11.426680564880371
    },
    {
        "title": "On the zeros of certain modular functions for the normalizers of\n  congruence subgroups of low levels I",
        "paperAbstract": "  We research the location of the zeros of the Eisenstein series and the\nmodular functions from the Hecke type Faber polynomials associated with the\nnormalizers of congruence subgroups which are of genus zero and of level at\nmost twelve.\n  In Part I, we will consider the general theory of modular functions for the\nnormalizers.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 48604,
        "score": 11.19227123260498
    },
    {
        "title": "Congruence and Noncongruence Subgroups of Gamma(2) via Graphs on\n  Surfaces",
        "paperAbstract": "  There is an established bijection between finite-index subgroups Gamma of\nGamma(2) and bipartite graphs on surfaces, or, equivalently, certain triples of\npermutations. We utilize this relationship to study both congruence and\nnoncongruence subgroups in terms of the corresponding graphs. We show some\nelementary criteria which can be used to identify many noncongruence subgroups.\nGiven a graph on a surface, we have a method to produce generators for the\ncorresponding group Gamma in terms of the generators of Gamma(2). Given\ngenerators for Gamma(2n), we show how to determine whether or not a graph of\nlevel 2n corresponds to a congruence subgroup.\n",
        "query": "number theory modular form functions noncongruence  and congruence ",
        "docId": 448841,
        "score": 11.166053771972656
    },
    {
        "title": "Intransitive Dice",
        "paperAbstract": "  We consider $n$-sided dice whose face values lie between $1$ and $n$ and\nwhose faces sum to $n(n+1)/2$. For two dice $A$ and $B$, define $A \\succ B$ if\nit is more likely for $A$ to show a higher face than $B$. Suppose $k$ such dice\n$A_1,\\dots,A_k$ are randomly selected. We conjecture that the probability of\nties goes to 0 as $n$ grows. We conjecture and provide some supporting evidence\nthat---contrary to intuition---each of the $2^{k \\choose 2}$ assignments of\n$\\succ$ or $\\prec$ to each pair is equally likely asymptotically. For a\nspecific example, suppose we randomly select $k$ dice $A_1,\\dots,A_k$ and\nobserve that $A_1 \\succ A_2 \\succ \\ldots \\succ A_k$. Then our conjecture\nasserts that the outcomes $A_k \\succ A_1$ and $A_1 \\prec A_k$ both have\nprobability approaching $1/2$ as $n \\rightarrow \\infty$.\n",
        "query": "intransitive dice rolling ",
        "docId": 480172,
        "score": 17.69561004638672
    },
    {
        "title": "Quantum dice rolling",
        "paperAbstract": "  A coin is just a two sided dice. Recently, Mochon proved that quantum weak\ncoin flipping with an arbitrarily small bias is possible. However, the use of\nquantum resources to allow N remote distrustful parties to roll an N-sided dice\nhas yet to be addressed. In this paper we show that contrary to the classical\ncase, N-sided dice rolling with arbitrarily small bias is possible for any N.\nIn addition, we present a six-round three-sided dice rolling protocol,\nachieving a bias of 0.181, which incorporates weak imbalanced coin flipping.\n",
        "query": "intransitive dice rolling ",
        "docId": 139453,
        "score": 15.08774185180664
    },
    {
        "title": "Intransitive dice tournament is not quasirandom",
        "paperAbstract": "  We settle a version of the conjecture about intransitive dice posed by\nConrey, Gabbard, Grant, Liu and Morrison in 2016 and Polymath in 2017. We\nconsider generalized dice with $n$ faces and we say that a die $A$ beats $B$ if\na random face of $A$ is more likely to show a higher number than a random face\nof $B$. We study random dice with faces drawn iid from the uniform distribution\non $[0,1]$ and conditioned on the sum of the faces equal to $n/2$. Considering\nthe \"beats\" relation for three such random dice, Polymath showed that each of\neight possible tournaments between them is asymptotically equally likely. In\nparticular, three dice form an intransitive cycle with probability converging\nto $1/4$. In this paper we prove that for four random dice not all tournaments\nare equally likely and the probability of a transitive tournament is strictly\nhigher than $3/8$.\n",
        "query": "intransitive dice rolling ",
        "docId": 1382815,
        "score": 15.015552520751953
    },
    {
        "title": "Generalized Intransitive Dice: Mimicking an Arbitrary Tournament",
        "paperAbstract": "  A generalized $N$-sided die is a random variable $D$ on a sample space of $N$\nequally likely outcomes taking values in the set of positive integers. We say\nof independent $N$ sided dice $D_i, D_j$ that $D_i$ beats $D_j$, written $D_i\n\\to D_j$, if $Prob(D_i \u003e D_j) \u003e \\frac{1}{2} $. Examples are known of\nintransitive $6$-sided dice, i.e. $D_1 \\to D_2 \\to D_3$ but $D_3 \\to D_1$. A\ntournament of size $n$ is a choice of direction $i \\to j$ for each edge of the\ncomplete graph on $n$ vertices. We show that if $R$ is tournament on the set\n$\\{ 1, \\dots, n \\}$, then for sufficiently large $N$ there exist sets of\nindependent $N$-sided dice $\\{ D_1, \\dots, D_n \\}$ such that $D_i \\to D_j$ if\nand only if $i \\to j$ in $R$.\n",
        "query": "intransitive dice rolling ",
        "docId": 1079024,
        "score": 11.97722053527832
    },
    {
        "title": "Emerging Diversity in a Population of Evolving Intransitive Dice",
        "paperAbstract": "  Exploiting the mathematical curiosity of intransitive dice, we present a\nsimple theoretical model for co-evolution that captures scales ranging from the\ngenome of the individual to the system-wide emergence of species diversity. We\nstudy a set of evolving agents that interact competitively in a closed system,\nin which both the dynamics of mutations and competitive advantage emerge\ndirectly from interpreting a genome as the sides of a die. The model\ndemonstrates sympatric speciation where new species evolve from existing ones\nwhile in contact with the entire ecosystem. Allowing free mutations both in the\ngenomes and the mutation rates, we find, in contrast to hierarchical models of\nfitness, the emergence of a metastable state of finite mutation rate and\ndiversity.\n",
        "query": "intransitive dice rolling ",
        "docId": 1756551,
        "score": 11.442998886108398
    },
    {
        "title": "Intransitive geometries",
        "paperAbstract": "  A lemma of Tits establishes a connection between the simple connectivity of\nan incidence geometry and the universal completion of an amalgam induced by a\nsufficiently transitive group of automorphisms of that geometry. In the present\npaper, we generalize this lemma to intransitive geometries, thus opening the\ndoor for numerous applications. We treat ourselves some amalgams related to\nintransitive actions of finite orthogonal groups, as a first class of examples.\n",
        "query": "intransitive dice rolling ",
        "docId": 19434,
        "score": 11.022180557250977
    },
    {
        "title": "Intransitive Machines",
        "paperAbstract": "  The intransitive cycle of superiority is characterized by such binary\nrelations between A, B, and C that A is superior to B, B is superior to C, and\nC is superior to A (i.e., A\u003eB\u003eC\u003eA - in contrast with transitive relations\nA\u003eB\u003eC). The first part of the article presents a brief review of studies of\nintransitive cycles in various disciplines (mathematics, biology, sociology,\nlogical games, decision theory, etc.), and their reflections in educational\nmaterials. The second part of the article introduces the issue of\nintransitivity in elementary physics. We present principles of building\nmechanical intransitive devices in correspondence with the structure of the\nCondorcet paradox, and describe five intransitive devices: intransitive gears;\nlevers; pulleys, wheels, and axles; wedges; inclined planes. Each of the\nmechanisms are constructed as compositions of simple machines and show\nparadoxical intransitivity of relations such as \"to rotate faster than\", \"to\nlift\", \"to be stronger than\" in some geometrical constructions. The article is\nan invitation to develop teaching materials and problems advancing the\nunderstanding of transitivity and intransitivity in various areas, including\nphysics education.\n",
        "query": "intransitive dice rolling ",
        "docId": 1023885,
        "score": 11.001007080078125
    },
    {
        "title": "Generalized Intransitive Dice II: Partition Constructions",
        "paperAbstract": "  A generalized $N$-sided die is a random variable $D$ on a sample space of $N$\nequally likely outcomes taking values in the set of positive integers. We say\nof independent $N$ sided dice $D_i, D_j$ that $D_i$ beats $D_j$, written $D_i\n\\to D_j$, if $Prob(D_i \u003e D_j) \u003e \\frac{1}{2} $. A collection of dice $\\{ D_i : i\n\u003d 1, \\dots, n \\}$ models a tournament on the set $[n] \u003d \\{ 1, 2, \\dots, n \\}$,\ni.e. a complete digraph with $n$ vertices, when $D_i \\to D_j$ if and only if $i\n\\to j$ in the tournament. By using $n$-fold partitions of the set $[Nn] $ with\neach set of size $N$ we can model an arbitrary tournament on $[n]$. A bound on\nthe required size of $N$ is obtained by examples with $N \u003d 3^{n-2}$.\n",
        "query": "intransitive dice rolling ",
        "docId": 1120186,
        "score": 10.52151107788086
    },
    {
        "title": "Quantum dice rolling: A multi-outcome generalization of quantum coin\n  flipping",
        "paperAbstract": "  We generalize the problem of coin flipping to more than two outcomes and\nparties. We term this problem dice rolling, and study both its weak and strong\nvariants. We prove by construction that in quantum settings (i) weak N-sided\ndice rolling admits an arbitrarily small bias for any value of N, and (ii)\ntwo-party strong N-sided dice rolling saturates the corresponding\ngeneralization of Kitaev\u0027s bound for any value of N. In addition, we make use\nof this last result to introduce a family of optimal 2m-party strong n^m-sided\ndice rolling protocols for any value of m and n.\n",
        "query": "intransitive dice rolling ",
        "docId": 146554,
        "score": 10.441509246826172
    },
    {
        "title": "Information without rolling dice",
        "paperAbstract": "  The deterministic notions of capacity and entropy are studied in the context\nof communication and storage of information using square-integrable,\nbandlimited signals subject to perturbation. The $(\\epsilon,\\delta)$-capacity,\nthat extends the Kolmogorov $\\epsilon$-capacity to packing sets of overlap at\nmost $\\delta$, is introduced and compared to the Shannon capacity. The\nfunctional form of the results indicates that in both Kolmogorov and Shannon\u0027s\nsettings, capacity and entropy grow linearly with the number of degrees of\nfreedom, but only logarithmically with the signal to noise ratio. This basic\ninsight transcends the details of the stochastic or deterministic description\nof the information-theoretic model. For $\\delta\u003d0$, the analysis leads to new\nbounds on the Kolmogorov $\\epsilon$-capacity, and to a tight asymptotic\nexpression of the Kolmogorov $\\epsilon$-entropy of bandlimited signals. A\ndeterministic notion of error exponent is introduced. Applications of the\ntheory are briefly discussed.\n",
        "query": "intransitive dice rolling ",
        "docId": 616559,
        "score": 10.057760238647461
    },
    {
        "title": "A Survey of the Usages of Deep Learning in Natural Language Processing",
        "paperAbstract": "  Over the last several years, the field of natural language processing has\nbeen propelled forward by an explosion in the use of deep learning models. This\nsurvey provides a brief introduction to the field and a quick overview of deep\nlearning architectures and methods. It then sifts through the plethora of\nrecent studies and summarizes a large assortment of relevant contributions.\nAnalyzed research areas include several core linguistic processing issues in\naddition to a number of applications of computational linguistics. A discussion\nof the current state of the art is then provided along with recommendations for\nfuture research in the field.\n",
        "query": "natural language processing and deep learning",
        "docId": 1008060,
        "score": 14.936250686645508
    },
    {
        "title": "Natural Language Processing Advancements By Deep Learning: A Survey",
        "paperAbstract": "  Natural Language Processing (NLP) helps empower intelligent machines by\nenhancing a better understanding of the human language for linguistic-based\nhuman-computer communication. Recent developments in computational power and\nthe advent of large amounts of linguistic data have heightened the need and\ndemand for automating semantic analysis using data-driven approaches. The\nutilization of data-driven strategies is pervasive now due to the significant\nimprovements demonstrated through the usage of deep learning methods in areas\nsuch as Computer Vision, Automatic Speech Recognition, and in particular, NLP.\nThis survey categorizes and addresses the different aspects and applications of\nNLP that have benefited from deep learning. It covers core NLP tasks and\napplications and describes how deep learning methods and models advance these\nareas. We further analyze and compare different approaches and state-of-the-art\nmodels.\n",
        "query": "natural language processing and deep learning",
        "docId": 1251555,
        "score": 14.59706974029541
    },
    {
        "title": "Recent Trends in Deep Learning Based Natural Language Processing",
        "paperAbstract": "  Deep learning methods employ multiple processing layers to learn hierarchical\nrepresentations of data and have produced state-of-the-art results in many\ndomains. Recently, a variety of model designs and methods have blossomed in the\ncontext of natural language processing (NLP). In this paper, we review\nsignificant deep learning related models and methods that have been employed\nfor numerous NLP tasks and provide a walk-through of their evolution. We also\nsummarize, compare and contrast the various models and put forward a detailed\nunderstanding of the past, present and future of deep learning in NLP.\n",
        "query": "natural language processing and deep learning",
        "docId": 877721,
        "score": 14.398652076721191
    },
    {
        "title": "Knowledge Efficient Deep Learning for Natural Language Processing",
        "paperAbstract": "  Deep learning has become the workhorse for a wide range of natural language\nprocessing applications. But much of the success of deep learning relies on\nannotated examples. Annotation is time-consuming and expensive to produce at\nscale. Here we are interested in methods for reducing the required quantity of\nannotated data -- by making the learning methods more knowledge efficient so as\nto make them more applicable in low annotation (low resource) settings. There\nare various classical approaches to making the models more knowledge efficient\nsuch as multi-task learning, transfer learning, weakly supervised and\nunsupervised learning etc. This thesis focuses on adapting such classical\nmethods to modern deep learning models and algorithms.\n  This thesis describes four works aimed at making machine learning models more\nknowledge efficient. First, we propose a knowledge rich deep learning model\n(KRDL) as a unifying learning framework for incorporating prior knowledge into\ndeep models. In particular, we apply KRDL built on Markov logic networks to\ndenoise weak supervision. Second, we apply a KRDL model to assist the machine\nreading models to find the correct evidence sentences that can support their\ndecision. Third, we investigate the knowledge transfer techniques in\nmultilingual setting, where we proposed a method that can improve pre-trained\nmultilingual BERT based on the bilingual dictionary. Fourth, we present an\nepisodic memory network for language modelling, in which we encode the large\nexternal knowledge for the pre-trained GPT.\n",
        "query": "natural language processing and deep learning",
        "docId": 1340600,
        "score": 14.287819862365723
    },
    {
        "title": "DeepZensols: Deep Natural Language Processing Framework",
        "paperAbstract": "  Reproducing results in publications by distributing publicly available source\ncode is becoming ever more popular. Given the difficulty of reproducing machine\nlearning (ML) experiments, there have been significant efforts in reducing the\nvariance of these results. As in any science, the ability to consistently\nreproduce results effectively strengthens the underlying hypothesis of the\nwork, and thus, should be regarded as important as the novel aspect of the\nresearch itself. The contribution of this work is a framework that is able to\nreproduce consistent results and provides a means of easily creating, training,\nand evaluating natural language processing (NLP) deep learning (DL) models.\n",
        "query": "natural language processing and deep learning",
        "docId": 1526204,
        "score": 13.473837852478027
    },
    {
        "title": "Development of Deep Learning Based Natural Language Processing Model for\n  Turkish",
        "paperAbstract": "  Natural language is one of the most fundamental features that distinguish\npeople from other living things and enable people to communicate each other.\nLanguage is a tool that enables people to express their feelings and thoughts\nand to transfers cultures through generations. Texts and audio are examples of\nnatural language in daily life. In the natural language, many words disappear\nin time, on the other hand new words are derived. Therefore, while the process\nof natural language processing (NLP) is complex even for human, it is difficult\nto process in computer system. The area of linguistics examines how people use\nlanguage. NLP, which requires the collaboration of linguists and computer\nscientists, plays an important role in human computer interaction. Studies in\nNLP have increased with the use of artificial intelligence technologies in the\nfield of linguistics. With the deep learning methods which are one of the\nartificial intelligence study areas, platforms close to natural language are\nbeing developed. Developed platforms for language comprehension, machine\ntranslation and part of speech (POS) tagging benefit from deep learning\nmethods. Recurrent Neural Network (RNN), one of the deep learning\narchitectures, is preferred for processing sequential data such as text or\naudio data. In this study, Turkish POS tagging model has been proposed by using\nBidirectional Long-Short Term Memory (BLSTM) which is an RNN type. The proposed\nPOS tagging model is provided to natural language researchers with a platform\nthat allows them to perform and use their own analysis. In the development\nphase of the platform developed by using BLSTM, the error rate of the POS\ntagger has been reduced by taking feedback with expert opinion.\n",
        "query": "natural language processing and deep learning",
        "docId": 1124135,
        "score": 13.462987899780273
    },
    {
        "title": "A Survey of Active Learning for Natural Language Processing",
        "paperAbstract": "  In this work, we provide a survey of active learning (AL) for its\napplications in natural language processing (NLP). In addition to a\nfine-grained categorization of query strategies, we also investigate several\nother important aspects of applying AL to NLP problems. These include AL for\nstructured prediction tasks, annotation cost, model learning (especially with\ndeep neural models), and starting and stopping AL. Finally, we conclude with a\ndiscussion of related topics and future directions.\n",
        "query": "natural language processing and deep learning",
        "docId": 1731464,
        "score": 13.409799575805664
    },
    {
        "title": "Evolution of transfer learning in natural language processing",
        "paperAbstract": "  In this paper, we present a study of the recent advancements which have\nhelped bring Transfer Learning to NLP through the use of semi-supervised\ntraining. We discuss cutting-edge methods and architectures such as BERT, GPT,\nELMo, ULMFit among others. Classically, tasks in natural language processing\nhave been performed through rule-based and statistical methodologies. However,\nowing to the vast nature of natural languages these methods do not generalise\nwell and failed to learn the nuances of language. Thus machine learning\nalgorithms such as Naive Bayes and decision trees coupled with traditional\nmodels such as Bag-of-Words and N-grams were used to usurp this problem.\nEventually, with the advent of advanced recurrent neural network architectures\nsuch as the LSTM, we were able to achieve state-of-the-art performance in\nseveral natural language processing tasks such as text classification and\nmachine translation. We talk about how Transfer Learning has brought about the\nwell-known ImageNet moment for NLP. Several advanced architectures such as the\nTransformer and its variants have allowed practitioners to leverage knowledge\ngained from unrelated task to drastically fasten convergence and provide better\nperformance on the target task. This survey represents an effort at providing a\nsuccinct yet complete understanding of the recent advances in natural language\nprocessing using deep learning in with a special focus on detailing transfer\nlearning and its potential advantages.\n",
        "query": "natural language processing and deep learning",
        "docId": 1191289,
        "score": 13.405004501342773
    },
    {
        "title": "Experimental Standards for Deep Learning in Natural Language Processing\n  Research",
        "paperAbstract": "  The field of Deep Learning (DL) has undergone explosive growth during the\nlast decade, with a substantial impact on Natural Language Processing (NLP) as\nwell. Yet, compared to more established disciplines, a lack of common\nexperimental standards remains an open challenge to the field at large.\nStarting from fundamental scientific principles, we distill ongoing discussions\non experimental standards in NLP into a single, widely-applicable methodology.\nFollowing these best practices is crucial to strengthen experimental evidence,\nimprove reproducibility and support scientific progress. These standards are\nfurther collected in a public repository to help them transparently adapt to\nfuture needs.\n",
        "query": "natural language processing and deep learning",
        "docId": 1636389,
        "score": 13.350086212158203
    },
    {
        "title": "Deep Natural Language Processing for LinkedIn Search",
        "paperAbstract": "  Many search systems work with large amounts of natural language data, e.g.,\nsearch queries, user profiles, and documents. Building a successful search\nsystem requires a thorough understanding of textual data semantics, where deep\nlearning based natural language processing techniques (deep NLP) can be of\ngreat help. In this paper, we introduce a comprehensive study for applying deep\nNLP techniques to five representative tasks in search systems: query intent\nprediction (classification), query tagging (sequential tagging), document\nranking (ranking), query auto completion (language modeling), and query\nsuggestion (sequence to sequence). We also introduce BERT pre-training as a\nsixth task that can be applied to many of the other tasks. Through the model\ndesign and experiments of the six tasks, readers can find answers to four\nimportant questions: (1). When is deep NLP helpful/not helpful in search\nsystems? (2). How to address latency challenges? (3). How to ensure model\nrobustness? This work builds on existing efforts of LinkedIn search, and is\ntested at scale on LinkedIn\u0027s commercial search engines. We believe our\nexperiences can provide useful insights for the industry and research\ncommunities.\n",
        "query": "natural language processing and deep learning",
        "docId": 1522115,
        "score": 13.245146751403809
    },
    {
        "title": "Mining Rank Data",
        "paperAbstract": "  The problem of frequent pattern mining has been studied quite extensively for\nvarious types of data, including sets, sequences, and graphs. Somewhat\nsurprisingly, another important type of data, namely rank data, has received\nvery little attention in data mining so far. In this paper, we therefore\naddresses the problem of mining rank data, that is, data in the form of\nrankings (total orders) of an underlying set of items. More specifically, two\ntypes of patterns are considered, namely frequent rankings and dependencies\nbetween such rankings in the form of association rules. Algorithms for mining\nfrequent rankings and frequent closed rankings are proposed and tested\nexperimentally, using both synthetic and real data.\n",
        "query": "types of the data mining",
        "docId": 991537,
        "score": 10.332682609558105
    },
    {
        "title": "Proof Mining with Dependent Types",
        "paperAbstract": "  Several approaches exist to data-mining big corpora of formal proofs. Some of\nthese approaches are based on statistical machine learning, and some -- on\ntheory exploration. However, most are developed for either untyped or\nsimply-typed theorem provers. In this paper, we present a method that combines\nstatistical data mining and theory exploration in order to analyse and automate\nproofs in dependently typed language of Coq.\n",
        "query": "types of the data mining",
        "docId": 848221,
        "score": 9.841279983520508
    },
    {
        "title": "Journey from Data Mining to Web Mining to Big Data",
        "paperAbstract": "  This paper describes the journey of big data starting from data mining to web\nmining to big data. It discusses each of this method in brief and also provides\ntheir applications. It states the importance of mining big data today using\nfast and novel approaches.\n",
        "query": "types of the data mining",
        "docId": 517193,
        "score": 9.45217514038086
    },
    {
        "title": "Application Of Data Mining In Bioinformatics",
        "paperAbstract": "  This article highlights some of the basic concepts of bioinformatics and data\nmining. The major research areas of bioinformatics are highlighted. The\napplication of data mining in the domain of bioinformatics is explained. It\nalso highlights some of the current challenges and opportunities of data mining\nin bioinformatics.\n",
        "query": "types of the data mining",
        "docId": 340126,
        "score": 9.424527168273926
    },
    {
        "title": "Spatiotemporal Data Mining: A Survey",
        "paperAbstract": "  Spatiotemporal data mining aims to discover interesting, useful but\nnon-trivial patterns in big spatial and spatiotemporal data. They are used in\nvarious application domains such as public safety, ecology, epidemiology, earth\nscience, etc. This problem is challenging because of the high societal cost of\nspurious patterns and exorbitant computational cost. Recent surveys of\nspatiotemporal data mining need update due to rapid growth. In addition, they\ndid not adequately survey parallel techniques for spatiotemporal data mining.\nThis paper provides a more up-to-date survey of spatiotemporal data mining\nmethods. Furthermore, it has a detailed survey of parallel formulations of\nspatiotemporal data mining.\n",
        "query": "types of the data mining",
        "docId": 1673173,
        "score": 8.888530731201172
    },
    {
        "title": "Mining atmospheric data",
        "paperAbstract": "  This paper overviews two interdependent issues important for mining remote\nsensing data (e.g. images) obtained from atmospheric monitoring missions. The\nfirst issue relates the building new public datasets and benchmarks, which are\nhot priority of the remote sensing community. The second issue is the\ninvestigation of deep learning methodologies for atmospheric data\nclassification based on vast amount of data without annotations and with\nlocalized annotated data provided by sparse observing networks at the surface.\nThe targeted application is air quality assessment and prediction. Air quality\nis defined as the pollution level linked with several atmospheric constituents\nsuch as gases and aerosols. There are dependency relationships between the bad\nair quality, caused by air pollution, and the public health. The target\napplication is the development of a fast prediction model for local and\nregional air quality assessment and tracking. The results of mining data will\nhave significant implication for citizen and decision makers by providing a\nfast prediction and reliable air quality monitoring system able to cover the\nlocal and regional scale through intelligent extrapolation of sparse\nground-based in situ measurement networks.\n",
        "query": "types of the data mining",
        "docId": 1491756,
        "score": 8.729225158691406
    },
    {
        "title": "Scientific Data Mining in Astronomy",
        "paperAbstract": "  We describe the application of data mining algorithms to research problems in\nastronomy. We posit that data mining has always been fundamental to\nastronomical research, since data mining is the basis of evidence-based\ndiscovery, including classification, clustering, and novelty discovery. These\nalgorithms represent a major set of computational tools for discovery in large\ndatabases, which will be increasingly essential in the era of data-intensive\nastronomy. Historical examples of data mining in astronomy are reviewed,\nfollowed by a discussion of one of the largest data-producing projects\nanticipated for the coming decade: the Large Synoptic Survey Telescope (LSST).\nTo facilitate data-driven discoveries in astronomy, we envision a new\ndata-oriented research paradigm for astronomy and astrophysics --\nastroinformatics. Astroinformatics is described as both a research approach and\nan educational imperative for modern data-intensive astronomy. An important\napplication area for large time-domain sky surveys (such as LSST) is the rapid\nidentification, characterization, and classification of real-time sky events\n(including moving objects, photometrically variable objects, and the appearance\nof transients). We describe one possible implementation of a classification\nbroker for such events, which incorporates several astroinformatics techniques:\nuser annotation, semantic tagging, metadata markup, heterogeneous data\nintegration, and distributed data mining. Examples of these types of\ncollaborative classification and discovery approaches within other science\ndisciplines are presented.\n",
        "query": "types of the data mining",
        "docId": 154526,
        "score": 8.647430419921875
    },
    {
        "title": "Crowd-Powered Data Mining",
        "paperAbstract": "  Many data mining tasks cannot be completely addressed by auto- mated\nprocesses, such as sentiment analysis and image classification. Crowdsourcing\nis an effective way to harness the human cognitive ability to process these\nmachine-hard tasks. Thanks to public crowdsourcing platforms, e.g., Amazon\nMechanical Turk and Crowd- Flower, we can easily involve hundreds of thousands\nof ordinary workers (i.e., the crowd) to address these machine-hard tasks. In\nthis tutorial, we will survey and synthesize a wide spectrum of existing\nstudies on crowd-powered data mining. We first give an overview of\ncrowdsourcing, and then summarize the fundamental techniques, including quality\ncontrol, cost control, and latency control, which must be considered in\ncrowdsourced data mining. Next we review crowd-powered data mining operations,\nincluding classification, clustering, pattern mining, machine learning using\nthe crowd (including deep learning, transfer learning and semi-supervised\nlearning) and knowledge discovery. Finally, we provide the emerging challenges\nin crowdsourced data mining.\n",
        "query": "types of the data mining",
        "docId": 990608,
        "score": 8.461841583251953
    },
    {
        "title": "Data Mining in Astronomical Databases",
        "paperAbstract": "  A Virtual Observatory (VO) will enable transparent and efficient access,\nsearch, retrieval, and visualization of data across multiple data repositories,\nwhich are generally heterogeneous and distributed. Aspects of data mining that\napply to a variety of science user scenarios with a VO are reviewed.\n",
        "query": "types of the data mining",
        "docId": 1820023,
        "score": 8.45211410522461
    },
    {
        "title": "Multi Relational Data Mining Approaches: A Data Mining Technique",
        "paperAbstract": "  The multi relational data mining approach has developed as an alternative way\nfor handling the structured data such that RDBMS. This will provides the mining\nin multiple tables directly. In MRDM the patterns are available in multiple\ntables (relations) from a relational database. As the data are available over\nthe many tables which will affect the many problems in the practice of the data\nmining. To deal with this problem, one either constructs a single table by\nPropositionalisation, or uses a Multi-Relational Data Mining algorithm. MRDM\napproaches have been successfully applied in the area of bioinformatics. Three\npopular pattern finding techniques classification, clustering and association\nare frequently used in MRDM. Multi relational approach has developed as an\nalternative for analyzing the structured data such as relational database. MRDM\nallowing applying directly in the data mining in multiple tables. To avoid the\nexpensive joining operations and semantic losses we used the MRDM technique.\nThis paper focuses some of the application areas of MRDM and feature directions\nas well as the comparison of ILP, GM, SSDM and MRDM\n",
        "query": "types of the data mining",
        "docId": 386117,
        "score": 8.430639266967773
    },
    {
        "title": "Firefly Algorithms for Multimodal Optimization",
        "paperAbstract": "  Nature-inspired algorithms are among the most powerful algorithms for\noptimization. This paper intends to provide a detailed description of a new\nFirefly Algorithm (FA) for multimodal optimization applications. We will\ncompare the proposed firefly algorithm with other metaheuristic algorithms such\nas particle swarm optimization (PSO). Simulations and results indicate that the\nproposed firefly algorithm is superior to existing metaheuristic algorithms.\nFinally we will discuss its applications and implications for further research.\n",
        "query": "optimization algorithms ",
        "docId": 177273,
        "score": 8.345537185668945
    },
    {
        "title": "Stochastic Optimization Algorithms",
        "paperAbstract": "  When looking for a solution, deterministic methods have the enormous\nadvantage that they do find global optima. Unfortunately, they are very\nCPU-intensive, and are useless on untractable NP-hard problems that would\nrequire thousands of years for cutting-edge computers to explore. In order to\nget a result, one needs to revert to stochastic algorithms, that sample the\nsearch space without exploring it thoroughly. Such algorithms can find very\ngood results, without any guarantee that the global optimum has been reached;\nbut there is often no other choice than using them. This chapter is a short\nintroduction to the main methods used in stochastic optimization.\n",
        "query": "optimization algorithms ",
        "docId": 3779,
        "score": 8.251981735229492
    },
    {
        "title": "On the Convergence of Bound Optimization Algorithms",
        "paperAbstract": "  Many practitioners who use the EM algorithm complain that it is sometimes\nslow. When does this happen, and what can be done about it? In this paper, we\nstudy the general class of bound optimization algorithms - including\nExpectation-Maximization, Iterative Scaling and CCCP - and their relationship\nto direct optimization algorithms such as gradient-based methods for parameter\nlearning. We derive a general relationship between the updates performed by\nbound optimization methods and those of gradient and second-order methods and\nidentify analytic conditions under which bound optimization algorithms exhibit\nquasi-Newton behavior, and conditions under which they possess poor,\nfirst-order convergence. Based on this analysis, we consider several specific\nalgorithms, interpret and analyze their convergence properties and provide some\nrecipes for preprocessing input to these algorithms to yield faster convergence\nbehavior. We report empirical results supporting our analysis and showing that\nsimple data preprocessing can result in dramatically improved performance of\nbound optimizers in practice.\n",
        "query": "optimization algorithms ",
        "docId": 392106,
        "score": 7.79159688949585
    },
    {
        "title": "Convex Optimization: Algorithms and Complexity",
        "paperAbstract": "  This monograph presents the main complexity theorems in convex optimization\nand their corresponding algorithms. Starting from the fundamental theory of\nblack-box optimization, the material progresses towards recent advances in\nstructural optimization and stochastic optimization. Our presentation of\nblack-box optimization, strongly influenced by Nesterov\u0027s seminal book and\nNemirovski\u0027s lecture notes, includes the analysis of cutting plane methods, as\nwell as (accelerated) gradient descent schemes. We also pay special attention\nto non-Euclidean settings (relevant algorithms include Frank-Wolfe, mirror\ndescent, and dual averaging) and discuss their relevance in machine learning.\nWe provide a gentle introduction to structural optimization with FISTA (to\noptimize a sum of a smooth and a simple non-smooth term), saddle-point mirror\nprox (Nemirovski\u0027s alternative to Nesterov\u0027s smoothing), and a concise\ndescription of interior point methods. In stochastic optimization we discuss\nstochastic gradient descent, mini-batches, random coordinate descent, and\nsublinear algorithms. We also briefly touch upon convex relaxation of\ncombinatorial problems and the use of randomness to round solutions, as well as\nrandom walks based methods.\n",
        "query": "optimization algorithms ",
        "docId": 525888,
        "score": 7.753931999206543
    },
    {
        "title": "Algorithms for Weighted Boolean Optimization",
        "paperAbstract": "  The Pseudo-Boolean Optimization (PBO) and Maximum Satisfiability (MaxSAT)\nproblems are natural optimization extensions of Boolean Satisfiability (SAT).\n  In the recent past, different algorithms have been proposed for PBO and for\nMaxSAT, despite the existence of straightforward mappings from PBO to MaxSAT\nand vice-versa. This papers proposes Weighted Boolean Optimization (WBO), a new\nunified framework that aggregates and extends PBO and MaxSAT. In addition, the\npaper proposes a new unsatisfiability-based algorithm for WBO, based on recent\nunsatisfiability-based algorithms for MaxSAT. Besides standard MaxSAT, the new\nalgorithm can also be used to solve weighted MaxSAT and PBO, handling\npseudo-Boolean constraints either natively or by translation to clausal form.\nExperimental results illustrate that unsatisfiability-based algorithms for\nMaxSAT can be orders of magnitude more efficient than existing dedicated\nalgorithms. Finally, the paper illustrates how other algorithms for either PBO\nor MaxSAT can be extended to WBO.\n",
        "query": "optimization algorithms ",
        "docId": 111962,
        "score": 7.737422943115234
    },
    {
        "title": "Convergence Analysis of Optimization Algorithms",
        "paperAbstract": "  The regret bound of an optimization algorithms is one of the basic criteria\nfor evaluating the performance of the given algorithm. By inspecting the\ndifferences between the regret bounds of traditional algorithms and adaptive\none, we provide a guide for choosing an optimizer with respect to the given\ndata set and the loss function. For analysis, we assume that the loss function\nis convex and its gradient is Lipschitz continuous.\n",
        "query": "optimization algorithms ",
        "docId": 866679,
        "score": 7.701959133148193
    },
    {
        "title": "Best practices for comparing optimization algorithms",
        "paperAbstract": "  Comparing, or benchmarking, of optimization algorithms is a complicated task\nthat involves many subtle considerations to yield a fair and unbiased\nevaluation. In this paper, we systematically review the benchmarking process of\noptimization algorithms, and discuss the challenges of fair comparison. We\nprovide suggestions for each step of the comparison process and highlight the\npitfalls to avoid when evaluating the performance of optimization algorithms.\nWe also discuss various methods of reporting the benchmarking results. Finally,\nsome suggestions for future research are presented to improve the current\nbenchmarking process.\n",
        "query": "optimization algorithms ",
        "docId": 893108,
        "score": 7.431210994720459
    },
    {
        "title": "A Comparison of Optimization Algorithms for Deep Learning",
        "paperAbstract": "  In recent years, we have witnessed the rise of deep learning. Deep neural\nnetworks have proved their success in many areas. However, the optimization of\nthese networks has become more difficult as neural networks going deeper and\ndatasets becoming bigger. Therefore, more advanced optimization algorithms have\nbeen proposed over the past years. In this study, widely used optimization\nalgorithms for deep learning are examined in detail. To this end, these\nalgorithms called adaptive gradient methods are implemented for both supervised\nand unsupervised tasks. The behaviour of the algorithms during training and\nresults on four image datasets, namely, MNIST, CIFAR-10, Kaggle Flowers and\nLabeled Faces in the Wild are compared by pointing out their differences\nagainst basic optimization algorithms.\n",
        "query": "optimization algorithms ",
        "docId": 1325680,
        "score": 7.422945976257324
    },
    {
        "title": "Provably Faster Algorithms for Bilevel Optimization",
        "paperAbstract": "  Bilevel optimization has been widely applied in many important machine\nlearning applications such as hyperparameter optimization and meta-learning.\nRecently, several momentum-based algorithms have been proposed to solve bilevel\noptimization problems faster. However, those momentum-based algorithms do not\nachieve provably better computational complexity than $\\mathcal{\\widetilde\nO}(\\epsilon^{-2})$ of the SGD-based algorithm. In this paper, we propose two\nnew algorithms for bilevel optimization, where the first algorithm adopts\nmomentum-based recursive iterations, and the second algorithm adopts recursive\ngradient estimations in nested loops to decrease the variance. We show that\nboth algorithms achieve the complexity of $\\mathcal{\\widetilde\nO}(\\epsilon^{-1.5})$, which outperforms all existing algorithms by the order of\nmagnitude. Our experiments validate our theoretical results and demonstrate the\nsuperior empirical performance of our algorithms in hyperparameter\napplications.\n",
        "query": "optimization algorithms ",
        "docId": 1482456,
        "score": 7.306224346160889
    },
    {
        "title": "The Analysis of Optimization Algorithms, A Dissipativity Approach",
        "paperAbstract": "  Optimization problems in engineering and applied mathematics are typically\nsolved in an iterative fashion, by systematically adjusting the variables of\ninterest until an adequate solution is found. The iterative algorithms that\ngovern these systematic adjustments can be viewed as a control system. In\ncontrol systems, the output in measured and the input is adjusted using\nfeedback to drive the error to zero. Similarly, in iterative algorithms, the\noptimization objective is evaluated and the candidate solution is adjusted to\ndrive it toward the optimal point. Choosing an algorithm that works well for a\nvariety of optimization problems is akin to robust controller design. Just as\ndissipativity theory can be used to analyze the stability properties of control\nsystems, it can also be used to analyze the convergence properties of iterative\nalgorithms. By defining an appropriate notion of \"energy\" that dissipates with\nevery iteration of the algorithm, the convergence properties of the algorithm\ncan be characterized. This article formalizes the connection between iterative\nalgorithms and control systems and shows through examples how dissipativity\ntheory can be used to analyze the performance of many classes of optimization\nalgorithms. This control-theoretic viewpoint enables the selection and tuning\nof optimization algorithms to be performed in an automated and systematic way.\n",
        "query": "optimization algorithms ",
        "docId": 1658676,
        "score": 7.273656845092773
    },
    {
        "title": "GDP growth rate and population",
        "paperAbstract": "  Real GDP growth rate in developed countries is found to be a sum of two\nterms. The first term is the reciprocal value of the duration of the period of\nmean income growth with work experience, Tcr. The current value of Tcr in the\nUSA is 40 years. The second term is inherently related to population and\ndefined by the relative change in the number of people with a specific age (9\nyears in the USA), (1/2)*dN9(t) /N9(t), where N9(t) is the number of\n9-year-olds at time t. The Tcr grows as the square root of real GDP per capita.\nHence, evolution of real GDP is defined by only one parameter - the number of\npeople of the specific age. Predictions for the USA, the UK, and France are\npresented and discussed. A similar relationship is derived for real GDP per\ncapita. Annual increment of GDP per capita is also a combination of economic\ntrend term and the same specific age population term. The economic trend term\nduring last 55 years is equal to $400 (2002 US dollars) divided by the attained\nlevel of real GDP per capita. Thus, the economic trend term has an asymptotic\nvalue of zero. Inversion of the measured GDP values is used to recover the\ncorresponding change of the specific age population between 1955 and 2003. The\npopulation recovery method based on GDP potentially is of a higher accuracy\nthan routine censuses.\n",
        "query": "GDP growth and inflation rate",
        "docId": 93477,
        "score": 15.38623046875
    },
    {
        "title": "Why is GDP growth linear?",
        "paperAbstract": "  In many European countries the growth of the real GDP per capita has been\nlinear since 1950. An explanation for this linearity is still missing. We\npropose that in artificial intelligence we may find models for a linear growth\nof performance. We also discuss possible consequences of the fact that in\nsystems with linear growth the percentage growth goes to zero.\n",
        "query": "GDP growth and inflation rate",
        "docId": 650902,
        "score": 12.177835464477539
    },
    {
        "title": "Violation of Invariance of Measurement for GDP Growth Rate and its\n  Consequences",
        "paperAbstract": "  The aim here is to address the origins of sustainability for the real growth\nrate in the United States. For over a century of observations on the real GDP\nper capita of the United States a sustainable two percent growth rate has been\nobserved. To find an explanation for this observation I consider the impact of\nutility preferences and the effect of mobility of labor \\\u0026 capital on every\nprovided measurement. Mobility of labor results in heterogenous rates of\nincrease in prices which is called Baumol\u0027s cost disease phenomenon.\nHeterogeneous rates of inflation then make it impossible to define an invariant\nmeasure for the real growth rate. Paradoxical and ambiguous results already\nhave been observed when different measurements provided by the World Bank have\nbeen compared with the ones from the systems of national accounts (SNA). Such\nambiguity is currently being discussed in economy. I define a toy model for\ncaring out measurements in order to state that this ambiguity can be very\nsignificant. I provide examples in which GDP expands 5 folds while measurements\npercept an expansion around 2 folds. Violation of invariance of the\nmeasurements leads to state that it is hard to compare the growth rate of GDP\nfor a smooth growing country such as the U.S. with a fast growing country such\nas China. Besides, I state that to extrapolate the time that economy of China\npasses the economy of the US we need to consider local metric of the central\nbanks of both countries. Finally I conclude that it is our method of\nmeasurements that leads us to percept the sustainable growth rate.\n",
        "query": "GDP growth and inflation rate",
        "docId": 642509,
        "score": 11.97974681854248
    },
    {
        "title": "The role of the \"Maximizing Output Growth Inflation Rate\" in monetary\n  policy",
        "paperAbstract": "  The paper discusses the role of monetary policy when potential output depends\non the inflation rate. If the intention of the central bank is to maximize\nactual output growth, then it has to be credibly committed to a strict\ninflation targeting rule, and to take the MOGIR (the Maximizing Output Growth\nInflation Rate) as the target.\n",
        "query": "GDP growth and inflation rate",
        "docId": 511011,
        "score": 11.023119926452637
    },
    {
        "title": "Secular bipolar growth rate of the real US GDP per capita: implications\n  for understanding past and future economic growth",
        "paperAbstract": "  We present a quantitative characterisation of the fluctuations of the\nannualized growth rate of the real US GDP per capita growth at many scales,\nusing a wavelet transform analysis of two data sets, quarterly data from 1947\nto 2015 and annual data from 1800 to 2010. Our main finding is that the\ndistribution of GDP growth rates can be well approximated by a bimodal function\nassociated to a series of switches between regimes of strong growth rate\n$\\rho_\\text{high}$ and regimes of low growth rate $\\rho_\\text{low}$. The\nsuccession of such two regimes compounds to produce a remarkably stable long\nterm average real annualized growth rate of 1.6\\% from 1800 to 2010 and\n$\\approx 2.0\\%$ since 1950, which is the result of a subtle compensation\nbetween the high and low growth regimes that alternate continuously. Thus, the\noverall growth dynamics of the US economy is punctuated, with phases of strong\ngrowth that are intrinsically unsustainable, followed by corrections or\nconsolidation until the next boom starts. We interpret these findings within\nthe theory of \"social bubbles\" and argue as a consequence that estimations of\nthe cost of the 2008 crisis may be misleading. We also interpret the absence of\nstrong recovery since 2008 as a protracted low growth regime $\\rho_\\text{low}$\nassociated with the exceptional nature of the preceding large growth regime.\n",
        "query": "GDP growth and inflation rate",
        "docId": 751687,
        "score": 10.1079683303833
    },
    {
        "title": "Logistic forecasting of GDP competitiveness",
        "paperAbstract": "  The GDP growth of national economies is modelled by the logistic function.\nApplying it on the GDP data of the World Bank till the year 2020, we forecast\nthe outcome of the competitive GDP growth of Japan, Germany, UK and India, all\nof whose current GDPs are very close to one another. Fulfilling one of the\npredictions, in 2022 the GDP of India has indeed overtaken the GDP of UK. Our\noverall forecast is that by 2047, the GDP of India will be greater than that of\nthe other three countries. We argue that when trade saturates, large and\npopulous countries (like India) have the benefit of high domestic consumption\nto propel their GDP growth.\n",
        "query": "GDP growth and inflation rate",
        "docId": 1742031,
        "score": 9.817230224609375
    },
    {
        "title": "Does GDP measure growth in the economy or simply growth in the money\n  supply?",
        "paperAbstract": "  Gross Domestic Product(GDP) is a widely used measurement of economic growth\nrepresenting the market value of all final goods and services produced by a\ncountry within a given time. In this paper we question the assumption that GDP\nmeasures production, and suggest that in reality it merely captures changes in\nthe rate of expansion of the money supply used to measure the price data it is\nderived from. We first review the Quantity Theory of Money $MV\u003dPT$, and show\nthat the Velocity of Circulation of Money(V) does not affect the price level as\nclaimed, as it is also a factor of the quantity of transactions(T). It then\nfollows directly that attempts to measure total production from any form of\nprice data as the GDP measurement does, will necessarily be confounded by the\ninverse relationship between prices and the quantity of production, which\nrequires that as the total quantity of production increases, prices will drop.\nFinally, in support of this claim we present an empirical analysis of the GDP\nof nine countries and one currency union, showing that when normalized for\nmoney supply growth GDP measures have been uniformly shrinking over the last 20\nyears, and discuss the possible reasons for this behaviour.\n",
        "query": "GDP growth and inflation rate",
        "docId": 361214,
        "score": 9.807945251464844
    },
    {
        "title": "Unified Growth Theory Contradicted by the GDP/cap Data",
        "paperAbstract": "  Mathematical properties of the historical GDP/cap distributions are discussed\nand explained. These distributions are frequently incorrectly interpreted and\nthe Unified Growth Theory is an outstanding example of such common\nmisconceptions. It is shown here that the fundamental postulates of this theory\nare contradicted by the data used in its formulation. The postulated three\nregimes of growth did not exist and there was no takeoff at any time. It is\ndemonstrated that features interpreted as three regimes of growth represent\njust mathematical properties of a single, monotonically-increasing\ndistribution, indicating that a single mechanism should be used to explain the\nhistorical economic growth. It is shown that using different socio-economic\nconditions for different perceived parts of the historical GDP/cap data is\nirrelevant and scientifically unjustified. The GDP/cap growth was indeed\nincreasing slowly over a long time and fast over a short time but these\nfeatures represent a single, uniform and uninterrupted growth process, which\nshould be interpreted as whole using a single mechanism of growth.\n",
        "query": "GDP growth and inflation rate",
        "docId": 682503,
        "score": 9.781845092773438
    },
    {
        "title": "Transitional Dynamics of the Saving Rate and Economic Growth",
        "paperAbstract": "  We estimate the relationship between GDP per capita growth and the growth\nrate of the national savings rate using a panel of 130 countries over the\nperiod 1960-2017. We find that GDP per capita growth increases (decreases) the\ngrowth rate of the national savings rate in poor countries (rich countries),\nand a higher credit-to-GDP ratio decreases the national savings rate as well as\nthe income elasticity of the national savings rate. We develop a model with a\ncredit constraint to explain the growth-saving relationship by the saving\nbehavior of entrepreneurs at both the intensive and extensive margins. We\nfurther present supporting evidence for our theoretical findings by utilizing\ncross-country time series data of the number of new businesses registered and\nthe corporate savings rate.\n",
        "query": "GDP growth and inflation rate",
        "docId": 1403313,
        "score": 9.299318313598633
    },
    {
        "title": "Global dynamics of GDP and trade",
        "paperAbstract": "  We use the logistic equation to model the dynamics of the GDP and the trade\nof the six countries with the highest GDP in the world, namely, USA, China,\nJapan, Germany, UK and India. From the modelling of the economic data, which\nare made available by the World Bank, we predict the maximum values of the\ngrowth of GDP and trade, as well as the duration over which exponential growth\ncan be sustained. We set up the correlated growth of GDP and trade as the phase\nsolutions of an autonomous second-order dynamical system. GDP and trade are\nrelated to each other by a power law, whose exponent seems to differentiate the\nsix national economies into two types. Under conducive conditions for economic\ngrowth, our conclusions have general validity.\n",
        "query": "GDP growth and inflation rate",
        "docId": 1528083,
        "score": 9.245779037475586
    },
    {
        "title": "A Survey of Impedance Measurement Methods in Power Electronics",
        "paperAbstract": "  Impedance is one of the vital parameters that provides useful information for\nmany power electronics related applications. A lot of impedance measurement\nmethods in power electronics have been reported. However, a comprehensive\ninvestigation among these methods in terms of their characteristics,\nadvantages, and limitations has not been found in the literature. In order to\nbridge this gap, a survey of the impedance measurement methods is conducted in\nthis paper. These methods are introduced, discussed, and then classified into\ndifferent categories depending on the measurement modes, principles, and\ninstruments. Moreover, recommendations for the future research on the impedance\nmeasurement are also presented.\n",
        "query": "power electronics applications",
        "docId": 1636233,
        "score": 8.70867919921875
    },
    {
        "title": "An open-source simulation package for power electronics education",
        "paperAbstract": "  Extension of the open-source simulation package GSEIM for power electronics\napplications is presented. Recent developments in GSEIM, including those\noriented specifically towards power electronic circuits, are described. Some\nexamples of electrical element templates, which form a part of the GSEIM\nlibrary, are discussed. Representative simulation examples in power electronics\nare presented to bring out important features of the simulator. Advantages of\nGSEIM for educational purposes are discussed. Finally, plans regarding future\ndevelopments in GSEIM are presented.\n",
        "query": "power electronics applications",
        "docId": 1643062,
        "score": 8.50107479095459
    },
    {
        "title": "Reconfigurable Power Electronics Topologies",
        "paperAbstract": "  This paper presents two novel topologies for automatically transforming power\nconverter topology from three-phase 3-level cascaded H-bridge to three-phase\n2-level converter design. These techniques are implemented by flicking specific\nswitches to rearrange circuit connections. The switches can be controlled by\nsignals in order to realize automation.\n",
        "query": "power electronics applications",
        "docId": 905625,
        "score": 8.238499641418457
    },
    {
        "title": "Fungal electronics",
        "paperAbstract": "  Fungal electronics is a family of living electronic devices made of mycelium\nbound composites or pure mycelium. Fungal electronic devices are capable of\nchanging their impedance and generating spikes of electrical potential in\nresponse to external control parameters. Fungal electronics can be embedded\ninto fungal materials and wearables or used as stand alone sensing and\ncomputing devices.\n",
        "query": "power electronics applications",
        "docId": 1565334,
        "score": 8.171867370605469
    },
    {
        "title": "RF Electronics",
        "paperAbstract": "  For many decades High Energy Physics (HEP) instrumentation has been\nconcentrated on detectors of ionizing radiation -- where the energy of incident\nparticles or photons is sufficient to create mobile charge in gas, liquid, or\nsolid material, which can be processed by front end electronics (FEE) to\nprovide information about the position, energy, and timing of the incident\nradiation. However, recently-proposed HEP experiments need to sense or control\nEM radiation in the radiofrequency (RF) range, where ionization detectors are\nunavailable. These experiments can take advantage of emerging microelectronics\ndevelopments fostered by the explosive growth of wireless data communications\nin the commercial sector.\n  Moore\u0027s Law advances in semiconductor technology have brought about the\nrecent development of advanced microelectronic components with groundbreaking\nlevels of analog-digital integration and processing speed. In particular, RF\n\"System-on-Chip\" (RFSoC) platforms offer multiple data converter interfaces to\nthe analog world (ADCs and DACs) having bandwidths approaching 10GHz and\nabundant digital signal processing resources on the same silicon die. Such\ndevices eliminate the complex PC board interfaces that have long been used to\ncouple discrete ADCs and DACs to FPGA processors, thus radically reducing power\nconsumption, impedance mismatch, and footprint area, while allowing analog\npreconditioning circuits to be eliminated in favor of digital processing.\nCosted for wide deployment, these devices are helping to accelerate the trend\ntowards \"software defined radio\" in several high-volume commercial markets. In\nthis whitepaper we highlight some HEP applications where leading-edge RF\nmicroelectronics can be a key enabler.\n",
        "query": "power electronics applications",
        "docId": 1631947,
        "score": 7.655843257904053
    },
    {
        "title": "Nanomodular Electronics",
        "paperAbstract": "  It may be possible to reinvent how microelectronics are made using a two step\nprocess: (1) Synthesizing modular, nanometer-scale components -- transistors,\nsensors, and other devices -- and suspending them in a liquid \"ink\" for storage\nor transport; (2) Using a 3D-printer-like machine to create circuits by placing\nand wiring the components. Developments in nanotechnology, colloidal chemistry,\nprecision additive manufacturing, and computer vision suggest this new process\nis possible. Herein, we describe a roadmap to these nanomodular electronics,\nwhich could enable a \"fab in a box\" and make fabricating microelectronics as\nstraightforward as printing this document.\n",
        "query": "power electronics applications",
        "docId": 1810846,
        "score": 7.453268527984619
    },
    {
        "title": "Review for AI-based Open-Circuit Faults Diagnosis Methods in Power\n  Electronics Converters",
        "paperAbstract": "  Power electronics converters have been widely used in aerospace system, DC\ntransmission, distributed energy, smart grid and so forth, and the reliability\nof power electronics converters has been a hotspot in academia and industry. It\nis of great significance to carry out power electronics converters open-circuit\nfaults monitoring and intelligent fault diagnosis to avoid secondary faults,\nreduce time and cost of operation and maintenance, and improve the reliability\nof power electronics system. Firstly, the faults features of power electronic\nconverters are analyzed and summarized. Secondly, some AI-based fault diagnosis\nmethods and application examples in power electronics converters are reviewed,\nand a fault diagnosis method based on the combination of random forests and\ntransient fault features is proposed for three-phase power electronics\nconverters. Finally, the future research challenges and directions of AI-based\nfault diagnosis methods are pointed out.\n",
        "query": "power electronics applications",
        "docId": 1719773,
        "score": 7.416646957397461
    },
    {
        "title": "Towards the Solution of Power Dissipation in Electronics Systems through\n  Thermodynamics",
        "paperAbstract": "  Power loss in the electronic system is a very crucial limiting factor that\ncan be reduced or minimized with the help of using the reversible logics \"a\nconcept came from Thermodynamics\". In this paper the authors shows the concept\nof reversible logics for the Electronics system. The logical and physical\ndesigning approach is given in the paper in detail. The contradiction of\nlogical and physical reversibility with the conventional CMOS designing is also\nshows and the solution of that contradiction is also proposed by the authors\nusing adiabatic logic. This Paper gives a complete and clear idea if the\nthermodynamical concept for the electronics industries for power reduction.\n",
        "query": "power electronics applications",
        "docId": 337788,
        "score": 7.3896589279174805
    },
    {
        "title": "Intrinsically shunted Josephson junctions for electronics applications",
        "paperAbstract": "  Conventional Josephson metal-insulator-metal devices are inherently\nunderdamped and exhibit hysteretic current-voltage response due to a very high\nsubgap resistance compared to that in the normal state. At the same time,\noverdamped junctions with single-valued characteristics are needed for most\nsuperconducting digital applications. The usual way to overcome the hysteretic\nbehavior is to place an external low-resistance normal-metal shunt in parallel\nwith each junction. Unfortunately, such solution results in a considerable\ncomplication of the circuitry design and introduces parasitic inductance\nthrough the junction. This paper provides a concise overview of some generic\napproaches that have been proposed in order to realize internal shunting in\nJosephson heterostructures with a barrier that itself contains the desired\nresistive component. The main attention is paid to self-shunted devices with\nlocal weak-link transmission probabilities so strongly disordered in the\ninterface plane that transmission probabilities are tiny for the main part of\nthe transition region between two superconducting electrodes, while a small\npart of the interface is well transparent. We consider the possibility of\nrealizing a universal bimodal distribution function and emphasize advantages of\nsuch junctions that can be considered as a new class of self-shunted Josephson\ndevices promising for practical applications in superconducting electronics\noperating at 4.2 K.\n",
        "query": "power electronics applications",
        "docId": 898090,
        "score": 7.2047624588012695
    },
    {
        "title": "Review of Thermal Properties of Graphene and Few-Layer Graphene:\n  Applications in Electronics",
        "paperAbstract": "  We review thermal properties of graphene and few-layer graphene, and discuss\napplications of these materials in thermal management of advanced electronics.\nThe intrinsic thermal conductivity of graphene - among the highest of known\nmaterials - is dominated by phonons near the room temperature. The examples of\nthermal management applications include the few-layer graphene heat spreaders\nintegrated near the heat generating areas of the high-power density\ntransistors. It has been demonstrated that few-layer graphene heat spreaders\ncan lower the hot-spot temperature during device operation resulting in\nimproved performance and reliability of the devices.\n",
        "query": "power electronics applications",
        "docId": 604539,
        "score": 6.992620468139648
    },
    {
        "title": "Ramsey Optimal Policy versus Multiple Equilibria with Fiscal and\n  Monetary Interactions",
        "paperAbstract": "  We consider a frictionless constant endowment economy based on Leeper (1991).\nIn this economy, it is shown that, under an ad-hoc monetary rule and an ad-hoc\nfiscal rule, there are two equilibria. One has active monetary policy and\npassive fiscal policy, while the other has passive monetary policy and active\nfiscal policy. We consider an extended setup in which the policy maker\nminimizes a loss function under quasi-commitment, as in Schaumburg and\nTambalotti (2007). Under this formulation there exists a unique Ramsey\nequilibrium, with an interest rate peg and a passive fiscal policy. We thank\nJohn P. Conley, Luis de Araujo and one referree for their very helpful\ncomments.\n",
        "query": "what is fiscal policy",
        "docId": 1241931,
        "score": 10.684184074401855
    },
    {
        "title": "A note on the policy implications of the fiscal multiplier",
        "paperAbstract": "  We present an elementary analysis of the dynamical aspects of the GDP /\ngovernment surplus multiplier with relevance to the assessment of a country\u0027s\ndebt repayment policy. We show the (at first) counter intuitive result that in\norder to reduce the Debt/GDP ratio, countries with high Debt to GDP should go\ninto further debt, as long as the Debt to GDP ratio is roughly greater than the\ninverse of the multiplier. Thus small values of the multiplier make further\ndebt undesirable, and conversely.\n",
        "query": "what is fiscal policy",
        "docId": 468086,
        "score": 9.772027969360352
    },
    {
        "title": "The fiscal response to revenue shocks",
        "paperAbstract": "  We study the impact of fiscal revenue shocks on local fiscal policy. We focus\non the very volatile revenues from the immovable property gains tax in the\ncanton of Zurich, Switzerland, and analyze fiscal behavior following large and\nrare positive and negative revenue shocks. We apply causal machine learning\nstrategies and implement the post-double-selection LASSO estimator to identify\nthe causal effect of revenue shocks on public finances. We show that local\npolicymakers overall predominantly smooth fiscal shocks. However, we also find\nsome patterns consistent with fiscal conservatism, where positive shocks are\nsmoothed, while negative ones are mitigated by spending cuts.\n",
        "query": "what is fiscal policy",
        "docId": 1411403,
        "score": 9.672389030456543
    },
    {
        "title": "Fiscal policy and inequality in a model with endogenous positional\n  concerns",
        "paperAbstract": "  We investigate the dynamics of wealth inequality in an economy where\nhouseholds have positional preferences, with the strength of the positional\nconcern determined endogenously by inequality of wealth distribution in the\nsociety. We demonstrate that in the long run such an economy converges to a\nunique egalitarian steady-state equilibrium, with all households holding equal\npositive wealth, when the initial inequality is sufficiently low. Otherwise,\nthe steady state is characterised by polarisation of households into rich, who\nown all the wealth, and poor, whose wealth is zero. A fiscal policy with\ngovernment consumption funded by taxes on labour income and wealth can move the\neconomy from any initial state towards an egalitarian equilibrium with a higher\naggregate wealth.\n",
        "query": "what is fiscal policy",
        "docId": 1494422,
        "score": 9.481888771057129
    },
    {
        "title": "Estimating the Effects of Fiscal Policy using a Novel Proxy Shrinkage\n  Prior",
        "paperAbstract": "  Different proxy variables commonly used in fiscal policy SVARs lead to\ncontradicting conclusions implying that some of the exogeneity assumptions may\nnot be fulfilled. We combine data-driven identification with a novel proxy\nshrinkage prior which enables us to estimate the effects of fiscal policy\nshocks without relying on strong assumptions about the validity of the proxy\nvariables. Our results suggest that increasing government spending is a more\neffective tool to stimulate the economy than reducing taxes. Additionally, we\nprovide evidence that the commonly used proxies in the literature are\nendogenously related to the structural shocks which leads to biased estimates.\nWe construct new exogenous proxies that can be used in the traditional proxy\nVAR approach resulting in similar estimates compared to our proxy shrinkage\nmodel.\n",
        "query": "what is fiscal policy",
        "docId": 1798000,
        "score": 9.184704780578613
    },
    {
        "title": "Preliminary steps toward a universal economic dynamics for monetary and\n  fiscal policy",
        "paperAbstract": "  We consider the relationship between economic activity and intervention,\nincluding monetary and fiscal policy, using a universal dynamic framework.\nCentral bank policies are designed for growth without excess inflation.\nHowever, unemployment, investment, consumption, and inflation are interlinked.\nUnderstanding dynamics is crucial to assessing the effects of policy,\nespecially in the aftermath of the financial crisis. Here we lay out a program\nof research into monetary and economic dynamics and preliminary steps toward\nits execution. We use principles of response theory to derive implications for\npolicy. We find that the current approach, which considers the overall money\nsupply, is insufficient to regulate economic growth. While it can achieve some\ndegree of control, optimizing growth also requires a fiscal policy balancing\nmonetary injection between two dominant loop flows, the consumption and wages\nloop, and investment and returns loop. The balance arises from a composite of\ngovernment tax, entitlement, subsidy policies, corporate policies, as well as\nmonetary policy. We show empirically that a transition occurred in 1980 between\ntwo regimes--an oversupply to the consumption and wages loop, to an oversupply\nof the investment and returns loop. The imbalance is manifest in savings and\nborrowing by consumers and investors, and in inflation. The latter increased\nuntil 1980, and decreased subsequently, resulting in a zero rate largely\nunrelated to the financial crisis. Three recessions and the financial crisis\nare part of this dynamic. Optimizing growth now requires shifting the balance.\nOur analysis supports advocates of greater income and / or government support\nfor the poor who use a larger fraction of income for consumption. This promotes\ninvestment due to growth in demand. Otherwise, investment opportunities are\nlimited, capital remains uninvested, and does not contribute to growth.\n",
        "query": "what is fiscal policy",
        "docId": 901668,
        "score": 8.764744758605957
    },
    {
        "title": "Fiscal Stimulus of Last Resort",
        "paperAbstract": "  I examine global dynamics in a monetary model with overlapping generations of\nfinite-horizon agents and a binding lower bound on nominal interest rates. Debt\ntargeting rules exacerbate the possibility of self-fulfilling liquidity traps,\nfor agents expect austerity following deflationary slumps. Conversely, activist\nbut sustainable fiscal policy regimes - implementing intertemporally balanced\ntax cuts and/or transfer increases in response to disinflationary trajectories\n- are capable of escaping liquidity traps and embarking inflation into a\nglobally stable path that converges to the target. Should fiscal stimulus of\nlast resort be overly aggressive, however, spiral dynamics around the\nliquidity-trap steady state exist, causing global indeterminacy.\n",
        "query": "what is fiscal policy",
        "docId": 1450171,
        "score": 8.655365943908691
    },
    {
        "title": "Fiscal shocks and asymmetric effects: a comparative analysis",
        "paperAbstract": "  We empirically test the effects of unanticipated fiscal policy shocks on the\ngrowth rate and the cyclical component of real private output and reveal\ndifferent types of asymmetries in fiscal policy implementation. The data used\nare quarterly U.S. observati ons over the period 1967:1 to 2011:4. In doing so,\nwe use both a vector autoregressive and the novel support vector machines\nsystems in order to extract the fiscal policy shocks series. The latter has\nnever been used before in a similar macroeconomic setting. Within our research\nframework, in order to test the robustness of our results to alternative\naggregate money supply definitions we use two alternative moentary aggregates.\nThese are the commonly reported by central banks and policy makers simple sum\nmonetary aggregates at the MZM level of aggregation and the alternative CFS\nDivisia MZM aggregate. From each of these four systems we extracted four types\nof shocks: a negative and a positive government spending shock and a negative\nand a positive government revenue shock. These eight different types of\nunanticipated fiscal policy shocks are next used to empirically examine their\neffects on the growth rate and the cyclical component of real private GNP in\ntwo sets of regressions: one that assumes only contemporaneous effects of the\nshocks on output and one that is augmented with four lags of each fiscal shock.\n",
        "query": "what is fiscal policy",
        "docId": 484046,
        "score": 8.103179931640625
    },
    {
        "title": "Monetary-fiscal interactions under price level targeting",
        "paperAbstract": "  The adoption of a \"makeup\" strategy is one of the proposals in the ongoing\nreview of the Fed\u0027s monetary policy framework. Another suggestion, to avoid the\nzero lower bound, is a more active role for fiscal policy. We put together\nthese ideas to study monetary-fiscal interactions under price level targeting.\nUnder price level targeting and a fiscally-led regime, we find that following a\ndeflationary demand shock: (i) the central bank increases (rather than\ndecreases) the policy rate; (ii) the central bank, thus, avoids the zero lower\nbound; (iii) price level targeting is generally welfare improving if compared\nto inflation targeting.\n",
        "query": "what is fiscal policy",
        "docId": 1371309,
        "score": 7.698496341705322
    },
    {
        "title": "Balancing Fiscal and Mortality Impact of SARS-CoV-2 Mitigation\n  Measurements",
        "paperAbstract": "  An epidemic carries human and fiscal costs. In the case of imported\npandemics, the first-best solution is to restrict national borders to identify\nand isolate infected individuals. However, when that opportunity is not fully\nseized and there is no preventative intervention available, second-best options\nmust be chosen. In this article we develop a system of differential equations\nthat simulate both the fiscal and human costs associated to different\nmitigation measurements. After simulating several scenarios, we conclude that\nherd immunity (or unleashing the pandemic) is the worst policy in terms of both\nhuman and fiscal cost. We found that the second-best policy would be a strict\npolicy (e.g. physical distancing with massive testing) established under the\nfirst 20 days after the pandemic, that lowers the probability of infection by\n80%. In the case of the US, this strict policy would save more than 239\nthousands lives and almost $170.8 billion to taxpayers when compared to the\nherd immunity case.\n",
        "query": "what is fiscal policy",
        "docId": 1295877,
        "score": 7.129295825958252
    },
    {
        "title": "Deep Learning for Audio Signal Processing",
        "paperAbstract": "  Given the recent surge in developments of deep learning, this article\nprovides a review of the state-of-the-art deep learning techniques for audio\nsignal processing. Speech, music, and environmental sound processing are\nconsidered side-by-side, in order to point out similarities and differences\nbetween the domains, highlighting general methods, problems, key references,\nand potential for cross-fertilization between areas. The dominant feature\nrepresentations (in particular, log-mel spectra and raw waveform) and deep\nlearning models are reviewed, including convolutional neural networks, variants\nof the long short-term memory architecture, as well as more audio-specific\nneural network models. Subsequently, prominent deep learning application areas\nare covered, i.e. audio recognition (automatic speech recognition, music\ninformation retrieval, environmental sound detection, localization and\ntracking) and synthesis and transformation (source separation, audio\nenhancement, generative models for speech, sound, and music synthesis).\nFinally, key issues and future questions regarding deep learning applied to\naudio signal processing are identified.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 1118514,
        "score": 14.531946182250977
    },
    {
        "title": "An Overview on Audio, Signal, Speech, \u0026 Language Processing for COVID-19",
        "paperAbstract": "  Recently, there has been an increased attention towards innovating,\nenhancing, building, and deploying applications of speech signal processing for\nproviding assistance and relief to human mankind from the Coronavirus\n(COVID-19) pandemic. Many AI with speech initiatives are taken to combat with\nthe present situation and also to create a safe and secure environment for the\nfuture. This paper summarises all these efforts taken by the re-search\ncommunity towards helping the individuals and the society in the fight against\nCOVID-19 over the past 3-4 months using speech signal processing. We also\nsummarise the deep techniques used in this direction to come up with capable\nsolutions in a short span of time. This paper further gives an overview of the\ncontributions from non-speech modalities that may complement or serve as\ninspiration for audio and speech analysis. In addition, we discuss our\nobservations with respect to solution usability, challenges, and the\nsignificant technology achievements.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 1288374,
        "score": 13.668664932250977
    },
    {
        "title": "SpeechPy - A Library for Speech Processing and Recognition",
        "paperAbstract": "  SpeechPy is an open source Python package that contains speech preprocessing\ntechniques, speech features, and important post-processing operations. It\nprovides most frequent used speech features including MFCCs and filterbank\nenergies alongside with the log-energy of filter-banks. The aim of the package\nis to provide researchers with a simple tool for speech feature extraction and\nprocessing purposes in applications such as Automatic Speech Recognition and\nSpeaker Verification.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 951227,
        "score": 13.039945602416992
    },
    {
        "title": "Deep Audio-Visual Speech Recognition",
        "paperAbstract": "  The goal of this work is to recognise phrases and sentences being spoken by a\ntalking face, with or without the audio. Unlike previous works that have\nfocussed on recognising a limited number of words or phrases, we tackle lip\nreading as an open-world problem - unconstrained natural language sentences,\nand in the wild videos. Our key contributions are: (1) we compare two models\nfor lip reading, one using a CTC loss, and the other using a\nsequence-to-sequence loss. Both models are built on top of the transformer\nself-attention architecture; (2) we investigate to what extent lip reading is\ncomplementary to audio speech recognition, especially when the audio signal is\nnoisy; (3) we introduce and publicly release a new dataset for audio-visual\nspeech recognition, LRS2-BBC, consisting of thousands of natural sentences from\nBritish television. The models that we train surpass the performance of all\nprevious work on a lip reading benchmark dataset by a significant margin.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 1022124,
        "score": 13.034608840942383
    },
    {
        "title": "Joint Speech Recognition and Audio Captioning",
        "paperAbstract": "  Speech samples recorded in both indoor and outdoor environments are often\ncontaminated with secondary audio sources. Most end-to-end monaural speech\nrecognition systems either remove these background sounds using speech\nenhancement or train noise-robust models. For better model interpretability and\nholistic understanding, we aim to bring together the growing field of automated\naudio captioning (AAC) and the thoroughly studied automatic speech recognition\n(ASR). The goal of AAC is to generate natural language descriptions of contents\nin audio samples. We propose several approaches for end-to-end joint modeling\nof ASR and AAC tasks and demonstrate their advantages over traditional\napproaches, which model these tasks independently. A major hurdle in evaluating\nour proposed approach is the lack of labeled audio datasets with both speech\ntranscriptions and audio captions. Therefore we also create a multi-task\ndataset by mixing the clean speech Wall Street Journal corpus with multiple\nlevels of background noises chosen from the AudioCaps dataset. We also perform\nextensive experimental evaluation and show improvements of our proposed methods\nas compared to existing state-of-the-art ASR and AAC methods.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 1600229,
        "score": 13.017134666442871
    },
    {
        "title": "Audio, Speech, Language, \u0026 Signal Processing for COVID-19: A\n  Comprehensive Overview",
        "paperAbstract": "  The Coronavirus (COVID-19) pandemic has been the research focus world-wide in\nthe year 2020. Several efforts, from collection of COVID-19 patients\u0027 data to\nscreening them for the virus\u0027s detection are taken with rigour. A major portion\nof COVID-19 symptoms are related to the functioning of the respiratory system,\nwhich in-turn critically influences the human speech production system. This\ndrives the research focus towards identifying the markers of COVID-19 in speech\nand other human generated audio signals. In this paper, we give an overview of\nthe speech and other audio signal, language and general signal processing-based\nwork done using Artificial Intelligence techniques to screen, diagnose,\nmonitor, and spread the awareness aboutCOVID-19. We also briefly describe the\nresearch related to detect accord-ing COVID-19 symptoms carried out so far. We\naspire that this collective information will be useful in developing automated\nsystems, which can help in the context of COVID-19 using non-obtrusive and easy\nto use modalities such as audio, speech, and language.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 1387193,
        "score": 12.991975784301758
    },
    {
        "title": "Multimodal Speech Recognition with Unstructured Audio Masking",
        "paperAbstract": "  Visual context has been shown to be useful for automatic speech recognition\n(ASR) systems when the speech signal is noisy or corrupted. Previous work,\nhowever, has only demonstrated the utility of visual context in an unrealistic\nsetting, where a fixed set of words are systematically masked in the audio. In\nthis paper, we simulate a more realistic masking scenario during model\ntraining, called RandWordMask, where the masking can occur for any word\nsegment. Our experiments on the Flickr 8K Audio Captions Corpus show that\nmultimodal ASR can generalize to recover different types of masked words in\nthis unstructured masking setting. Moreover, our analysis shows that our models\nare capable of attending to the visual signal when the audio signal is\ncorrupted. These results show that multimodal ASR systems can leverage the\nvisual signal in more generalized noisy scenarios.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 1364972,
        "score": 12.373600959777832
    },
    {
        "title": "The Multimodal Information based Speech Processing (MISP) 2022\n  Challenge: Audio-Visual Diarization and Recognition",
        "paperAbstract": "  The Multi-modal Information based Speech Processing (MISP) challenge aims to\nextend the application of signal processing technology in specific scenarios by\npromoting the research into wake-up words, speaker diarization, speech\nrecognition, and other technologies. The MISP2022 challenge has two tracks: 1)\naudio-visual speaker diarization (AVSD), aiming to solve ``who spoken when\u0027\u0027\nusing both audio and visual data; 2) a novel audio-visual diarization and\nrecognition (AVDR) task that focuses on addressing ``who spoken what when\u0027\u0027\nwith audio-visual speaker diarization results. Both tracks focus on the Chinese\nlanguage, and use far-field audio and video in real home-tv scenarios: 2-6\npeople communicating each other with TV noise in the background. This paper\nintroduces the dataset, track settings, and baselines of the MISP2022\nchallenge. Our analyses of experiments and examples indicate the good\nperformance of AVDR baseline system, and the potential difficulties in this\nchallenge due to, e.g., the far-field video quality, the presence of TV noise\nin the background, and the indistinguishable speakers.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 1806123,
        "score": 12.200799942016602
    },
    {
        "title": "Speech Recognition with no speech or with noisy speech",
        "paperAbstract": "  The performance of automatic speech recognition systems(ASR) degrades in the\npresence of noisy speech. This paper demonstrates that using\nelectroencephalography (EEG) can help automatic speech recognition systems\novercome performance loss in the presence of noise. The paper also shows that\ndistillation training of automatic speech recognition systems using EEG\nfeatures will increase their performance. Finally, we demonstrate the ability\nto recognize words from EEG with no speech signal on a limited English\nvocabulary with high accuracy.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 1093125,
        "score": 12.11676025390625
    },
    {
        "title": "Visual Speech Recognition",
        "paperAbstract": "  Lip reading is used to understand or interpret speech without hearing it, a\ntechnique especially mastered by people with hearing difficulties. The ability\nto lip read enables a person with a hearing impairment to communicate with\nothers and to engage in social activities, which otherwise would be difficult.\nRecent advances in the fields of computer vision, pattern recognition, and\nsignal processing has led to a growing interest in automating this challenging\ntask of lip reading. Indeed, automating the human ability to lip read, a\nprocess referred to as visual speech recognition (VSR) (or sometimes speech\nreading), could open the door for other novel related applications. VSR has\nreceived a great deal of attention in the last decade for its potential use in\napplications such as human-computer interaction (HCI), audio-visual speech\nrecognition (AVSR), speaker recognition, talking heads, sign language\nrecognition and video surveillance. Its main aim is to recognise spoken word(s)\nby using only the visual signal that is produced during speech. Hence, VSR\ndeals with the visual domain of speech and involves image processing,\nartificial intelligence, object detection, pattern recognition, statistical\nmodelling, etc.\n",
        "query": "speech recognition and audio signal processing",
        "docId": 553836,
        "score": 12.06761646270752
    },
    {
        "title": "The Chills and Thrills of Whole Genome Sequencing",
        "paperAbstract": "  In recent years, Whole Genome Sequencing (WGS) evolved from a\nfuturistic-sounding research project to an increasingly affordable technology\nfor determining complete genome sequences of complex organisms, including\nhumans. This prompts a wide range of revolutionary applications, as WGS\npromises to improve modern healthcare and provide a better understanding of the\nhuman genome -- in particular, its relation to diseases and response to\ntreatments. However, this progress raises worrisome privacy and ethical issues,\nsince, besides uniquely identifying its owner, the genome contains a treasure\ntrove of highly personal and sensitive information. In this article, after\nsummarizing recent advances in genomics, we discuss some important privacy\nissues associated with human genomic information and identify a number of\nparticularly relevant research challenges.\n",
        "query": "genome sequencing of covid-19",
        "docId": 436048,
        "score": 11.04826545715332
    },
    {
        "title": "Benchmarking Machine Learning Robustness in Covid-19 Genome Sequence\n  Classification",
        "paperAbstract": "  The rapid spread of the COVID-19 pandemic has resulted in an unprecedented\namount of sequence data of the SARS-CoV-2 genome -- millions of sequences and\ncounting. This amount of data, while being orders of magnitude beyond the\ncapacity of traditional approaches to understanding the diversity, dynamics,\nand evolution of viruses is nonetheless a rich resource for machine learning\n(ML) approaches as alternatives for extracting such important information from\nthese data. It is of hence utmost importance to design a framework for testing\nand benchmarking the robustness of these ML models.\n  This paper makes the first effort (to our knowledge) to benchmark the\nrobustness of ML models by simulating biological sequences with errors. In this\npaper, we introduce several ways to perturb SARS-CoV-2 genome sequences to\nmimic the error profiles of common sequencing platforms such as Illumina and\nPacBio. We show from experiments on a wide array of ML models that some\nsimulation-based approaches are more robust (and accurate) than others for\nspecific embedding methods to certain adversarial attacks to the input\nsequences. Our benchmarking framework may assist researchers in properly\nassessing different ML models and help them understand the behavior of the\nSARS-CoV-2 virus or avoid possible future pandemics.\n",
        "query": "genome sequencing of covid-19",
        "docId": 1684796,
        "score": 10.649553298950195
    },
    {
        "title": "COVID-19 Evolves in Human Hosts",
        "paperAbstract": "  Today, we are all threatened by an unprecedented pandemic: COVID-19. How\ndifferent is it from other coronaviruses? Will it be attenuated or become more\nvirulent? Which animals may be its original host? In this study, we collected\nand analyzed nearly thirty thousand publicly available complete genome\nsequences for COVID-19 virus from 79 different countries, the previously known\nflu-causing coronaviruses (HCov-229E, HCov-OC43, HCov-NL63 and HCov-HKU1) and\nthe lethal, pathogenic viruses, SARS, MERS, Victoria, Lassa, Yamagata, Ebola,\nand Dengue. We found strong similarities between the current circulating\nCOVID-19 and SARS and MERS, as well as COVID-19 in rhinolophines and pangolins.\nOn the contrary, COVID-19 shares little similarity with the flu-causing\ncoronaviruses and the other known viruses. Strikingly, we observed that the\ndivergence of COVID-19 strains isolated from human hosts has steadily increased\nfrom December 2019 to May 2020, suggesting COVID-19 is actively evolving in\nhuman hosts. In this paper, we first propose a novel MLCS algorithm NP-MLCS1\nfor the big sequence analysis, which can calculate the common model for\nCOVID-19 complete genome sequences to provide important information for vaccine\nand antibody development. Geographic and time-course analysis of the evolution\ntrees of the human COVID-19 reveals possible evolutional paths among strains\nfrom 79 countries. This finding has important implications to the management of\nCOVID-19 and the development of vaccines and medications.\n",
        "query": "genome sequencing of covid-19",
        "docId": 1255935,
        "score": 10.449219703674316
    },
    {
        "title": "A Summary of COVID-19 Datasets",
        "paperAbstract": "  This research presents a review of main datasets that are developed for\nCOVID-19 research. We hope this collection will continue to bring together\nmembers of the computing community, biomedical experts, and policymakers in the\npursuit of effective COVID-19 treatments and management policies. Many\norganizations, such as the World Health Organization (WHO), John Hopkins,\nNational Institute of Health (NIH), COVID-19 open science table4 and such, in\nthe world, have made numerous datasets available to the public. However, these\ndatasets originate from a variety of different sources and initiatives. The\npurpose of this research is to summarize the open COVID-19 datasets to make\nthem more accessible to the research community for health systems design and\nanalysis.\n",
        "query": "genome sequencing of covid-19",
        "docId": 1601648,
        "score": 10.191751480102539
    },
    {
        "title": "Innovation in times of Covid-19",
        "paperAbstract": "  Did the Covid-19 pandemic have an impact on innovation? Past economic\ndisruptions, anecdotal evidence, and the previous literature suggest a decline\nwith substantial differences between industries. We leverage USPTO patent\napplication data to investigate and quantify the disturbance. We assess\ndifferences by field of technology (at the CPC subclass level) as well as the\nimpact of direct and indirect relevance for the management of the pandemic.\nDirect Covid-19 relevance is identified from a keyword search of the patent\napplication fulltexts; indirect Covid-19 relevance is derived from past CPC\nsubclass to subclass citation patterns. We find that direct Covid-19 relevance\nis associated with a strong boost to the growth of the number of patent\napplications in the first year of the pandemic at the same order of magnitude\n(in percentage points) as the percentage of patents referencing Covid-19. We\nfind no effect for indirect Covid-19 relevance, indicating a focus on applied\nresearch at the expense of more basic research. Fields of technology (CPC\nmainsections) have an additional significant impact, with, e.g., mainsections A\n(human necessities) and C (chemistry, metallurgy) having a strong performance.\n",
        "query": "genome sequencing of covid-19",
        "docId": 1770336,
        "score": 10.11745548248291
    },
    {
        "title": "Nanopore Sequencing of the phi X 174 genome",
        "paperAbstract": "  Nanopore sequencing of DNA is a single-molecule technique that may achieve\nlong reads, low cost, and high speed with minimal sample preparation and\ninstrumentation. Here, we build on recent progress with respect to nanopore\nresolution and DNA control to interpret the procession of ion current levels\nobserved during the translocation of DNA through the pore MspA. As\napproximately four nucleotides affect the ion current of each level, we\nmeasured the ion current corresponding to all 256 four-nucleotide combinations\n(quadromers). This quadromer map is highly predictive of ion current levels of\npreviously unmeasured sequences derived from the bacteriophage phi X 174\ngenome. Furthermore, we show nanopore sequencing reads of phi X 174 up to 4,500\nbases in length that can be unambiguously aligned to the phi X 174 reference\ngenome, and demonstrate proof-of-concept utility with respect to hybrid genome\nassembly and polymorphism detection. All methods and data are made fully\navailable.\n",
        "query": "genome sequencing of covid-19",
        "docId": 533097,
        "score": 10.08987045288086
    },
    {
        "title": "On COVID-19 Modelling",
        "paperAbstract": "  This contribution analyzes the COVID-19 outbreak by comparably simple\nmathematical and numerical methods. The final goal is to predict the peak of\nthe epidemic outbreak per country with a reliable technique. This is done by an\nalgorithm motivated by standard SIR models and aligned with the standard data\nprovided by the Johns Hopkins University. To reconstruct data for the\nunregistered Infected, the algorithm uses current values of the infection\nfatality rate and a data-driven estimation of a specific form of the recovery\nrate. All other ingredients are data-driven as well. Various examples of\npredictions are provided for illustration.\n",
        "query": "genome sequencing of covid-19",
        "docId": 1286799,
        "score": 10.031463623046875
    },
    {
        "title": "Translational Knowledge Map of COVID-19",
        "paperAbstract": "  A translational knowledge map of COVID-19, based on the analysis of\nscientific papers and networks citation concurrence of terms and keywords of\nthe terms: covid- 19, 2019-ncov and sars-cov-2 in leading databases (MEDLINE,\nweb of Science and Scopus), was constructed. Some fields of the research on\ncovid-19 are connected together, differing in structure, content and evolution.\n",
        "query": "genome sequencing of covid-19",
        "docId": 1260789,
        "score": 9.994003295898438
    },
    {
        "title": "Even better correction of genome sequencing data",
        "paperAbstract": "  We introduce an improved version of RECKONER, an error corrector for Illumina\nwhole genome sequencing data. By modifying its workflow we reduce the\ncomputation time even 10 times. We also propose a new method of determination\nof $k$-mer length, the key parameter of $k$-spectrum-based family of\ncorrectors. The correction algorithms are examined on huge data sets, i.e.,\nhuman and maize genomes for both Illumina HiSeq and MiSeq instruments.\n",
        "query": "genome sequencing of covid-19",
        "docId": 824194,
        "score": 9.939142227172852
    },
    {
        "title": "EDGE COVID-19: A Web Platform to generate submission-ready genomes for\n  SARS-CoV-2 sequencing efforts",
        "paperAbstract": "  Genomics has become an essential technology for surveilling emerging\ninfectious disease outbreaks. A wide range of technologies and strategies for\npathogen genome enrichment and sequencing are being used by laboratories\nworldwide, together with different, and sometimes ad hoc, analytical procedures\nfor generating genome sequences. As a result, public repositories now contain\nnon-standard entries of varying quality. A standardized analytical process for\nconsensus genome sequence determination, particularly for outbreaks such as the\nongoing COVID-19 pandemic, is critical to provide a solid genomic basis for\nepidemiological analyses and well-informed decision making. To address this\nneed, we have developed a bioinformatic workflow to standardize the analysis of\nSARS-CoV-2 sequencing data generated with either the Illumina or Oxford\nNanopore platforms. Using an intuitive web-based interface, this workflow\nautomates SARS-CoV-2 reference-based genome assembly, variant calling, lineage\ndetermination, and provides the ability to submit the consensus sequence and\nnecessary metadata to GenBank or GISAID. Given a raw Illumina or Oxford\nNanopore FASTQ read file, this web-based platform enables non-bioinformatics\nexperts to automatically produce a SARS-CoV-2 genome that is ready for\nsubmission to GISAID or GenBank.\n  Availability:https://edge-covid19.edgebioinformatics.org;https://github.com/LANL-Bioinformatics/EDGE/tree/SARS-CoV2\n",
        "query": "genome sequencing of covid-19",
        "docId": 1302572,
        "score": 9.931639671325684
    },
    {
        "title": "Nested Sampling Methods",
        "paperAbstract": "  Nested sampling (NS) computes parameter posterior distributions and makes\nBayesian model comparison computationally feasible. Its strengths are the\nunsupervised navigation of complex, potentially multi-modal posteriors until a\nwell-defined termination point. A systematic literature review of nested\nsampling algorithms and variants is presented. We focus on complete algorithms,\nincluding solutions to likelihood-restricted prior sampling, parallelisation,\ntermination and diagnostics. The relation between number of live points,\ndimensionality and computational cost is studied for two complete algorithms. A\nnew formulation of NS is presented, which casts the parameter space exploration\nas a search on a tree. Previously published ways of obtaining robust error\nestimates and dynamic variations of the number of live points are presented as\nspecial cases of this formulation. A new on-line diagnostic test is presented\nbased on previous insertion rank order work. The survey of nested sampling\nmethods concludes with outlooks for future research.\n",
        "query": "different sampling methods ",
        "docId": 1413417,
        "score": 8.80793571472168
    },
    {
        "title": "Evaluation of Sampling Methods for Scatterplots",
        "paperAbstract": "  Given a scatterplot with tens of thousands of points or even more, a natural\nquestion is which sampling method should be used to create a small but \"good\"\nscatterplot for a better abstraction. We present the results of a user study\nthat investigates the influence of different sampling strategies on multi-class\nscatterplots. The main goal of this study is to understand the capability of\nsampling methods in preserving the density, outliers, and overall shape of a\nscatterplot. To this end, we comprehensively review the literature and select\nseven typical sampling strategies as well as eight representative datasets. We\nthen design four experiments to understand the performance of different\nstrategies in maintaining: 1) region density; 2) class density; 3) outliers;\nand 4) overall shape in the sampling results. The results show that: 1) random\nsampling is preferred for preserving region density; 2) blue noise sampling and\nrandom sampling have comparable performance with the three multi-class sampling\nstrategies in preserving class density; 3) outlier biased density based\nsampling, recursive subdivision based sampling, and blue noise sampling perform\nthe best in keeping outliers; and 4) blue noise sampling outperforms the others\nin maintaining the overall shape of a scatterplot.\n",
        "query": "different sampling methods ",
        "docId": 1326180,
        "score": 8.798240661621094
    },
    {
        "title": "Coupling methods for multistage sampling",
        "paperAbstract": "  Multistage sampling is commonly used for household surveys when there exists\nno sampling frame, or when the population is scattered over a wide area.\nMultistage sampling usually introduces a complex dependence in the selection of\nthe final units, which makes asymptotic results quite difficult to prove. In\nthis work, we consider multistage sampling with simple random without\nreplacement sampling at the first stage, and with an arbitrary sampling design\nfor further stages. We consider coupling methods to link this sampling design\nto sampling designs where the primary sampling units are selected\nindependently. We first generalize a method introduced by [Magyar Tud. Akad.\nMat. Kutat\\\u0027{o} Int. K\\\"{o}zl. 5 (1960) 361-374] to get a coupling with\nmultistage sampling and Bernoulli sampling at the first stage, which leads to a\ncentral limit theorem for the Horvitz--Thompson estimator. We then introduce a\nnew coupling method with multistage sampling and simple random with replacement\nsampling at the first stage. When the first-stage sampling fraction tends to\nzero, this method is used to prove consistency of a with-replacement bootstrap\nfor simple random without replacement sampling at the first stage, and\nconsistency of bootstrap variance estimators for smooth functions of totals.\n",
        "query": "different sampling methods ",
        "docId": 678517,
        "score": 8.49378776550293
    },
    {
        "title": "A* Sampling",
        "paperAbstract": "  The problem of drawing samples from a discrete distribution can be converted\ninto a discrete optimization problem. In this work, we show how sampling from a\ncontinuous distribution can be converted into an optimization problem over\ncontinuous space. Central to the method is a stochastic process recently\ndescribed in mathematical statistics that we call the Gumbel process. We\npresent a new construction of the Gumbel process and A* sampling, a practical\ngeneric sampling algorithm that searches for the maximum of a Gumbel process\nusing A* search. We analyze the correctness and convergence time of A* sampling\nand demonstrate empirically that it makes more efficient use of bound and\nlikelihood evaluations than the most closely related adaptive rejection\nsampling-based algorithms.\n",
        "query": "different sampling methods ",
        "docId": 570002,
        "score": 8.185224533081055
    },
    {
        "title": "Towards Cost-efficient Sampling Methods",
        "paperAbstract": "  The sampling method has been paid much attention in the field of complex\nnetwork in general and statistical physics in particular. This paper presents\ntwo new sampling methods based on the perspective that a small part of vertices\nwith high node degree can possess the most structure information of a network.\nThe two proposed sampling methods are efficient in sampling the nodes with high\ndegree. The first new sampling method is improved on the basis of the\nstratified random sampling method and selects the high degree nodes with higher\nprobability by classifying the nodes according to their degree distribution.\nThe second sampling method improves the existing snowball sampling method so\nthat it enables to sample the targeted nodes selectively in every sampling\nstep. Besides, the two proposed sampling methods not only sample the nodes but\nalso pick the edges directly connected to these nodes. In order to demonstrate\nthe two methods\u0027 availability and accuracy, we compare them with the existing\nsampling methods in three commonly used simulation networks that are scale-free\nnetwork, random network, small-world network, and two real networks. The\nexperimental results show that the two proposed sampling methods perform much\nbetter than the compared existing sampling methods in terms of sampling cost\nand obtaining the true network structural characteristics.\n",
        "query": "different sampling methods ",
        "docId": 526664,
        "score": 8.16287899017334
    },
    {
        "title": "Survey on Positioning System: Sampling methods",
        "paperAbstract": "  Millimeter-accuracy Ultra-Wideband (UWB) positioning systems using the Time\nDifference Of Arrival (TDOA) algorithm are able to be utilized in military and\nmany other important applications. Previous research on UWB positioning system\nhas achieved up to mm or sub-mm accuracy. However, one bottleneck in UWB system\nis at sampling high resolution UWB signals, as well as high resolution timing\ninformation. In this paper, UWB positioning systems are surveyed and we focus\non sampling methods for handling UWB signals. Among different sampling methods,\none traditional way is the sequential sampling method, which is not a real time\nsampling method and blocks UWB positioning system to achieve higher precision.\nAnother way is by applying Compressed Sensing (CS) to UWB system for achieving\nsub-mm positioning accuracy. In this paper, we compare different TDOA-based UWB\nsystems with different sampling methods. In particular, several CS-UWB\nalgorithms for UWB signal reconstruction are compared in terms of positioning\naccuracy. Simulation results in 2D and 3D experiments demonstrate performance\nof different algorithms including typical BCS, OMP and BP algorithms. CS-UWB is\nalso compared with UWB positioning system based on the sequential sampling\nmethod.\n",
        "query": "different sampling methods ",
        "docId": 449330,
        "score": 7.970593452453613
    },
    {
        "title": "Enhanced sampling methods for molecular dynamics simulations",
        "paperAbstract": "  Enhanced sampling algorithms have emerged as powerful methods to extend the\nutility of molecular dynamics simulations and allow the sampling of larger\nportions of the configuration space of complex systems in a given amount of\nsimulation time. This review aims to present the unifying principles and\ndifferences of many of the computational methods currenly used for enhanced\nsampling in molecular simulations of biomolecules, soft matter and molecular\ncrystals. Indeed, despite the apparent abundance and divergence of such\nmethods, the principles at their core can be boiled down to a relatively\nlimited number of statistical and physical principles. To enable comparisons,\nthe various methods are introduced using similar terminology and notation. We\nthen illustrate in which ways many different methods combine principles from a\nsmaller class of enhanced sampling concepts. This review is intended for\nscientists with an understanding of the basics of molecular dynamics\nsimulations and statistical physics who want a deeper understanding of the\nideas that underlie various enhanced sampling methods and the relationships\nbetween them. This living review is intended to be updated to continue to\nreflect the wealth of sampling methods as they continue to emerge in the\nliterature.\n",
        "query": "different sampling methods ",
        "docId": 1602988,
        "score": 7.531382083892822
    },
    {
        "title": "Are Outlier Detection Methods Resilient to Sampling?",
        "paperAbstract": "  Outlier detection is a fundamental task in data mining and has many\napplications including detecting errors in databases. While there has been\nextensive prior work on methods for outlier detection, modern datasets often\nhave sizes that are beyond the ability of commonly used methods to process the\ndata within a reasonable time. To overcome this issue, outlier detection\nmethods can be trained over samples of the full-sized dataset. However, it is\nnot clear how a model trained on a sample compares with one trained on the\nentire dataset. In this paper, we introduce the notion of resilience to\nsampling for outlier detection methods. Orthogonal to traditional performance\nmetrics such as precision/recall, resilience represents the extent to which the\noutliers detected by a method applied to samples from a sampling scheme matches\nthose when applied to the whole dataset. We propose a novel approach for\nestimating the resilience to sampling of both individual outlier methods and\ntheir ensembles. We performed an extensive experimental study on synthetic and\nreal-world datasets where we study seven diverse and representative outlier\ndetection methods, compare results obtained from samples versus those obtained\nfrom the whole datasets and evaluate the accuracy of our resilience estimates.\nWe observed that the methods are not equally resilient to a given sampling\nscheme and it is often the case that careful joint selection of both the\nsampling scheme and the outlier detection method is necessary. It is our hope\nthat the paper initiates research on designing outlier detection algorithms\nthat are resilient to sampling.\n",
        "query": "different sampling methods ",
        "docId": 1157812,
        "score": 7.454155445098877
    },
    {
        "title": "Sampling Algorithms, from Survey Sampling to Monte Carlo Methods:\n  Tutorial and Literature Review",
        "paperAbstract": "  This paper is a tutorial and literature review on sampling algorithms. We\nhave two main types of sampling in statistics. The first type is survey\nsampling which draws samples from a set or population. The second type is\nsampling from probability distribution where we have a probability density or\nmass function. In this paper, we cover both types of sampling. First, we review\nsome required background on mean squared error, variance, bias, maximum\nlikelihood estimation, Bernoulli, Binomial, and Hypergeometric distributions,\nthe Horvitz-Thompson estimator, and the Markov property. Then, we explain the\ntheory of simple random sampling, bootstrapping, stratified sampling, and\ncluster sampling. We also briefly introduce multistage sampling, network\nsampling, and snowball sampling. Afterwards, we switch to sampling from\ndistribution. We explain sampling from cumulative distribution function, Monte\nCarlo approximation, simple Monte Carlo methods, and Markov Chain Monte Carlo\n(MCMC) methods. For simple Monte Carlo methods, whose iterations are\nindependent, we cover importance sampling and rejection sampling. For MCMC\nmethods, we cover Metropolis algorithm, Metropolis-Hastings algorithm, Gibbs\nsampling, and slice sampling. Then, we explain the random walk behaviour of\nMonte Carlo methods and more efficient Monte Carlo methods, including\nHamiltonian (or hybrid) Monte Carlo, Adler\u0027s overrelaxation, and ordered\noverrelaxation. Finally, we summarize the characteristics, pros, and cons of\nsampling methods compared to each other. This paper can be useful for different\nfields of statistics, machine learning, reinforcement learning, and\ncomputational physics.\n",
        "query": "different sampling methods ",
        "docId": 1373649,
        "score": 7.392632007598877
    },
    {
        "title": "Evaluation of Sampling Methods for Robotic Sediment Sampling Systems",
        "paperAbstract": "  Analysis of sediments from rivers, lakes, reservoirs, wetlands and other\nconstructed surface water impoundments is an important tool to characterize the\nfunction and health of these systems, but is generally carried out manually.\nThis is costly and can be hazardous and difficult for humans due to\ninaccessibility, contamination, or availability of required equipment. Robotic\nsampling systems can ease these burdens, but little work has examined the\nefficiency of such sampling means and no prior work has investigated the\nquality of the resulting samples. This paper presents an experimental study\nthat evaluates and optimizes sediment sampling patterns applied to a robot\nsediment sampling system that allows collection of minimally-disturbed sediment\ncores from natural and man-made water bodies for various sediment types. To\nmeet this need, we developed and tested a robotic sampling platform in the\nlaboratory to test functionality under a range of sediment types and operating\nconditions. Specifically, we focused on three patterns by which a cylindrical\ncoring device was driven into the sediment (linear, helical, and zig-zag) for\nthree sediment types (coarse sand, medium sand, and silt). The results show\nthat the optimal sampling pattern varies depending on the type of sediment and\ncan be optimized based on the sampling objective. We examined two sampling\nobjectives: maximizing the mass of minimally disturbed sediment and minimizing\nthe power per mass of sample. This study provides valuable data to aid in the\nselection of optimal sediment coring methods for various applications and\nbuilds a solid foundation for future field testing under a range of\nenvironmental conditions.\n",
        "query": "different sampling methods ",
        "docId": 1307874,
        "score": 7.355737686157227
    },
    {
        "title": "On entropy in eulerian thermodynamics",
        "paperAbstract": "  To the student of thermodynamics the most difficult subject is entropy. In\nthis paper we examine the actual, practical application of entropy to two\nsimple systems, the homogeneous slab with fixed boundary values of the\ntemperature, and an isolated atmosphere in the presence of the static\ngravitational field. The first gives valuable insight into the nature of\nentropy that is subsequently applied to the second system.\n  It is a basic tenet of thermodynamics that the equilibrium of an extended,\nhomogeneous and isolated system is characterized by a uniform temperature\ndistribution and it is a strongly held belief that this remains true in the\npresence of gravity. We find that this is consistent with the equations of\nextended thermodynamics but that entropy enters in an essential way. The\nprinciple of equivalence takes on a new aspect.\n",
        "query": "entropy and thermodynamics",
        "docId": 267908,
        "score": 10.137030601501465
    },
    {
        "title": "Thermodynamics from relative entropy",
        "paperAbstract": "  Thermodynamics is usually developed starting from entropy and the maximum\nentropy principle. We investigate here to what extent one can replace entropy\nwith relative entropy which has several advantages, for example in the context\nof local quantum field theory. We find that the principle of maximum entropy\ncan be replaced by a principle of minimum expected relative entropy. Various\nensembles and their thermodynamic potentials can be defined through relative\nentropy. We also show that thermal fluctuations are in fact governed by a\nrelative entropy. Furthermore we reformulate the third law of thermodynamics\nusing relative entropy only.\n",
        "query": "entropy and thermodynamics",
        "docId": 1278303,
        "score": 9.537836074829102
    },
    {
        "title": "No Entropy Production in Quantum Thermodynamics",
        "paperAbstract": "  In this work we will show that there exists a fundamental difference between\nmicroscopic quantum thermodynamics and macroscopic classical thermodynamics. It\nwill be proved that the entropy production in quantum thermodynamics always\nvanishes for both closed and open quantum thermodynamic systems. This novel and\nvery surprising result is derived based on the genuine reasoning Clausius used\nto establish the science of thermodynamics in the first place. This result will\ninterestingly lead to define the generalized temperature for any\nnon-equilibrium quantum system.\n",
        "query": "entropy and thermodynamics",
        "docId": 1248170,
        "score": 9.083768844604492
    },
    {
        "title": "Thermodynamics, entropy and waterwheels",
        "paperAbstract": "  In this paper the analogy between a thermal engine and a waterwheel is\ndeveloped in details, showing that the analogous of the flow of water in an\nhydraulic engine is the flow of entropy in a thermal one. This analogy mat\nserve to analyse in details the aspects of a thermal engine that are quite\ndistant from pupils\u0027 intuition. The discussion is complemented by an\nillustration of the working of thermal and hydraulic engines at the microscopic\nlevel, thus furnishing a view of what heat and work are at this level, and\nintroducing the statistical and information aspects of entropy. Both hydraulic\nand thermal non-ideal engines are also discussed.\n",
        "query": "entropy and thermodynamics",
        "docId": 770568,
        "score": 8.596015930175781
    },
    {
        "title": "Positive and negative entropy production in thermodynamics systems",
        "paperAbstract": "  This article presents a heuristic combination of the local and global\nformulations of the second law of thermodynamics that suggests the possibility\nof theoretical existence of thermodynamics processes with positive and negative\nentropy production.Such processes may exhibit entropy couplings that reveal an\nunusual behavior from the point of view of conventional thermodynamics.\n",
        "query": "entropy and thermodynamics",
        "docId": 101265,
        "score": 8.546010971069336
    },
    {
        "title": "Entropy in the interior of a black hole and thermodynamics",
        "paperAbstract": "  Based on a recent proposal for the volume inside a black hole, we calculate\nthe entropy associated with this volume and show that such entropy is\nproportional to the surface area of the black hole. Together with the\nconsideration of black hole radiation, we find that the thermodynamics\nassociated with the entropy is likely to be caused by the vacuum polarization\nnear the horizon.\n",
        "query": "entropy and thermodynamics",
        "docId": 666139,
        "score": 8.466960906982422
    },
    {
        "title": "Entropy, Gravitation, and Thermodynamics",
        "paperAbstract": "  The relationship between the intrinsic motion of gravity, light, and time is\nexplored in terms of the principles of entropy, causality, energy, and symmetry\nconservation. A conceptual mechanism for gravity and the gravitational\nconnection between quantum mechanics and relativity is explored. A \"concept\nequation\" is given for the gravitational annihilation of space and the\nextraction of a metrically equivalent temporal residue. The relationship of\ngravity to the other forces is discussed, including the reason for the weakness\nof gravity.\n",
        "query": "entropy and thermodynamics",
        "docId": 1998235,
        "score": 8.438209533691406
    },
    {
        "title": "Entropy and time: Thermodynamics of diffusion processes",
        "paperAbstract": "  We give meaning to the first and second laws of thermodynamics in case of\nmesoscopic out-of-equilibrium systems which are driven by diffusion processes.\nThe notion of the entropy production is analyzed. The role of the Helmholtz\nextremum principle is contrasted to that of the more familiar entropy extremum\nprinciples.\n",
        "query": "entropy and thermodynamics",
        "docId": 1944499,
        "score": 8.380264282226562
    },
    {
        "title": "The Entropy Anomaly and the Linear Irreversible Thermodynamics",
        "paperAbstract": "  The irreversible currents and entropy production rate of a dilute colloidal\nsuspension are calculated using the linear irreversible thermodynamics and the\nlinear response theory. The \\anomalous\" or \\hidden\" entropy recently discussed\nin the context of the stochastic thermodynamics is fully accounted in these\nclassic frameworks. We show that the two distinct formulations lead to\nidentical results as long as the local equilibrium assumption or, equivalently\nthe linear response theory, is valid.\n",
        "query": "entropy and thermodynamics",
        "docId": 967744,
        "score": 8.34876823425293
    },
    {
        "title": "Gibbs entropy and irreversible thermodynamics",
        "paperAbstract": "  Recently a number of approaches has been developed to connect the microscopic\ndynamics of particle systems to the macroscopic properties of systems in\nnonequilibrium stationary states, via the theory of dynamical systems. This way\na direct connection between dynamics and Irreversible Thermodynamics has been\nclaimed to have been found. However, the main quantity used in these studies is\na (coarse-grained) Gibbs entropy, which to us does not seem suitable, in its\npresent form, to characterize nonequilibrium states. Various simplified models\nhave also been devised to give explicit examples of how the coarse-grained\napproach may succeed in giving a full description of the Irreversible\nThermodynamics. We analyze some of these models pointing out a number of\ndifficulties which, in our opinion, need to be overcome in order to establish a\nphysically relevant connection between these models and Irreversible\nThermodynamics.\n",
        "query": "entropy and thermodynamics",
        "docId": 1971406,
        "score": 8.27273941040039
    },
    {
        "title": "A Bayesian latent allocation model for clustering compositional data\n  with application to the Great Barrier Reef",
        "paperAbstract": "  Relative abundance is a common metric to estimate the composition of species\nin ecological surveys reflecting patterns of commonness and rarity of\nbiological assemblages. Measurements of coral reef compositions formed by four\ncommunities along Australia\u0027s Great Barrier Reef (GBR) gathered between 2012\nand 2017 are the focus of this paper. We undertake the task of finding clusters\nof transect locations with similar community composition and investigate\nchanges in clustering dynamics over time. During these years, an unprecedented\nsequence of extreme weather events (cyclones and coral bleaching) impacted the\n58 surveyed locations. The dependence between constituent parts of a\ncomposition presents a challenge for existing multivariate clustering\napproaches. In this paper, we introduce a finite mixture of Dirichlet\ndistributions with group-specific parameters, where cluster memberships are\ndictated by unobserved latent variables. The inference is carried in a Bayesian\nframework, where MCMC strategies are outlined to sample from the posterior\nmodel. Simulation studies are presented to illustrate the performance of the\nmodel in a controlled setting. The application of the model to the 2012 coral\nreef data reveals that clusters were spatially distributed in similar ways\nacross reefs which indicates a potential influence of wave exposure at the\norigin of coral reef community composition. The number of clusters estimated by\nthe model decreased from four in 2012 to two from 2014 until 2017. Posterior\nprobabilities of transect allocations to the same cluster substantially\nincrease through time showing a potential homogenization of community\ncomposition across the whole GBR. The Bayesian model highlights the diversity\nof coral reef community composition within a coral reef and rapid changes\nacross large spatial scales that may contribute to undermining the future of\nthe GBR\u0027s biodiversity.\n",
        "query": "great barrier reef",
        "docId": 1464699,
        "score": 12.045077323913574
    },
    {
        "title": "Monitoring through many eyes: Integrating disparate datasets to improve\n  monitoring of the Great Barrier Reef",
        "paperAbstract": "  Numerous organisations collect data in the Great Barrier Reef (GBR), but they\nare rarely analysed together due to different program objectives, methods, and\ndata quality. We developed a weighted spatiotemporal Bayesian model and used it\nto integrate image based hard coral data collected by professional and citizen\nscientists, who captured and or classified underwater images. We used the model\nto predict coral cover across the GBR with estimates of uncertainty; thus\nfilling gaps in space and time where no data exist. Additional data increased\nthe models predictive ability by 43 percent, but did not affect model\ninferences about pressures (e.g. bleaching and cyclone damage). Thus, effective\nintegration of professional and high-volume citizen data could enhance the\ncapacity and cost efficiency of monitoring programs. This general approach is\nequally viable for other variables collected in the marine environment or other\necosystems; opening up new opportunities to integrate data and provide pathways\nfor community engagement and stewardship.\n",
        "query": "great barrier reef",
        "docId": 1014444,
        "score": 10.904232025146484
    },
    {
        "title": "Reef-insight: A framework for reef habitat mapping with clustering\n  methods via remote sensing",
        "paperAbstract": "  Environmental damage has been of much concern, particularly coastal areas and\nthe oceans given climate change and drastic effects of pollution and extreme\nclimate events. Our present day analytical capabilities along with the\nadvancements in information acquisition techniques such as remote sensing can\nbe utilized for the management and study of coral reef ecosystems. In this\npaper, we present Reef-insight, an unsupervised machine learning framework that\nfeatures advanced clustering methods and remote sensing for reef community\nmapping. Our framework compares different clustering methods to evaluate them\nfor reef community mapping using remote sensing data. We evaluate four major\nclustering approaches such as k- means, hierarchical clustering, Gaussian\nmixture model, and density-based clustering based on qualitative and visual\nassessment. We utilise remote sensing data featuring Heron reef island region\nin the Great Barrier Reef of Australia. Our results indicate that clustering\nmethods using remote sensing data can well identify benthic and geomorphic\nclusters that are found in reefs when compared to other studies. Our results\nindicate that Reef-insight can generate detailed reef community maps outlining\ndistinct reef habitats and has the potential to enable further insights for\nreef restoration projects. We release our framework as open source software to\nenable its extension to different parts of the world\n",
        "query": "great barrier reef",
        "docId": 1781940,
        "score": 9.324366569519043
    },
    {
        "title": "The Great Debate",
        "paperAbstract": "  A hundred years ago (1920) in the auditorium of the Smithsonian Institution\u0027s\nU.S. National Museum there were two lectures under the auspices of the George\nEllery Hale Lecture series, what has come to be called the \u0027Great Debate\u0027. In\nthe debate, Harlow Shapley and Heber Curtis argued over the \u0027Scale of the\nUniverse\u0027. Curtis argued that the Universe is composed of many galaxies like\nour own and they are relatively small. Shapley argued that the Universe was\ncomposed of only one big Galaxy. In Shapley\u0027s model, our Sun was far from the\ncenter of this great island Universe.\n",
        "query": "great barrier reef",
        "docId": 1225572,
        "score": 7.708736419677734
    },
    {
        "title": "Bayesreef: A Bayesian inference framework for modelling reef growth in\n  response to environmental change and biological dynamics",
        "paperAbstract": "  Estimating the impact of environmental processes on vertical reef development\nin geological time is a very challenging task. pyReef-Core is a deterministic\ncarbonate stratigraphic forward model designed to simulate the key biological\nand environmental processes that determine vertical reef accretion and\nassemblage changes in fossil reef drill cores. We present a Bayesian framework\ncalled Bayesreef for the estimation and uncertainty quantification of\nparameters in pyReef-Core that represent environmental conditions affecting the\ngrowth of coral assemblages on geological timescales. We demonstrate the\nexistence of multimodal posterior distributions and investigate the challenges\nof sampling using Markov chain Monte-Carlo (MCMC) methods, which includes\nparallel tempering MCMC. We use synthetic reef-core to investigate fundamental\nissues and then apply the methodology to a selected reef-core from the Great\nBarrier Reef in Australia. The results show that Bayesreef accurately estimates\nand provides uncertainty quantification of the selected parameters that\nrepresent the environment and ecological conditions in pyReef-Core. Bayesreef\nprovides insights into the complex posterior distributions of parameters in\npyReef-Core, which provides the groundwork for future research in this area.\n",
        "query": "great barrier reef",
        "docId": 1011909,
        "score": 7.309904098510742
    },
    {
        "title": "A Real-time Edge-AI System for Reef Surveys",
        "paperAbstract": "  Crown-of-Thorn Starfish (COTS) outbreaks are a major cause of coral loss on\nthe Great Barrier Reef (GBR) and substantial surveillance and control programs\nare ongoing to manage COTS populations to ecologically sustainable levels. In\nthis paper, we present a comprehensive real-time machine learning-based\nunderwater data collection and curation system on edge devices for COTS\nmonitoring. In particular, we leverage the power of deep learning-based object\ndetection techniques, and propose a resource-efficient COTS detector that\nperforms detection inferences on the edge device to assist marine experts with\nCOTS identification during the data collection phase. The preliminary results\nshow that several strategies for improving computational efficiency (e.g.,\nbatch-wise processing, frame skipping, model input size) can be combined to run\nthe proposed detection model on edge hardware with low resource consumption and\nlow information loss.\n",
        "query": "great barrier reef",
        "docId": 1691310,
        "score": 7.168368339538574
    },
    {
        "title": "OysterSim: Underwater Simulation for Enhancing Oyster Reef Monitoring",
        "paperAbstract": "  Oysters are the living vacuum cleaners of the oceans. There is an exponential\ndecline in the oyster population due to over-harvesting. With the current\ndevelopment of the automation and AI, robots are becoming an integral part of\nthe environmental monitoring process that can be also utilized for oyster reef\npreservation. Nevertheless, the underwater environment poses many difficulties,\nboth from the practical - dangerous and time consuming operations, and the\ntechnical perspectives - distorted perception and unreliable navigation. To\nthis end, we present a simulated environment that can be used to improve oyster\nreef monitoring. The simulated environment can be used to create\nphoto-realistic image datasets with multiple sensor data and ground truth\nlocation of a remotely operated vehicle(ROV). Currently, there are no\nphoto-realistic image datasets for oyster reef monitoring. Thus, we want to\nprovide a new benchmark suite to the underwater community.\n",
        "query": "great barrier reef",
        "docId": 1715110,
        "score": 6.94046688079834
    },
    {
        "title": "The Great Division",
        "paperAbstract": "  When information flow fails, when Democrats and Republicans do not talk to\neach other, when Israelis and Palestinians do not talk to each other, and when\nNorth Koreans and South Koreans do not talk to each other, mis-perceptions,\nbiases and fake news arise. In this paper we present an in-depth study of\npolitical polarization and social division using Twitter data and Monte Carlo\nsimulations. First, we study at the aggregate level people\u0027s inclination to\nretweet within their own ideological circle. Introducing the concept of cocoon\nratio, we show that Donald Trump\u0027s followers are 2.56 more likely to retweet a\nfellow Trump follower than to retweet a Hillary Clinton follower. Second, going\ndown to the individual level, we show that the tendency of retweeting\nexclusively within one\u0027s ideological circle is stronger for women than for men\nand that such tendency weakens as one\u0027s social capital grows. Third, we use a\none-dimensional Ising model to simulate how a society with high cocoon ratios\ncould end up becoming completely divided. We conclude with a discussion of our\nfindings with respect to fake news.\n",
        "query": "great barrier reef",
        "docId": 939696,
        "score": 6.746514797210693
    },
    {
        "title": "Reconfigurable Robots for Scaling Reef Restoration",
        "paperAbstract": "  Coral reefs are under increasing threat from the impacts of climate change.\nWhilst current restoration approaches are effective, they require significant\nhuman involvement and equipment, and have limited deployment scale. Harvesting\nwild coral spawn from mass spawning events, rearing them to the larval stage\nand releasing the larvae onto degraded reefs is an emerging solution for reef\nrestoration known as coral reseeding. This paper presents a reconfigurable\nautonomous surface vehicle system that can eliminate risky diving, cover\ngreater areas with coral larvae, has a sensory suite for additional data\nmeasurement, and requires minimal non-technical expert training. A key feature\nis an on-board real-time benthic substrate classification model that predicts\nwhen to release larvae to increase settlement rate and ultimately,\nsurvivability. The presented robot design is reconfigurable, light weight,\nscalable, and easy to transport. Results from restoration deployments at Lizard\nIsland demonstrate improved coral larvae release onto appropriate coral\nsubstrate, while also achieving 21.8 times more area coverage compared to\nmanual methods.\n",
        "query": "great barrier reef",
        "docId": 1649024,
        "score": 6.711132049560547
    },
    {
        "title": "The great trinomial hunt",
        "paperAbstract": "  We describe a search for primitive trinomials of high degree and its\ninteraction with the Great Internet Mersenne prime search (GIMPS). The search\nis complete for trinomials whose degree is the exponent of a Mersenne prime,\nfor all 47 currently known Mersenne primes.\n",
        "query": "great barrier reef",
        "docId": 189507,
        "score": 6.51927375793457
    },
    {
        "title": "Bias in Machine Learning -- What is it Good for?",
        "paperAbstract": "  In public media as well as in scientific publications, the term \\emph{bias}\nis used in conjunction with machine learning in many different contexts, and\nwith many different meanings. This paper proposes a taxonomy of these different\nmeanings, terminology, and definitions by surveying the, primarily scientific,\nliterature on machine learning. In some cases, we suggest extensions and\nmodifications to promote a clear terminology and completeness. The survey is\nfollowed by an analysis and discussion on how different types of biases are\nconnected and depend on each other. We conclude that there is a complex\nrelation between bias occurring in the machine learning pipeline that leads to\na model, and the eventual bias of the model (which is typically related to\nsocial discrimination). The former bias may or may not influence the latter, in\na sometimes bad, and sometime good way.\n",
        "query": "what is bias in machine learning",
        "docId": 1265456,
        "score": 13.899625778198242
    },
    {
        "title": "Understanding Bias in Machine Learning",
        "paperAbstract": "  Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.\n",
        "query": "what is bias in machine learning",
        "docId": 1171904,
        "score": 12.140279769897461
    },
    {
        "title": "What is the Machine Learning?",
        "paperAbstract": "  Applications of machine learning tools to problems of physical interest are\noften criticized for producing sensitivity at the expense of transparency. To\naddress this concern, we explore a data planing procedure for identifying\ncombinations of variables -- aided by physical intuition -- that can\ndiscriminate signal from background. Weights are introduced to smooth away the\nfeatures in a given variable(s). New networks are then trained on this modified\ndata. Observed decreases in sensitivity diagnose the variable\u0027s discriminating\npower. Planing also allows the investigation of the linear versus non-linear\nnature of the boundaries between signal and background. We demonstrate the\nefficacy of this approach using a toy example, followed by an application to an\nidealized heavy resonance scenario at the Large Hadron Collider. By unpacking\nthe information being utilized by these algorithms, this method puts in context\nwhat it means for a machine to learn.\n",
        "query": "what is bias in machine learning",
        "docId": 894972,
        "score": 11.831708908081055
    },
    {
        "title": "Underestimation Bias and Underfitting in Machine Learning",
        "paperAbstract": "  Often, what is termed algorithmic bias in machine learning will be due to\nhistoric bias in the training data. But sometimes the bias may be introduced\n(or at least exacerbated) by the algorithm itself. The ways in which algorithms\ncan actually accentuate bias has not received a lot of attention with\nresearchers focusing directly on methods to eliminate bias - no matter the\nsource. In this paper we report on initial research to understand the factors\nthat contribute to bias in classification algorithms. We believe this is\nimportant because underestimation bias is inextricably tied to regularization,\ni.e. measures to address overfitting can accentuate bias.\n",
        "query": "what is bias in machine learning",
        "docId": 1288847,
        "score": 11.472586631774902
    },
    {
        "title": "Machine-Learning media bias",
        "paperAbstract": "  We present an automated method for measuring media bias. Inferring which\nnewspaper published a given article, based only on the frequencies with which\nit uses different phrases, leads to a conditional probability distribution\nwhose analysis lets us automatically map newspapers and phrases into a bias\nspace. By analyzing roughly a million articles from roughly a hundred\nnewspapers for bias in dozens of news topics, our method maps newspapers into a\ntwo-dimensional bias landscape that agrees well with previous bias\nclassifications based on human judgement. One dimension can be interpreted as\ntraditional left-right bias, the other as establishment bias. This means that\nalthough news bias is inherently political, its measurement need not be.\n",
        "query": "what is bias in machine learning",
        "docId": 1522845,
        "score": 10.557260513305664
    },
    {
        "title": "Bias in Machine Learning Software: Why? How? What to do?",
        "paperAbstract": "  Increasingly, software is making autonomous decisions in case of criminal\nsentencing, approving credit cards, hiring employees, and so on. Some of these\ndecisions show bias and adversely affect certain social groups (e.g. those\ndefined by sex, race, age, marital status). Many prior works on bias mitigation\ntake the following form: change the data or learners in multiple ways, then see\nif any of that improves fairness. Perhaps a better approach is to postulate\nroot causes of bias and then applying some resolution strategy. This paper\npostulates that the root causes of bias are the prior decisions that affect-\n(a) what data was selected and (b) the labels assigned to those examples. Our\nFair-SMOTE algorithm removes biased labels; and rebalances internal\ndistributions such that based on sensitive attribute, examples are equal in\nboth positive and negative classes. On testing, it was seen that this method\nwas just as effective at reducing bias as prior approaches. Further, models\ngenerated via Fair-SMOTE achieve higher performance (measured in terms of\nrecall and F1) than other state-of-the-art fairness improvement algorithms. To\nthe best of our knowledge, measured in terms of number of analyzed learners and\ndatasets, this study is one of the largest studies on bias mitigation yet\npresented in the literature.\n",
        "query": "what is bias in machine learning",
        "docId": 1474754,
        "score": 10.37391185760498
    },
    {
        "title": "Contextuality and inductive bias in quantum machine learning",
        "paperAbstract": "  Generalisation in machine learning often relies on the ability to encode\nstructures present in data into an inductive bias of the model class. To\nunderstand the power of quantum machine learning, it is therefore crucial to\nidentify the types of data structures that lend themselves naturally to quantum\nmodels. In this work we look to quantum contextuality -- a form of\nnonclassicality with links to computational advantage -- for answers to this\nquestion. We introduce a framework for studying contextuality in machine\nlearning, which leads us to a definition of what it means for a learning model\nto be contextual. From this, we connect a central concept of contextuality,\ncalled operational equivalence, to the ability of a model to encode a linearly\nconserved quantity in its label space. A consequence of this connection is that\ncontextuality is tied to expressivity: contextual model classes that encode the\ninductive bias are generally more expressive than their noncontextual\ncounterparts. To demonstrate this, we construct an explicit toy learning\nproblem -- based on learning the payoff behaviour of a zero-sum game -- for\nwhich this is the case. By leveraging tools from geometric quantum machine\nlearning, we then describe how to construct quantum learning models with the\nassociated inductive bias, and show through our toy problem that they\noutperform their corresponding classical surrogate models. This suggests that\nunderstanding learning problems of this form may lead to useful insights about\nthe power of quantum machine learning.\n",
        "query": "what is bias in machine learning",
        "docId": 1786299,
        "score": 10.248140335083008
    },
    {
        "title": "A Survey on Bias and Fairness in Machine Learning",
        "paperAbstract": "  With the widespread use of AI systems and applications in our everyday lives,\nit is important to take fairness issues into consideration while designing and\nengineering these types of systems. Such systems can be used in many sensitive\nenvironments to make important and life-changing decisions; thus, it is crucial\nto ensure that the decisions do not reflect discriminatory behavior toward\ncertain groups or populations. We have recently seen work in machine learning,\nnatural language processing, and deep learning that addresses such challenges\nin different subdomains. With the commercialization of these systems,\nresearchers are becoming aware of the biases that these applications can\ncontain and have attempted to address them. In this survey we investigated\ndifferent real-world applications that have shown biases in various ways, and\nwe listed different sources of biases that can affect AI applications. We then\ncreated a taxonomy for fairness definitions that machine learning researchers\nhave defined in order to avoid the existing bias in AI systems. In addition to\nthat, we examined different domains and subdomains in AI showing what\nresearchers have observed with regard to unfair outcomes in the\nstate-of-the-art methods and how they have tried to address them. There are\nstill many future directions and solutions that can be taken to mitigate the\nproblem of bias in AI systems. We are hoping that this survey will motivate\nresearchers to tackle these issues in the near future by observing existing\nwork in their respective fields.\n",
        "query": "what is bias in machine learning",
        "docId": 1167805,
        "score": 9.986740112304688
    },
    {
        "title": "On Adversarial Bias and the Robustness of Fair Machine Learning",
        "paperAbstract": "  Optimizing prediction accuracy can come at the expense of fairness. Towards\nminimizing discrimination against a group, fair machine learning algorithms\nstrive to equalize the behavior of a model across different groups, by imposing\na fairness constraint on models. However, we show that giving the same\nimportance to groups of different sizes and distributions, to counteract the\neffect of bias in training data, can be in conflict with robustness. We analyze\ndata poisoning attacks against group-based fair machine learning, with the\nfocus on equalized odds. An adversary who can control sampling or labeling for\na fraction of training data, can reduce the test accuracy significantly beyond\nwhat he can achieve on unconstrained models. Adversarial sampling and\nadversarial labeling attacks can also worsen the model\u0027s fairness gap on test\ndata, even though the model satisfies the fairness constraint on training data.\nWe analyze the robustness of fair machine learning through an empirical\nevaluation of attacks on multiple algorithms and benchmark datasets.\n",
        "query": "what is bias in machine learning",
        "docId": 1303183,
        "score": 9.564441680908203
    },
    {
        "title": "Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey",
        "paperAbstract": "  This paper provides a comprehensive survey of bias mitigation methods for\nachieving fairness in Machine Learning (ML) models. We collect a total of 341\npublications concerning bias mitigation for ML classifiers. These methods can\nbe distinguished based on their intervention procedure (i.e., pre-processing,\nin-processing, post-processing) and the technology they apply. We investigate\nhow existing bias mitigation methods are evaluated in the literature. In\nparticular, we consider datasets, metrics and benchmarking. Based on the\ngathered insights (e.g., what is the most popular fairness metric? How many\ndatasets are used for evaluating bias mitigation methods?). We hope to support\npractitioners in making informed choices when developing and evaluating new\nbias mitigation methods.\n",
        "query": "what is bias in machine learning",
        "docId": 1682966,
        "score": 9.51605224609375
    },
    {
        "title": "Multiscale Mechanical Consequences of Ocean Acidification for Cold-Water\n  Corals",
        "paperAbstract": "  Ocean acidification is a threat to deep-sea corals and could lead to dramatic\nand rapid loss of the reef framework habitat they build. Weakening of\nstructurally critical parts of the coral reef framework can lead to physical\nhabitat collapse on an ecosystem scale, reducing the potential for biodiversity\nsupport. The mechanism underpinning crumbling and collapse of corals can be\ndescribed via a combination of laboratory-scale experiments and mathematical\nand computational models. We synthesise data from electron back-scatter\ndiffraction, micro-computed tomography, and micromechanical experiments,\nsupplemented by molecular dynamics and continuum micromechanics simulations to\npredict failure of coral structures under increasing porosity and dissolution.\nResults reveal remarkable mechanical properties of cold-water coral skeletons\nof 462 MPa compressive strength and 45-67 GPa stiffness. This is 10 times\nstronger than concrete, twice as strong than ultrahigh performance fibre\nreinforced concrete, or nacre. Contrary to what would be expected, CWCs\nskeletons retain their strength despite a loss of stiffness and even when\nsynthesised under future oceanic conditions. Our models capture the impact of\ncorrosive waters on exposed skeletons and illustrate how small modifications in\ntheir skeleton lead to significantly increased risk of crumbling coral habitat.\nThis new understanding, combined with projections of how seawater chemistry\nwill change over the coming decades, will help support future conservation and\nmanagement efforts of these vulnerable marine ecosystems by identifying which\necosystems are at risk and when they will be at risk, allowing assessment of\nthe impact upon associated biodiversity.\n",
        "query": "Ocean acidification",
        "docId": 1539844,
        "score": 9.9503173828125
    },
    {
        "title": "Modeling the seasonal variability and the governing factors of Ocean\n  Acidification over the Bay of Bengal region",
        "paperAbstract": "  The Bay of Bengal (BoB) is a high recipient of freshwater flux from rivers\nand precipitation, making the region strongly stratified. The strong\nstratification results in a thick barrier layer formation, which inhibits\nvertical mixing making this region a low-productive zone. In the present study,\nwe attempt to model the pH of the BoB region and understand the role of\ndifferent governing factors such as sea-surface temperature (SST), sea-surface\nsalinity (SSS), dissolved inorganic carbon (DIC), and total alkalinity (TALK)\non the seasonality of sea-surface pH. We run a set of sensitivity experiments\nto understand the role of each of the governing factors. The results show that\nthe SST, SSS, and DIC are the principal drivers affecting the sea-surface pH,\nwhile TALK plays a buffering role. The SST and DIC are consistently found to be\nopposite to each other. The pre-monsoon season (MAM) has shown to have an\nalmost equal contribution from all the drivers. In the pre-monsoon season, the\nSST and DIC are balanced by TALK and SSS. The role of SSS is significantly\ndominant in the second half of the year. Both SST and SSS counter the role of\nDIC in the southwest monsoon season. The strong stratification plays an\nessential role in modulating the pH of the BoB region. The thickness of the\nbarrier layer formed in the sub-surface layers positively affects the\nsea-surface pH. The northern BoB is found to be more alkaline than the southern\nBoB. Our study highlights the complexity of ocean acidification in the BoB\nregion compared to the other part of the world ocean.\n",
        "query": "Ocean acidification",
        "docId": 1661826,
        "score": 8.964097023010254
    },
    {
        "title": "Ocean Terracing",
        "paperAbstract": "  Artworks can improve humanity ability to apply macro-engineering principles\nwhich skirt or correct oceanographic problems impairing the economic usefulness\nof coastal land, the overhead airshed, and seawater temperature and salinity\nstability. A new form of Art, Ocean Art, is here proposed which centers on\ndeliberate terracing of appropriate regions of our world ocean; a proposed\nexample of macro-engineered useful Ocean Art is the technically possible 21-st\nCentury terracing of the Mediterranean Sea. Ocean Art is applicable worldwide\nto places that might be practically improved by its judicious employment. Such\nOcean Art may constitute an entirely unique category of solutions to coastal\ndisaster prevention planning.\n",
        "query": "Ocean acidification",
        "docId": 2199638,
        "score": 8.487104415893555
    },
    {
        "title": "The Pacific Ocean Neutrino Experiment",
        "paperAbstract": "  The Pacific Ocean Neutrino Experiment (P-ONE) is a new initiative with a\nvision towards constructing a multi-cubic kilometre neutrino telescope, to\nexpand our observable window of the Universe to highest energies, installed\nwithin the deep Pacific Ocean underwater infrastructure of Ocean Networks\nCanada.\n",
        "query": "Ocean acidification",
        "docId": 1289288,
        "score": 6.932348251342773
    },
    {
        "title": "The pH of Enceladus\u0027 ocean",
        "paperAbstract": "  Observational data from the Cassini spacecraft are used to obtain a chemical\nmodel of ocean water on Enceladus. The model indicates that Enceladus\u0027 ocean is\na Na-Cl-CO3 solution with an alkaline pH of ~11-12. The dominance of aqueous\nNaCl is a feature that Enceladus\u0027 ocean shares with terrestrial seawater, but\nthe ubiquity of dissolved Na2CO3 suggests that soda lakes are more analogous to\nthe Enceladus ocean. The high pH implies that the hydroxide ion should be\nrelatively abundant, while divalent metals should be present at low\nconcentrations owing to buffering by clays and carbonates on the ocean floor.\nThe high pH is interpreted to be a key consequence of serpentinization of\nchondritic rock, as predicted by prior geochemical reaction path models;\nalthough degassing of CO2 from the ocean may also play a role depending on the\nefficiency of mixing processes in the ocean. Serpentinization leads to the\ngeneration of H2, a geochemical fuel that can support both abiotic and\nbiological synthesis of organic molecules such as those that have been detected\nin Enceladus\u0027 plume. Serpentinization and H2 generation should have occurred on\nEnceladus, like on the parent bodies of aqueously altered meteorites; but it is\nunknown whether these critical processes are still taking place, or if\nEnceladus\u0027 rocky core has been completely altered by past hydrothermal\nactivity. The high pH also suggests that the delivery of oxidants from the\nsurface to the ocean has not been significant, and the rocky core did not\nexperience partial melting and igneous differentiation. On the other hand, the\npH is compatible with life as we know it; life on Earth may have begun under\nsimilar conditions, and serpentinites on Earth support microbial communities\nthat are centered on H2 that is provided by water-rock reactions.\n",
        "query": "Ocean acidification",
        "docId": 596606,
        "score": 6.922619819641113
    },
    {
        "title": "CONet: A Cognitive Ocean Network",
        "paperAbstract": "  The scientific and technological revolution of the Internet of Things has\nbegun in the area of oceanography. Historically, humans have observed the ocean\nfrom an external viewpoint in order to study it. In recent years, however,\nchanges have occurred in the ocean, and laboratories have been built on the\nseafloor. Approximately 70.8% of the Earth\u0027s surface is covered by oceans and\nrivers. The Ocean of Things is expected to be important for disaster\nprevention, ocean-resource exploration, and underwater environmental\nmonitoring. Unlike traditional wireless sensor networks, the Ocean Network has\nits own unique features, such as low reliability and narrow bandwidth. These\nfeatures will be great challenges for the Ocean Network. Furthermore, the\nintegration of the Ocean Network with artificial intelligence has become a\ntopic of increasing interest for oceanology researchers. The Cognitive Ocean\nNetwork (CONet) will become the mainstream of future ocean science and\nengineering developments. In this article, we define the CONet. The\ncontributions of the paper are as follows: (1) a CONet architecture is proposed\nand described in detail; (2) important and useful demonstration applications of\nthe CONet are proposed; and (3) future trends in CONet research are presented.\n",
        "query": "Ocean acidification",
        "docId": 1075800,
        "score": 6.718070030212402
    },
    {
        "title": "An inverse problem of ocean acoustics",
        "paperAbstract": "  The inverse problem of finding the refraction coefficient of a shallow ocean\nfrom the observation of the extra Cauchy data for the acoustic field at the\nsurface of the ocean is studied. Uniqueness theorem is proved and a\nreconstruction algorithm is obtained.\n  Comments are given on the related results in the literature.\n",
        "query": "Ocean acidification",
        "docId": 2109449,
        "score": 6.666922569274902
    },
    {
        "title": "Ocean Circulation on Enceladus With a High Versus Low Salinity Ocean",
        "paperAbstract": "  Previous studies that have considered the ocean circulation on Enceladus have\ngenerally assumed the salinity to be Earth-like. However, according to\nobservations and geochemical constraints, the salinity of Enceladus\u0027 ocean is\nlikely to be lower, and importantly, it is probably low enough to reverse the\nsign of thermal expansivity. We investigate the ocean circulation and\nstratification of Enceladus\u0027 ocean using a combination of theoretical arguments\nand simulations using the MITgcm. We find that, if the salinity is high, the\nwhole ocean is unstratified, and convection dominates the entire ocean.\nHowever, if the salinity is low enough, there exists a stratified layer in the\nupper ocean, whose thickness depends on the magnitude of the turbulent vertical\ndiffusivity, which remains poorly constrained. Such a layer can suppress the\nvertical flux of heat and tracers, thereby affecting the heat flux to the ice\nshell and leading to a vertical tracer mixing time scale across the stratified\nlayer of at least hundreds of years. This time scale is inconsistent with a\nprevious estimate of vertical ocean mixing of several years, based on the size\nof detected silica nanoparticles in the plumes, leading us to conclude that\neither the salinity of Enceladus\u0027 ocean is higher than previously suggested or\nthe interpretation of silica nanoparticle observations has to be reconsidered.\n",
        "query": "Ocean acidification",
        "docId": 1414272,
        "score": 6.650677680969238
    },
    {
        "title": "The ocean fine spray",
        "paperAbstract": "  A major fraction of the atmospheric aerosols come from the ocean spray\noriginated by the bursting of bubbles from breaking waves. A theoretical\nframework that incorporates the latest knowledge on film and jet droplets from\nbubble bursting is proposed. Assuming that their relics constitute the ultimate\norigin of primary and secondary sea aerosols through a diversity of\nphysicochemical routes, the model can be reduced to a single controlling\nparameter to predict the global probability density distribution (pdf) of the\nocean spray. The bursting and collapse of small bubbles on the sea surface from\nabout 10 to 100 microns produces an extreme energy focusing and the ejection of\na rapid liquid spout whose size reaches the free molecular regime of the\ngaseous environment. In these rarefied conditions, simulations show that this\nspout yields a jet of sub-micrometer and nanometric scale droplets whose number\nand speed can be far beyond any previous estimation, overcoming by orders of\nmagnitude alternative mechanisms recently proposed. The one-parameter model\nfits remarkably well published experimental measurements along five orders of\nmagnitude of spray size, from about 5 nm to about 0.5 mm. According to this\nproposal, the majority of aerosols determining the life on our planet would\nhave their extremely elusive birth in the uterus-like nano-shape of small\nbursting bubbles on the ocean surface at the very latest instants of collapse.\n",
        "query": "Ocean acidification",
        "docId": 1599946,
        "score": 6.395439147949219
    },
    {
        "title": "Ocean Skeletal Structures Hypotheses and Interpretation",
        "paperAbstract": "  In this paper we discuss hypotheses on formation of ocean skeletal\nstructures. These structures entered the ocean together with atmospheric\nprecipitation and were assembled from fragments of skeletal structures present\nin clouds. We base interpretation of this phenomenon on surface tension forces\nbetween fundamental tubular blocks of the investigated structures that may also\noccur beneath the ocean surface. A capillary model is presented to explain\nformation of a network of interacting tubes. Data about the nature of ocean\nskeletal structures can be instrumental in modeling many processes associated\nwith physics of the ocean.\n",
        "query": "Ocean acidification",
        "docId": 185468,
        "score": 6.347686767578125
    },
    {
        "title": "Stochastic resetting antiviral therapies prevents drug resistance\n  development",
        "paperAbstract": "  We study minimal mean-field models of viral drug resistance development in\nwhich the efficacy of a therapy is described by a one-dimensional stochastic\nresetting process with mixed reflecting-absorbing boundary conditions. We\nderive analytical expressions for the mean survival time for the virus to\ndevelop complete resistance to the drug. We show that the optimal therapy\nresetting rates that achieve a minimum and maximum mean survival times undergo\na second and first-order phase transition-like behaviour as a function of the\ntherapy efficacy drift. We illustrate our results with simulations of a\npopulation-dynamics model of HIV-1 infection.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 1348189,
        "score": 8.614604949951172
    },
    {
        "title": "Machine Learning Methods for Shark Detection",
        "paperAbstract": "  This essay reviews human observer-based methods employed in shark spotting in\nMuizenberg Beach. It investigates Machine Learning methods for automated shark\ndetection with the aim of enhancing human observation. A questionnaire and\ninterview were used to collect information about shark spotting, the motivation\nof the actual Shark Spotter program and its limitations. We have defined a list\nof desirable properties for our model and chosen the adequate mathematical\ntechniques. The preliminary results of the research show that we can expect to\nextract useful information from shark images despite the geometric\ntransformations that sharks perform, its features do not change. To conclude,\nwe have partially implemented our model; the remaining implementation requires\ndataset.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 1131745,
        "score": 8.382742881774902
    },
    {
        "title": "Review of COVID-19 Antibody Therapies",
        "paperAbstract": "  Under the global health emergency caused by coronavirus disease 2019\n(COVID-19), efficient and specific therapies are urgently needed. Compared with\ntraditional small-molecular drugs, antibody therapies are relatively easy to\ndevelop and as specific as vaccines in targeting severe acute respiratory\nsyndrome coronavirus 2 (SARS-CoV-2), and thus attract much attention in the\npast few months. This work reviews seven existing antibodies for SARS-CoV-2\nspike (S) protein with three-dimensional (3D) structures deposited in the\nProtein Data Bank. Five antibody structures associated with SARS-CoV are\nevaluated for their potential in neutralizing SARS-CoV-2. The interactions of\nthese antibodies with the S protein receptor-binding domain (RBD) are compared\nwith those of angiotensin-converting enzyme 2 (ACE2) and RBD complexes. Due to\nthe orders of magnitude in the discrepancies of experimental binding\naffinities, we introduce topological data analysis (TDA), a variety of network\nmodels, and deep learning to analyze the binding strength and therapeutic\npotential of the aforementioned fourteen antibody-antigen complexes. The\ncurrent COVID-19 antibody clinical trials, which are not limited to the S\nprotein target, are also reviewed.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 1305098,
        "score": 7.703289985656738
    },
    {
        "title": "N-terminal domain Increases Activation of Elephant Shark Glucocorticoid\n  and Mineralocorticoid Receptors",
        "paperAbstract": "  Cortisol, corticosterone and aldosterone activate full-length glucocorticoid\nreceptor (GR) from elephant shark, a cartilaginous fish belonging to the oldest\ngroup of jawed vertebrates. Activation by aldosterone a mineralocorticoid,\nindicates partial divergence of elephant shark GR from the MR. Progesterone\nactivates elephant shark MR, but not elephant shark GR. Progesterone inhibits\nsteroid binding to elephant shark GR, but not to human GR. Deletion of the\nN-terminal domain (NTD) from elephant shark GR (Truncated GR) reduced the\nresponse to corticosteroids, while truncated and full-length elephant shark MR\nhad similar responses to corticosteroids. Chimeras of elephant shark GR NTD\nfused to MR DBD+LBD had increased activation by corticosteroids and\nprogesterone compared to full-length elephant shark MR. Elephant shark MR NTD\nfused to GR DBD+LBD had similar activation as full-length elephant shark MR,\nindicating that activation of human GR by the NTD evolved early in GR\ndivergence from the MR.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 1202111,
        "score": 7.478575706481934
    },
    {
        "title": "Shark: SQL and Rich Analytics at Scale",
        "paperAbstract": "  Shark is a new data analysis system that marries query processing with\ncomplex analytics on large clusters. It leverages a novel distributed memory\nabstraction to provide a unified engine that can run SQL queries and\nsophisticated analytics functions (e.g., iterative machine learning) at scale,\nand efficiently recovers from failures mid-query. This allows Shark to run SQL\nqueries up to 100x faster than Apache Hive, and machine learning programs up to\n100x faster than Hadoop. Unlike previous systems, Shark shows that it is\npossible to achieve these speedups while retaining a MapReduce-like execution\nengine, and the fine-grained fault tolerance properties that such engines\nprovide. It extends such an engine in several ways, including column-oriented\nin-memory storage and dynamic mid-query replanning, to effectively execute SQL.\nThe result is a system that matches the speedups reported for MPP analytic\ndatabases over MapReduce, while offering fault tolerance properties and complex\nanalytics capabilities that they lack.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 388422,
        "score": 7.402504920959473
    },
    {
        "title": "Mediation Analyses for the Effect of Antibodies in Vaccination",
        "paperAbstract": "  We partition the total ratio effect (one minus the vaccine effect) from a\nvaccine trial into indirect (effects through antibodies) and direct effects\n(other effects). Identifying $p$, the proportion of the total effect due to the\nindirect effect, depends on a cross-world quantity, the potential outcome among\nvaccinated individuals with antibody levels as if given placebo, or vice versa.\nWe review assumptions for identifying $p$, showing that, unless the effect of\nadding antibodies to the placebo arm is equal in magnitude to that of\nsubtracting antibodies from the vaccine arm, there are two versions of $p$. We\nfocus on the case when the placebo is unlikely to induce needed antibodies, and\nin that case if a standard assumption (given confounders, potential mediators\nand potential outcomes are independent) is true, only one version of $p$ is\nidentifiable, and if not neither is identifiable. We propose alternatives for\nidentifying and estimating the other version of $p$, without making the\nstandard independence assumption and instead experimentally modeling to\nidentify the formerly cross-world quantity. First, a three arm trial with the\nextra arm being passive immunization (administering monoclonal antibodies), and\nusing a model of antibody level amongst vaccinees. Second, combining\ninformation from a placebo-controlled vaccine trial with a placebo-controlled\npassive immunization trial.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 1697177,
        "score": 7.3538103103637695
    },
    {
        "title": "The efficacy of antiviral drug, HIV viral load and the immune response",
        "paperAbstract": "  Developing antiviral drugs is an exigent task since viruses mutate to\novercome the effect of antiviral drugs. As a result, the efficacy of most\nantiviral drugs is short-lived. To include this effect, we modify the Neumann\nand Dahari model. Considering the fact that the efficacy of the antiviral drug\nvaries in time, the differential equations introduced in the previous model\nsystems are rewritten to study the correlation between the viral load and\nantiviral drug. The effect of antiviral drug that either prevents infection or\nstops the production of a virus is explored. First, the efficacy of the drug is\nconsidered to decreases monotonously as time progresses. In this case, our\nresult depicts that when the efficacy of the drug is low, the viral load\ndecreases and increases back in time revealing the effect of the antiviral\ndrugs is short-lived. On the other hand, for the antiviral drug with high\nefficacy, the viral load, as well as the number of infected cells, monotonously\ndecreases while the number of uninfected cells increases. The dependence of the\ncritical drug efficacy on time is also explored. Moreover, the correlation\nbetween viral load, the antiviral drug, and CTL response is also explored. In\nthis case, not only the dependence for the basic reproduction ratio on the\nmodel parameters is explored but also we analyze the critical drug efficacy as\na function of time. We show that the term related to the basic reproduction\nratio increases when the CTL response step up. A simple analytically solvable\nmathematical model is also presented to analyze the correlation between viral\nload and antiviral drugs.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 1414155,
        "score": 7.243921756744385
    },
    {
        "title": "The shark teeth is a topological IFS-attractor",
        "paperAbstract": "  We show that the space called shark teeth is a topological IFS-attractor,\nthat is for every open cover of $X\u003d\\bigcup_{i\u003d1}^nf_i(X)$, its image under\nevery suitable large composition from the family of continuous functions\n$\\{f_1,...,f_n\\}$ lies in some set from the cover. In particular, there exists\na space which is not homeomorphic to any IFS-attractor but is a topological\nIFS-attractor.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 431760,
        "score": 7.218331336975098
    },
    {
        "title": "Shark skin effect in creeping films",
        "paperAbstract": "  If a body in a stream is provided with small ridges aligned in the local flow\ndirection, a remarkable drag reduction can be reached under turbulent flow\nconditions. This surprising phenomenon is called the \u0027shark skin effect\u0027. We\ndemonstrate, that a reduction of resistance can also be reached in creeping\nflows if the ridges are aligned perpendicular to the flow direction. We\nespecially consider in gravity-driven film flows the effect of the bottom\ntopography on the mean transport velocity.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 2197533,
        "score": 7.149975776672363
    },
    {
        "title": "Dynamical Characterization of Antiviral Effects in COVID-19",
        "paperAbstract": "  Mathematical models describing SARS-CoV-2 dynamics and the corresponding\nimmune responses in patients with COVID-19 can be critical to evaluate possible\nclinical outcomes of antiviral treatments. In this work, based on the concept\nof virus spreadability in the host, antiviral effectiveness thresholds are\ndetermined to establish whether or not a treatment will be able to clear the\ninfection. In addition, the virus dynamic in the host -- including the\ntime-to-peak and the final monotonically decreasing behavior -- is chracterized\nas a function of the treatment initial time. Simulation results, based on nine\nreal patient data, show the potential clinical benefits of a treatment\nclassification according to patient critical parameters. This study is aimed at\npaving the way for the different antivirals being developed to tackle\nSARS-CoV-2.\n",
        "query": "Shark antibodies antiviral therapies",
        "docId": 1403463,
        "score": 6.86720085144043
    },
    {
        "title": "Logistic forecasting of GDP competitiveness",
        "paperAbstract": "  The GDP growth of national economies is modelled by the logistic function.\nApplying it on the GDP data of the World Bank till the year 2020, we forecast\nthe outcome of the competitive GDP growth of Japan, Germany, UK and India, all\nof whose current GDPs are very close to one another. Fulfilling one of the\npredictions, in 2022 the GDP of India has indeed overtaken the GDP of UK. Our\noverall forecast is that by 2047, the GDP of India will be greater than that of\nthe other three countries. We argue that when trade saturates, large and\npopulous countries (like India) have the benefit of high domestic consumption\nto propel their GDP growth.\n",
        "query": "what is CPI and GDP",
        "docId": 1742031,
        "score": 8.809118270874023
    },
    {
        "title": "Global dynamics of GDP and trade",
        "paperAbstract": "  We use the logistic equation to model the dynamics of the GDP and the trade\nof the six countries with the highest GDP in the world, namely, USA, China,\nJapan, Germany, UK and India. From the modelling of the economic data, which\nare made available by the World Bank, we predict the maximum values of the\ngrowth of GDP and trade, as well as the duration over which exponential growth\ncan be sustained. We set up the correlated growth of GDP and trade as the phase\nsolutions of an autonomous second-order dynamical system. GDP and trade are\nrelated to each other by a power law, whose exponent seems to differentiate the\nsix national economies into two types. Under conducive conditions for economic\ngrowth, our conclusions have general validity.\n",
        "query": "what is CPI and GDP",
        "docId": 1528083,
        "score": 8.168062210083008
    },
    {
        "title": "GDP growth rate and population",
        "paperAbstract": "  Real GDP growth rate in developed countries is found to be a sum of two\nterms. The first term is the reciprocal value of the duration of the period of\nmean income growth with work experience, Tcr. The current value of Tcr in the\nUSA is 40 years. The second term is inherently related to population and\ndefined by the relative change in the number of people with a specific age (9\nyears in the USA), (1/2)*dN9(t) /N9(t), where N9(t) is the number of\n9-year-olds at time t. The Tcr grows as the square root of real GDP per capita.\nHence, evolution of real GDP is defined by only one parameter - the number of\npeople of the specific age. Predictions for the USA, the UK, and France are\npresented and discussed. A similar relationship is derived for real GDP per\ncapita. Annual increment of GDP per capita is also a combination of economic\ntrend term and the same specific age population term. The economic trend term\nduring last 55 years is equal to $400 (2002 US dollars) divided by the attained\nlevel of real GDP per capita. Thus, the economic trend term has an asymptotic\nvalue of zero. Inversion of the measured GDP values is used to recover the\ncorresponding change of the specific age population between 1955 and 2003. The\npopulation recovery method based on GDP potentially is of a higher accuracy\nthan routine censuses.\n",
        "query": "what is CPI and GDP",
        "docId": 93477,
        "score": 8.030464172363281
    },
    {
        "title": "Predicting China\u0027s CPI by Scanner Big Data",
        "paperAbstract": "  Scanner big data has potential to construct Consumer Price Index (CPI). This\nwork utilizes the scanner data of supermarket retail sales, which are provided\nby China Ant Business Alliance (CAA), to construct the Scanner-data Food\nConsumer Price Index (S-FCPI) in China, and the index reliability is verified\nby other macro indicators, especially by China\u0027s CPI. And not only that, we\nbuild multiple machine learning models based on S-FCPI to quantitatively\npredict the CPI growth rate in months, and qualitatively predict those\ndirections and levels. The prediction models achieve much better performance\nthan the traditional time series models in existing research. This work paves\nthe way to construct and predict price indexes through using scanner big data\nin China. S-FCPI can not only reflect the changes of goods prices in higher\nfrequency and wider geographic dimension than CPI, but also provide a new\nperspective for monitoring macroeconomic operation, predicting inflation and\nunderstanding other economic issues, which is beneficial supplement to China\u0027s\nCPI.\n",
        "query": "what is CPI and GDP",
        "docId": 1755547,
        "score": 7.8777079582214355
    },
    {
        "title": "Research on CPI Prediction Based on Natural Language Processing",
        "paperAbstract": "  In the past, the seed keywords for CPI prediction were often selected based\non empirical summaries of research and literature studies, which were prone to\nselect omitted and invalid variables. In this paper, we design a keyword\nexpansion technique for CPI prediction based on the cutting-edge NLP model,\nPANGU. We improve the CPI prediction ability using the corresponding web search\nindex. Compared with the unsupervised pre-training and supervised downstream\nfine-tuning natural language processing models such as BERT and NEZHA, the\nPANGU model can be expanded to obtain more reliable CPI-generated keywords by\nits excellent zero-sample learning capability without the limitation of the\ndownstream fine-tuning data set. Finally, this paper empirically tests the\nkeyword prediction ability obtained by this keyword expansion method with\nhistorical CPI data.\n",
        "query": "what is CPI and GDP",
        "docId": 1805463,
        "score": 7.722714900970459
    },
    {
        "title": "The energy representation of world GDP",
        "paperAbstract": "  The dependence of world GDP on current energy consumption and total energy\nproduced over the previous period and materialized in the form of production\ninfrastructure is studied. The dependence describes empirical data with high\naccuracy over the entire observation interval 1965-2018.\n",
        "query": "what is CPI and GDP",
        "docId": 1302452,
        "score": 7.617264747619629
    },
    {
        "title": "Why is GDP growth linear?",
        "paperAbstract": "  In many European countries the growth of the real GDP per capita has been\nlinear since 1950. An explanation for this linearity is still missing. We\npropose that in artificial intelligence we may find models for a linear growth\nof performance. We also discuss possible consequences of the fact that in\nsystems with linear growth the percentage growth goes to zero.\n",
        "query": "what is CPI and GDP",
        "docId": 650902,
        "score": 7.356594085693359
    },
    {
        "title": "Forecasting CPI Inflation Components with Hierarchical Recurrent Neural\n  Networks",
        "paperAbstract": "  We present a hierarchical architecture based on Recurrent Neural Networks\n(RNNs) for predicting disaggregated inflation components of the Consumer Price\nIndex (CPI). While the majority of existing research is focused mainly on\npredicting the inflation headline, many economic and financial entities are\nmore interested in its partial disaggregated components. To this end, we\ndeveloped the novel Hierarchical Recurrent Neural Network (HRNN) model that\nutilizes information from higher levels in the CPI hierarchy to improve\npredictions at the more volatile lower levels. Our evaluations, based on a\nlarge data-set from the US CPI-U index, indicate that the HRNN model\nsignificantly outperforms a vast array of well-known inflation prediction\nbaselines.\n",
        "query": "what is CPI and GDP",
        "docId": 1380668,
        "score": 7.006938934326172
    },
    {
        "title": "Nowcasting the Portuguese GDP with Monthly Data",
        "paperAbstract": "  In this article, we present a method to forecast the Portuguese gross\ndomestic product (GDP) in each current quarter (nowcasting). It combines bridge\nequations of the real GDP on readily available monthly data like the Economic\nSentiment Indicator (ESI), industrial production index, cement sales or exports\nand imports, with forecasts for the jagged missing values computed with the\nwell-known Hodrick and Prescott (HP) filter. As shown, this simple multivariate\napproach can perform as well as a Targeted Diffusion Index (TDI) model and\nslightly better than the univariate Theta method in terms of out-of-sample mean\nerrors.\n",
        "query": "what is CPI and GDP",
        "docId": 1667243,
        "score": 6.864195823669434
    },
    {
        "title": "GDP Forecasting using Payments Transaction Data",
        "paperAbstract": "  UK GDP data is published with a lag time of more than a month and it is often\nadjusted for prior periods. This paper contemplates breaking away from the\nhistoric GDP measure to a more dynamic method using Bank Account, Cheque and\nCredit Card payment transactions as possible predictors for faster and real\ntime measure of GDP value. Historic timeseries data available from various\npublic domain for various payment types, values, volume and nominal UK GDP was\nused for this analysis. Low Value Payments was selected for simple Ordinary\nLeast Square Simple Linear Regression with mixed results around explanatory\npower of the model and reliability measured through residuals distribution and\nvariance. Future research could potentially expand this work using datasets\nsplit by period of economic shocks to further test the OLS method or explore\none of General Least Square method or an autoregression on GDP timeseries\nitself.\n",
        "query": "what is CPI and GDP",
        "docId": 1410220,
        "score": 6.858778476715088
    },
    {
        "title": "Fluctuation Domains in Adaptive Evolution",
        "paperAbstract": "  We derive an expression for the variation between parallel trajectories in\nphenotypic evolution, extending the well known result that predicts the mean\nevolutionary path in adaptive dynamics or quantitative genetics. We show how\nthis expression gives rise to the notion of fluctuation domains - parts of the\nfitness landscape where the rate of evolution is very predictable (due to\nfluctuation dissipation) and parts where it is highly variable (due to\nfluctuation enhancement). These fluctuation domains are determined by the\ncurvature of the fitness landscape. Regions of the fitness landscape with\npositive curvature, such as adaptive valleys or branching points, experience\nenhancement. Regions with negative curvature, such as adaptive peaks,\nexperience dissipation. We explore these dynamics in the ecological scenarios\nof implicit and explicit competition for a limiting resource.\n",
        "query": "genomics of adaptive evolution",
        "docId": 186173,
        "score": 7.617269515991211
    },
    {
        "title": "Rate of Adaptive Evolution under Blending Inheritance",
        "paperAbstract": "  In a population of size N, adaptive evolution is 2N times faster under\nMendelian inheritance than the rate implied by Victorian theories of heredity\nand evolution.\n",
        "query": "genomics of adaptive evolution",
        "docId": 612279,
        "score": 7.448058128356934
    },
    {
        "title": "Adaptive evolution of molecular phenotypes",
        "paperAbstract": "  Molecular phenotypes link genomic information with organismic functions,\nfitness, and evolution. Quantitative traits are complex phenotypes that depend\non multiple genomic loci. In this paper, we study the adaptive evolution of a\nquantitative trait under time-dependent selection, which arises from\nenvironmental changes or through fitness interactions with other co-evolving\nphenotypes. We analyze a model of trait evolution under mutations and genetic\ndrift in a single-peak fitness seascape. The fitness peak performs a\nconstrained random walk in the trait amplitude, which determines the\ntime-dependent trait optimum in a given population. We derive analytical\nexpressions for the distribution of the time-dependent trait divergence between\npopulations and of the trait diversity within populations. Based on this\nsolution, we develop a method to infer adaptive evolution of quantitative\ntraits. Specifically, we show that the ratio of the average trait divergence\nand the diversity is a universal function of evolutionary time, which predicts\nthe stabilizing strength and the driving rate of the fitness seascape. From an\ninformation-theoretic point of view, this function measures the\nmacro-evolutionary entropy in a population ensemble, which determines the\npredictability of the evolutionary process. Our solution also quantifies two\nkey characteristics of adapting populations: the cumulative fitness flux, which\nmeasures the total amount of adaptation, and the adaptive load, which is the\nfitness cost due to a population\u0027s lag behind the fitness peak.\n",
        "query": "genomics of adaptive evolution",
        "docId": 506702,
        "score": 7.346874237060547
    },
    {
        "title": "Adaptive evolution of hybrid bacteria by horizontal gene transfer",
        "paperAbstract": "  Horizontal gene transfer is an important factor in bacterial evolution that\ncan act across species boundaries. Yet, we know little about rate and genomic\ntargets of cross-lineage gene transfer, and about its effects on the recipient\norganism\u0027s physiology and fitness. Here, we address these questions in a\nparallel evolution experiment with two Bacillus subtilis lineages of 7%\nsequence divergence. We observe rapid evolution of hybrid organisms: gene\ntransfer swaps ~12% of the core genome in just 200 generations, and 60% of core\ngenes are replaced in at least one population. By genomics, transcriptomics,\nfitness assays, and statistical modeling, we show that transfer generates\nadaptive evolution and functional alterations in hybrids. Specifically, our\nexperiments reveal a strong, repeatable fitness increase of evolved populations\nin the stationary growth phase. By genomic analysis of the transfer statistics\nacross replicate populations, we infer that selection on HGT has a broad\ngenetic basis: 40% of the observed transfers are adaptive. At the level of\nfunctional gene networks, we find signatures of negative and positive\nselection, consistent with hybrid incompatibilities and adaptive evolution of\nnetwork functions. Our results suggest that gene transfer navigates a complex\ncross-lineage fitness landscape, bridging epistatic barriers along multiple\nhigh-fitness paths.\n",
        "query": "genomics of adaptive evolution",
        "docId": 1275885,
        "score": 6.764293670654297
    },
    {
        "title": "Population genomics of intrapatient HIV-1 evolution",
        "paperAbstract": "  Many microbial populations rapidly adapt to changing environments with\nmultiple variants competing for survival. To quantify such complex evolutionary\ndynamics in vivo, time resolved and genome wide data including rare variants\nare essential. We performed whole-genome deep sequencing of HIV-1 populations\nin 9 untreated patients, with 6-12 longitudinal samples per patient spanning\n5-8 years of infection. We show that patterns of minor diversity are\nreproducible between patients and mirror global HIV-1 diversity, suggesting a\nuniversal landscape of fitness costs that control diversity. Reversions towards\nthe ancestral HIV-1 sequence are observed throughout infection and account for\nalmost one third of all sequence changes. Reversion rates depend strongly on\nconservation. Frequent recombination limits linkage disequilibrium to about\n100bp in most of the genome, but strong hitch-hiking due to short range linkage\nlimits diversity.\n",
        "query": "genomics of adaptive evolution",
        "docId": 657122,
        "score": 6.729079246520996
    },
    {
        "title": "Taking Quantitative Genomics into the Wild",
        "paperAbstract": "  A key goal in studies of ecology and evolution is understanding the causes of\nphenotypic diversity in nature. Most traits of interest, such as those relating\nto morphology, life-history, immunity and behaviour are quantitative, and\nphenotypic variation is driven by the cumulative effects of genetic and\nenvironmental variation. The field of quantitative genetics aims to quantify\nthe additive genetic component of this trait variance (i.e. the\n\"heritability\"), often with the underlying assumption that trait variance is\ndriven by many loci of infinitesimal effects throughout the genome. This\napproach allows us to understand the evolutionary potential of natural\npopulations and can be extended to examine the genetic covariation with fitness\nto predict responses to selection. Therefore, quantitative genetic studies are\nfundamental to understanding evolution in the wild. Over the last two decades,\nthere has been a wealth of studies investigating trait heritabilities and\ngenetic correlations, but these were initially limited to long-term studies of\npedigreed populations or common-garden experiments. However, genomic\ntechnologies have since allowed quantitative genetic studies in a more diverse\nrange of wild systems and has increased the opportunities for addressing\noutstanding questions in ecology and evolution. In particular, genomic studies\ncan uncover the genetic basis of fitness-related quantitative traits, allowing\na better understanding of their evolutionary dynamics. We organised this\nspecial issue to highlight new work and review recent advances at the cutting\nedge of \"Wild Quantitative Genomics\". In this Editorial, we will present some\nhistory of wild quantitative genetic and genomic studies, before discussing the\nmain themes in the papers published in this special issue and highlighting the\nfuture outlook of this dynamic field.\n",
        "query": "genomics of adaptive evolution",
        "docId": 1718782,
        "score": 6.640900135040283
    },
    {
        "title": "Revolutionizing Genomics with Reinforcement Learning Techniques",
        "paperAbstract": "  In recent years, Reinforcement Learning (RL) has emerged as a powerful tool\nfor solving a wide range of problems, including decision-making and genomics.\nThe exponential growth of raw genomic data over the past two decades has\nexceeded the capacity of manual analysis, leading to a growing interest in\nautomatic data analysis and processing. RL algorithms are capable of learning\nfrom experience with minimal human supervision, making them well-suited for\ngenomic data analysis and interpretation. One of the key benefits of using RL\nis the reduced cost associated with collecting labeled training data, which is\nrequired for supervised learning. While there have been numerous studies\nexamining the applications of Machine Learning (ML) in genomics, this survey\nfocuses exclusively on the use of RL in various genomics research fields,\nincluding gene regulatory networks (GRNs), genome assembly, and sequence\nalignment. We present a comprehensive technical overview of existing studies on\nthe application of RL in genomics, highlighting the strengths and limitations\nof these approaches. We then discuss potential research directions that are\nworthy of future exploration, including the development of more sophisticated\nreward functions as RL heavily depends on the accuracy of the reward function,\nthe integration of RL with other machine learning techniques, and the\napplication of RL to new and emerging areas in genomics research. Finally, we\npresent our findings and conclude by summarizing the current state of the field\nand the future outlook for RL in genomics.\n",
        "query": "genomics of adaptive evolution",
        "docId": 1798202,
        "score": 6.636112213134766
    },
    {
        "title": "GenoML: Automated Machine Learning for Genomics",
        "paperAbstract": "  GenoML is a Python package automating machine learning workflows for genomics\n(genetics and multi-omics) with an open science philosophy. Genomics data\nrequire significant domain expertise to clean, pre-process, harmonize and\nperform quality control of the data. Furthermore, tuning, validation, and\ninterpretation involve taking into account the biology and possibly the\nlimitations of the underlying data collection, protocols, and technology.\nGenoML\u0027s mission is to bring machine learning for genomics and clinical data to\nnon-experts by developing an easy-to-use tool that automates the full\ndevelopment, evaluation, and deployment process. Emphasis is put on open\nscience to make workflows easily accessible, replicable, and transferable\nwithin the scientific community. Source code and documentation is available at\nhttps://genoml.com.\n",
        "query": "genomics of adaptive evolution",
        "docId": 1433366,
        "score": 6.590704917907715
    },
    {
        "title": "Adaptive ratchets and the evolution of molecular complexity",
        "paperAbstract": "  Biological systems have evolved to amazingly complex states, yet we do not\nunderstand in general how evolution operates to generate increasing genetic and\nfunctional complexity. Molecular recognition sites are short genome segments or\npeptides binding a cognate recognition target of sufficient sequence\nsimilarity. Such sites are simple, ubiquitous modules of sequence information,\ncellular function, and evolution. Here we show that recognition sites, if\ncoupled to a time-dependent target, can rapidly evolve to complex states with\nlarger code length and smaller coding density than sites recognising a static\ntarget. The underlying fitness model contains selection for recognition, which\ndepends on the sequence similarity between site and target, and a uniform cost\nper unit of code length. Site sequences are shown to evolve in a specific\nadaptive ratchet, which produces selection of different strength for code\nextensions and compressions. Ratchet evolution increases the adaptive width of\nevolved sites, accelerating the adaptation to moving targets and facilitating\nrefinement and innovation of recognition functions. We apply these results to\nthe recognition of fast-evolving antigens by the human immune system. Our\nanalysis shows how molecular complexity can evolve as a collateral to selection\nfor function in a dynamic environment.\n",
        "query": "genomics of adaptive evolution",
        "docId": 1564084,
        "score": 6.5611724853515625
    },
    {
        "title": "Interpretable Machine Learning for Genomics",
        "paperAbstract": "  High-throughput technologies such as next generation sequencing allow\nbiologists to observe cell function with unprecedented resolution, but the\nresulting datasets are too large and complicated for humans to understand\nwithout the aid of advanced statistical methods. Machine learning (ML)\nalgorithms, which are designed to automatically find patterns in data, are well\nsuited to this task. Yet these models are often so complex as to be opaque,\nleaving researchers with few clues about underlying mechanisms. Interpretable\nmachine learning (iML) is a burgeoning subdiscipline of computational\nstatistics devoted to making the predictions of ML models more intelligible to\nend users. This article is a gentle and critical introduction to iML, with an\nemphasis on genomic applications. I define relevant concepts, motivate leading\nmethodologies, and provide a simple typology of existing approaches. I survey\nrecent examples of iML in genomics, demonstrating how such techniques are\nincreasingly integrated into research workflows. I argue that iML solutions are\nrequired to realize the promise of precision medicine. However, several open\nchallenges remain. I examine the limitations of current state of the art tools\nand propose a number of directions for future research. While the horizon for\niML in genomics is wide and bright, continued progress requires close\ncollaboration across disciplines.\n",
        "query": "genomics of adaptive evolution",
        "docId": 1541206,
        "score": 6.509003639221191
    },
    {
        "title": "Molecular Hydrogen in High-Velocity Clouds",
        "paperAbstract": "  We present Far Ultraviolet Spectroscopic Explorer (FUSE) observations of\ninterstellar molecular hydrogen (H_2) in two Galactic high-velocity clouds\n(HVCs). Molecular hydrogen absorption is detected in the Magellanic Stream\n(abundance ~0.3 solar) toward the Seyfert galaxy Fairall 9 in the lowest three\nrotational states (J\u003d0-2) at v(LSR)\u003d+190 km/s, yielding a total H_2 column\ndensity of log N(H_2)\u003d16.40(+0.26)(-0.53). In contrast, no H_2 absorption is\nseen in the high-velocity cloud Complex C (abundance ~0.1 solar) toward the\nquasar PG 1259+593 (log N(H_2)\u003c13.96 at v(LSR)\u003d-130 km/s) although both HVCs\nhave similar HI column densities on the order of log N(HI)~20. Weak H_2\nabsorption is detected in the Intermediate-Velocity Arch (IV Arch; abundance\n\\~1.0 solar) toward PG 1259+593 (log N(H_2)\u003d14.10(+0.21)(-0.44) at v(LSR)\u003d-55\nkm/s and log N(HI)\u003d19.5). It thus appears that metal- and dust-poor halo clouds\nlike Complex C are not able to form and maintain widely distributed H_2,\nwhereas metal and dust-rich halo clouds like the IV Arch can maintain H_2 even\nat low HI column densities.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 1826429,
        "score": 11.229143142700195
    },
    {
        "title": "The Formation of Molecular Clouds",
        "paperAbstract": "  In a recent paper, Elmegreen (2000) has made a cogent case, from an\nobservational point of view, that the lifetimes of molecular clouds are\ncomparable to their dynamical timescales. If so, this has important\nimplications for the mechanisms by which molecular clouds form. In particular\nwe consider the hypothesis that molecular clouds may form not by {\\it in situ}\ncooling of atomic gas, but rather by the agglomeration of the dense phase of\nthe interstellar medium (ISM), much, if not most, of which is already in\nmolecular form.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 1824309,
        "score": 10.456754684448242
    },
    {
        "title": "Turbulent molecular clouds",
        "paperAbstract": "  Stars form within molecular clouds but our understanding of this fundamental\nprocess remains hampered by the complexity of the physics that drives their\nevolution. We review our observational and theoretical knowledge of molecular\nclouds trying to confront the two approaches wherever possible. After a broad\npresentation of the cold interstellar medium and molecular clouds, we emphasize\nthe dynamical processes with special focus to turbulence and its impact on\ncloud evolution. We then review our knowledge of the velocity, density and\nmagnetic fields. We end by openings towards new chemistry models and the links\nbetween molecular cloud structure and star--formation rates.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 382883,
        "score": 10.11113166809082
    },
    {
        "title": "A FUSE Survey of Interstellar Molecular Hydrogen in Translucent Clouds",
        "paperAbstract": "  We report the first ensemble results from the FUSE survey of molecular\nhydrogen in lines of sight with A_V $\\gtrsim$ 1 mag. We have developed\ntechniques for fitting computed profiles to the low-J lines of H2, and thus\ndetermining column densities for J \u003d 0 and J \u003d 1, which contain $\\gtrsim$99% of\nthe total H2. From these column densities and ancillary data we have derived\nthe total H2 column densities, hydrogen molecular fractions, and kinetic\ntemperatures for 23 lines of sight. This is the first significant sample of\nmolecular hydrogen column densities of 10^21 cm^-2, measured through UV\nabsorption bands. We have also compiled a set of extinction data for these\nlines of sight, which sample a wide range of environments. We have searched for\ncorrelations of our H2-related quantities with previously published column\ndensities of other molecules and extinction parameters. We find strong\ncorrelations between H2 and molecules such as CH, CN, and CO, in general\nagreement with predictions of chemical models. We also find the expected\ncorrelations between hydrogen molecular fraction and various density indicators\nsuch as kinetic temperature, CN abundance, the steepness of the far-UV\nextinction rise, and the width of the 2175A bump. Despite the relatively large\nmolecular fractions, we do not see the values greater than 0.8 expected in\ntranslucent clouds. With the exception of a few lines of sight, we see little\nevidence for the presence of individual translucent clouds in our sample. We\nconclude that most of the lines of sight are actually composed of two or more\ndiffuse clouds similar to those found toward targets like zeta Oph. We suggest\na modification in terminology to distinguish between a \"translucent line of\nsight\" and a \"translucent cloud.\"\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 1830582,
        "score": 10.061200141906738
    },
    {
        "title": "Observing molecular hydrogen clouds and dark massive objects in galactic\n  halos",
        "paperAbstract": "  Molecular hydrogen clouds can contribute substantially to the galactic halo\u003c\ndark matter and may lead to the birth of massive halo objects (MHOs) observed\nindirectly by microlensing. We present a method to detect these molecular\nclouds in the halo of M31 using the Doppler shift effect. We also consider the\npossibility to directly observe MHOs in the halo of M31 via their infrared\nemission.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 1873366,
        "score": 9.999336242675781
    },
    {
        "title": "Directional Radiation and Photodissociation Regions in Molecular\n  Hydrogen Clouds",
        "paperAbstract": "  Some astrophysical observations of molecular hydrogen point to a broadening\nof the velocity distribution for molecules at excited rotational levels. This\neffect is observed in both Galactic and high redshift clouds. Analysis of H_2,\nHD, and CI absorption lines has revealed the broadening effect in the\nabsorption system of QSO 1232+082 (z_{abs}\u003d2.33771). We analyze line broadening\nmechanisms by considering in detail the transfer of ultraviolet radiation (in\nthe resonance lines of the Lyman and Werner H_2 molecular bands) for various\nvelocity distributions at excited rotational levels. The mechanism we suggest\nincludes the saturation of the lines that populate excited rotational levels\n(radiative pumping) and manifests itself most clearly in the case of\ndirectional radiation in the medium. Based on the calculated structure of a\nmolecular hydrogen cloud in rotational level populations, we have considered an\nadditional mechanism that takes into account the presence of a\nphotodissociation region. Note that disregarding the broadening effects we\ninvestigated can lead to a significant systematic error when the data are\nprocessed.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 140690,
        "score": 9.877447128295898
    },
    {
        "title": "High Altitude Molecular Clouds",
        "paperAbstract": "  A population of molecular clouds with a significantly greater scale height\nthan that of Giant Molecular Clouds has been identified by examining maps of\nthe latitude distribution of the $^{12}CO(1-0)$ emission in the first quadrant\nof the Galaxy. These clouds are found by identifying emission more than 2.6\ntimes the scale-height away from the galactic midplane (centroid of CO\nemission) at the tangent points. Since the distance to the tangent points is\nknown, we know the height and the sizes of these clouds. They are smaller and\nfainter than the GMCs and do not seem to be gravitationally bound. These clouds\nhave properties similar to the high latitude clouds in the solar neighborhood.\nAlthough they lie outside the molecular cloud layer, the high altitude clouds\nare well within the HI layer in the Galaxy and coincide with distinct peaks in\nthe HI distribution. These clouds represent a galaxy wide population of small\nmolecular clouds having a larger scale height. They may be clouds in transition\nbetween molecular and atomic phases.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 1872478,
        "score": 9.559792518615723
    },
    {
        "title": "Supernovae in Molecular Clouds",
        "paperAbstract": "  Supernovae are expected to occur near the molecular material in which the\nmassive progenitor star was born, except in cases where the photoionizing\nradiation and winds from the progenitor star and its neighbors have cleared out\na region. The clumpy structure in molecular clouds is crucial for the remnant\nevolution; the supernova shock front can become radiative in the interclump\nmedium and the radiative shell then collides with molecular clumps. The\ninteraction is relevant to a number of phenomena: the hydrodynamics of a\nmagnetically supported dense shell interacting with molecular clumps; the\nmolecular emission from shock waves, including the production of the OH 1720\nMHz maser line; the relativistic particle emission, including radio synchrotron\nand gamma-ray emission, from the dense radiative shell; and the possible\ngravitational instability of a compressed clump.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 1822015,
        "score": 9.478601455688477
    },
    {
        "title": "Dynamics of Molecular Clouds",
        "paperAbstract": "  We further develop the model of molecular cloud fragmentation introduced in\nField, Blackman and Keto (2007; FBK). We show that external pressure acting on\nfragments establishes a scale-dependent critical mass. Fragments with masses\nless than the critical value are confined largely by pressure, while those with\nmasses greater than or equal to the critical value collapse under self\ngravitation. Both types of fragments are commonly observed. Without specifying\nthe source of the external pressure, and without assuming any other scaling\nrelations, we predict the power - law index in the relation between the rms\nvelocity of supersonic motions and the size of fragments . We then investigate\nthe possibility that the external pressure is due to the kinetic energy of H\natoms released by photodissociation of hydrogen molecules in the fragment. This\ncan account approximately for the observed values of external pressure and two\nadditional observations: the value of the scaling coefficient in the power law\nmentioned above, and the observation of outflowing atomic hydrogen around\nmolecular clouds. A further prediction is HI at fragment edges with column\ndensities of order 1E20 per sq. cm and velocities of a few km/s that should be\ndetectable with high resolution 21 cm observations. Finally, we predict the\nmagnitude of the coefficient of dissipation in the observed supersonic flows.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 120743,
        "score": 9.438421249389648
    },
    {
        "title": "TURBULENCE IN MOLECULAR CLOUDS",
        "paperAbstract": "  We generate random Gaussian turbulent velocity fields with a Kolmogorov\nspectrum and use these to obtain synthetic line-of-sight velocity profiles. The\nprofiles are found to be similar to line profiles observed in molecular clouds.\nWe suggest methods for analysing measured line profiles to test whether they\nmight arise from Gaussian Kolmogorov turbulence.\n",
        "query": "Molecular hydrogen clouds ",
        "docId": 1873321,
        "score": 9.420056343078613
    },
    {
        "title": "A Common Gene Expression Signature Analysis Method for Multiple Types of\n  Cancer",
        "paperAbstract": "  Mining gene expression profiles has proven valuable for identifying\nsignatures serving as surrogates of cancer phenotypes. However, the\nsimilarities of such signatures across different cancer types have not been\nstrong enough to conclude that they represent a universal biological mechanism\nshared among multiple cancer types. Here we describe a network-based approach\nthat explores gene-to-gene connections in multiple cancer datasets while\nmaximizing the overall association of the subnetwork with clinical outcomes.\nWith the dataset of The Cancer Genome Atlas (TCGA), we studied the\ncharacteristics of common gene expression of three types of cancers: Rectum\nadenocarcinoma (READ), Breast invasive carcinoma (BRCA) and Colon\nadenocarcinoma (COAD). By analyzing several pairs of highly correlated genes\nafter filtering and clustering work, we found that the co-expressed genes\nacross multiple types of cancers point to particular biological mechanisms\nrelated to cancer cell progression , suggesting that they represent important\nattributes of cancer in need of being elucidated for potential applications in\ndiagnostic, prognostic and therapeutic products applicable to multiple cancer\ntypes.\n",
        "query": "Types of cancer",
        "docId": 1224275,
        "score": 8.082043647766113
    },
    {
        "title": "Identify Statistical Similarities and Differences Between the Deadliest\n  Cancer Types Through Gene Expression",
        "paperAbstract": "  Prognostic genes have been well studied within each type of cancer. However,\ninvestigations of the similarities and differences across cancer types are\nrare. In view of the optimal course of treatment, the classification of cancers\ninto subtypes is critical to the diagnosis. We examined the properties in gene\nco-expression networks using a patient-to-patient correlation network analysis\nand a weighted gene correlation network analysis (WGCNA) for five cancer types\nusing data generated by UC Irvine. We further analyze and compare the degree,\ncentrality and betweenness of the network for each cancer type and apply a\nmultinomial logistic regression to identify the critical subset of genes. Given\nthe cancer types provided, our study presents a view of emergent similarities\nand differences across cancer types.\n",
        "query": "Types of cancer",
        "docId": 1100233,
        "score": 7.699305534362793
    },
    {
        "title": "OncoNetExplainer: Explainable Predictions of Cancer Types Based on Gene\n  Expression Data",
        "paperAbstract": "  The discovery of important biomarkers is a significant step towards\nunderstanding the molecular mechanisms of carcinogenesis; enabling accurate\ndiagnosis for, and prognosis of, a certain cancer type. Before recommending any\ndiagnosis, genomics data such as gene expressions(GE) and clinical outcomes\nneed to be analyzed. However, complex nature, high dimensionality, and\nheterogeneity in genomics data make the overall analysis challenging.\nConvolutional neural networks(CNN) have shown tremendous success in solving\nsuch problems. However, neural network models are perceived mostly as `black\nbox\u0027 methods because of their not well-understood internal functioning.\nHowever, interpretability is important to provide insights on why a given\ncancer case has a certain type. Besides, finding the most important biomarkers\ncan help in recommending more accurate treatments and drug repositioning. In\nthis paper, we propose a new approach called OncoNetExplainer to make\nexplainable predictions of cancer types based on GE data. We used genomics data\nabout 9,074 cancer patients covering 33 different cancer types from the\nPan-Cancer Atlas on which we trained CNN and VGG16 networks using\nguided-gradient class activation maps++(GradCAM++). Further, we generate\nclass-specific heat maps to identify significant biomarkers and computed\nfeature importance in terms of mean absolute impact to rank top genes across\nall the cancer types. Quantitative and qualitative analyses show that both\nmodels exhibit high confidence at predicting the cancer types correctly giving\nan average precision of 96.25%. To provide comparisons with the baselines, we\nidentified top genes, and cancer-specific driver genes using gradient boosted\ntrees and SHapley Additive exPlanations(SHAP). Finally, our findings were\nvalidated with the annotations provided by the TumorPortal.\n",
        "query": "Types of cancer",
        "docId": 1174207,
        "score": 7.474564552307129
    },
    {
        "title": "The Universality of Cancer",
        "paperAbstract": "  Cancer has been characterized as a constellation of hundreds of diseases\ndiffering in underlying mutations and depending on cellular environments.\nCarcinogenesis as a stochastic physical process has been studied for over sixty\nyears, but there is no accepted standard model. We show that the hazard rates\nof all cancers are characterized by a simple dynamic stochastic process on a\nhalf-line, with a universal linear restoring force balancing a universal simple\nBrownian motion starting from a universal initial distribution. Only a critical\nradius defining the transition from normal to tumorigenic genomes distinguishes\nbetween different cancer types when time is measured in cell--cycle units.\nReparametrizing to chronological time units introduces two additional\nparameters: the onset of cellular senescence with age and the time interval\nover which this cessation in replication takes place. This universality implies\nthat there may exist a finite separation between normal cells and tumorigenic\ncells in all tissue types that may be a viable target for both early detection\nand preventive therapy.\n",
        "query": "Types of cancer",
        "docId": 629041,
        "score": 7.351295471191406
    },
    {
        "title": "Dataset of Segmented Nuclei in Hematoxylin and Eosin Stained\n  Histopathology Images of 10 Cancer Types",
        "paperAbstract": "  The distribution and appearance of nuclei are essential markers for the\ndiagnosis and study of cancer. Despite the importance of nuclear morphology,\nthere is a lack of large scale, accurate, publicly accessible nucleus\nsegmentation data. To address this, we developed an analysis pipeline that\nsegments nuclei in whole slide tissue images from multiple cancer types with a\nquality control process. We have generated nucleus segmentation results in\n5,060 Whole Slide Tissue images from 10 cancer types in The Cancer Genome\nAtlas. One key component of our work is that we carried out a multi-level\nquality control process (WSI-level and image patch-level), to evaluate the\nquality of our segmentation results. The image patch-level quality control used\nmanual segmentation ground truth data from 1,356 sampled image patches. The\ndatasets we publish in this work consist of roughly 5 billion quality\ncontrolled nuclei from more than 5,060 TCGA WSIs from 10 different TCGA cancer\ntypes and 1,356 manually segmented TCGA image patches from the same 10 cancer\ntypes plus additional 4 cancer types. Data is available at\nhttps://doi.org/10.7937/tcia.2019.4a4dkp9u\n",
        "query": "Types of cancer",
        "docId": 1245336,
        "score": 7.295759201049805
    },
    {
        "title": "A Deep Autoencoder System for Differentiation of Cancer Types Based on\n  DNA Methylation State",
        "paperAbstract": "  A Deep Autoencoder based content retrieval algorithm is proposed for\nprediction and differentiation of cancer types based on the presence of\nepigenetic patterns of DNA methylation identified in genetic regions known as\nCpG islands. The developed deep learning system uses a CpG island state\nclassification sub-system to complete sets of missing/incomplete island data in\ngiven human cell lines, and is then pipelined with an intricate set of\nstatistical and signal processing methods to accurately predict the presence of\ncancer and further differentiate the type and cell of origin in the event of a\npositive result. The proposed system was trained with previously reported data\nderived from four case groups of cancer cell lines, achieving overall\nSensitivity of 88.24%, Specificity of 83.33%, Accuracy of 84.75% and Matthews\nCorrelation Coefficient of 0.687. The ability to predict and differentiate\ncancer types using epigenetic events as the identifying patterns was\ndemonstrated in previously reported data sets from breast, lung, lymphoblastic\nleukemia and urological cancer cell lines, allowing the pipelined system to be\nrobust and adjustable to other cancer cell lines or epigenetic events.\n",
        "query": "Types of cancer",
        "docId": 1032430,
        "score": 7.2250823974609375
    },
    {
        "title": "Using the \"Hidden\" Genome to Improve Classification of Cancer Types",
        "paperAbstract": "  It is increasingly common clinically for cancer specimens to be examined\nusing techniques that identify somatic mutations. In principle these mutational\nprofiles can be used to diagnose the tissue of origin, a critical task for the\n3-5% of tumors that have an unknown primary site. Diagnosis of primary site is\nalso critical for screening tests that employ circulating DNA. However, most\nmutations observed in any new tumor are very rarely occurring mutations, and\nindeed the preponderance of these may never have been observed in any previous\nrecorded tumor. To create a viable diagnostic tool we need to harness the\ninformation content in this \"hidden genome\" of variants for which no direct\ninformation is available. To accomplish this we propose a multi-level\nmeta-feature regression to extract the critical information from rare variants\nin the training data in a way that permits us to also extract diagnostic\ninformation from any previously unobserved variants in the new tumor sample. A\nscalable implementation of the model is obtained by combining a\nhigh-dimensional feature screening approach with a group-lasso penalized\nmaximum likelihood approach based on an equivalent mixed-effect representation\nof the multilevel model. We apply the method to the Cancer Genome Atlas\nwhole-exome sequencing data set including 3702 tumor samples across 7 common\ncancer sites. Results show that our multi-level approach can harness\nsubstantial diagnostic information from the hidden genome.\n",
        "query": "Types of cancer",
        "docId": 1290574,
        "score": 7.046535491943359
    },
    {
        "title": "Evolving Nano Particle Cancer Treatments with Multiple Particle Types",
        "paperAbstract": "  Evolutionary algorithms have long been used for optimization problems where\nthe appropriate size of solutions is unclear a priori. The applicability of\nthis methodology is here investigated on the problem of designing a\nnano-particle (NP) based drug delivery system targeting cancer tumours.\nUtilizing a treatment comprising of multiple types of NPs is expected to be\nmore effective due to the higher complexity of the treatment. This paper begins\nby utilizing the well-known NK model to explore the effects of fitness\nlandscape ruggedness upon the evolution of genome length and, hence, solution\ncomplexity. The size of a novel sequence and the absence or presence of\nsequence deletion are also considered. Results show that whilst landscape\nruggedness can alter the dynamics of the process, it does not hinder the\nevolution of genome length. These findings are then explored within the\naforementioned real-world problem. In the first known instance, treatments with\nmultiple types of NPs are used simultaneously, via an agent-based open source\nphysics-based cell simulator. The results suggest that utilizing multiple types\nof NPs is more efficient when the solution space is explored with the\nevolutionary techniques under a predefined computational budget.\n",
        "query": "Types of cancer",
        "docId": 1377723,
        "score": 6.982641220092773
    },
    {
        "title": "Noncoding RNAs and deep learning neural network discriminate\n  multi-cancer types",
        "paperAbstract": "  Detecting cancers at early stages can dramatically reduce mortality rates.\nTherefore, practical cancer screening at the population level is needed. Here,\nwe develop a comprehensive detection system to classify all common cancer\ntypes. By integrating artificial intelligence deep learning neural network and\nnoncoding RNA biomarkers selected from massive data, our system can accurately\ndetect cancer vs healthy object with 96.3% of AUC of ROC (Area Under Curve of a\nReceiver Operating Characteristic curve). Intriguinely, with no more than 6\nbiomarkers, our approach can easily discriminate any individual cancer type vs\nnormal with 99% to 100% AUC. Furthermore, a comprehensive marker panel can\nsimultaneously multi-classify all common cancers with a stable 78% of accuracy\nat heterological cancerous tissues and conditions. This provides a valuable\nframework for large scale cancer screening. The AI models and plots of results\nwere available in https://combai.org/ai/cancerdetection/\n",
        "query": "Types of cancer",
        "docId": 1431324,
        "score": 6.981838226318359
    },
    {
        "title": "Deep learning-based survival prediction for multiple cancer types using\n  histopathology images",
        "paperAbstract": "  Prognostic information at diagnosis has important implications for cancer\ntreatment and monitoring. Although cancer staging, histopathological\nassessment, molecular features, and clinical variables can provide useful\nprognostic insights, improving risk stratification remains an active research\narea. We developed a deep learning system (DLS) to predict disease specific\nsurvival across 10 cancer types from The Cancer Genome Atlas (TCGA). We used a\nweakly-supervised approach without pixel-level annotations, and tested three\ndifferent survival loss functions. The DLS was developed using 9,086 slides\nfrom 3,664 cases and evaluated using 3,009 slides from 1,216 cases. In\nmultivariable Cox regression analysis of the combined cohort including all 10\ncancers, the DLS was significantly associated with disease specific survival\n(hazard ratio of 1.58, 95% CI 1.28-1.70, p\u003c0.0001) after adjusting for cancer\ntype, stage, age, and sex. In a per-cancer adjusted subanalysis, the DLS\nremained a significant predictor of survival in 5 of 10 cancer types. Compared\nto a baseline model including stage, age, and sex, the c-index of the model\ndemonstrated an absolute 3.7% improvement (95% CI 1.0-6.5) in the combined\ncohort. Additionally, our models stratified patients within individual cancer\nstages, particularly stage II (p\u003d0.025) and stage III (p\u003c0.001). By developing\nand evaluating prognostic models across multiple cancer types, this work\nrepresents one of the most comprehensive studies exploring the direct\nprediction of clinical outcomes using deep learning and histopathology images.\nOur analysis demonstrates the potential for this approach to provide prognostic\ninformation in multiple cancer types, and even within specific pathologic\nstages. However, given the relatively small number of clinical events, we\nobserved wide confidence intervals, suggesting that future work will benefit\nfrom larger datasets.\n",
        "query": "Types of cancer",
        "docId": 1219250,
        "score": 6.961482048034668
    },
    {
        "title": "Loss impresses human beings more than gain in the decision-making game",
        "paperAbstract": "  What happen in the brain when human beings play games with computers? Here a\nsimple zero-sum game was conducted to investigate how people make decision via\ntheir brain even they know that their opponent is a computer. There are two\nchoices (a low or high number) for people and also two strategies for the\ncomputer (red color or green color). When the number selected by the human\nsubject meet the red color, the person loses the score which is equal to the\nnumber. On the contrary, the person gains the number of score if the computer\nchooses a green color for the number selected by the human being. Both the\nhuman subject and the computer give their choice at the same time, and subjects\nhave been told that the computer make its decision randomly on the red color or\ngreen color. During the experiments, the signal of electroencephalograph (EEG)\nobtained from brain of subjects was recorded. From the analysis of EEG, we find\nthat people mind the loss more than the gain, and the phenomenon becoming\nobvious when the gap between loss and gain grows. In addition, the signal of\nEEG is clearly distinguishable before making different decisions. It is\nobserved that significant negative waves in the entire brain region when the\nparticipant has a greater expectation for the outcome, and these negative waves\nare mainly concentrated in the forebrain region in the brain of human beings.\n",
        "query": "Human beings evolution",
        "docId": 866407,
        "score": 8.153522491455078
    },
    {
        "title": "Digital Beings as an option to study gut flora evolution and adaptation",
        "paperAbstract": "  In this work, we introduce a computational model for the study of the\nhost-bacteria interaction and the influence of the intestinal microbiota on the\nbehavior and feeding pattern of an individual. The model is based on digital\nentities, which we\u0027ve called Digital Beings (DBs), modeled using dynamic\nsystems and genetic algorithms. We have successfully tested the use of the DBs\nby reproducing observation in previously made studies using rats and humans.\nAmong these studies, we highlight those on how the bacteria in an individual\u0027s\nstomach could influence their eating behavior and how a controlled and\ncontinuous diet can affect the longevity of a certain population. Our results\npoint that the Digital Beings can be used as a tool for supporting the devising\nof experiments and corroborating with theoretical hypotheses, reducing the\nnumber of in vivo tests.\n",
        "query": "Human beings evolution",
        "docId": 1174598,
        "score": 7.949456214904785
    },
    {
        "title": "Atomic beings and the discovery of gravity",
        "paperAbstract": "  We aim to bring a new perspective about some aspects of the current research\nin Cosmology. We start with a brief introduction about the main developments of\nthe field in the last century; then we introduce an analogy that shall\nelucidate the main difficulties that observational sciences involve, which\nmight be part of the issue related to some of the contemporary cosmological\nproblems. The analogy investigates how microscopic beings could ever discover\nand understand gravitational phenomena.\n",
        "query": "Human beings evolution",
        "docId": 678611,
        "score": 7.713738441467285
    },
    {
        "title": "Human Niche Evolution: pathways, choices and outcomes",
        "paperAbstract": "  Humankind has spread worldwide supported by cultural and technological\nknowledge, but the environmental sustainability on the human niche evolution\ndepends on a new human beings relationship with the biosphere. Human lifestyles\nnowadays are very Antropocentric and in many ways deleterious to the other life\nforms. Here we try to identify future scenarios, where the less deleterious is\nthe Natural-Technological Model that points the urgent need to change the\nevolutionary direction of the human niche seeking the resumption of original\necological relations. New cultural habits and novel technologies, thereby,\nwould reverse the current anthropogenic impacts. The middle way is the\nBio-Anthropogenic Model that predicts the success of the emerging ecosystems\nand the symbiotic relationship of humans and anthropogenic-favored species,\nhybrids, aliens and genetically modified organisms. For such, we must also\nchange our way of life and adopt new conscious ways of consumption aiming at\nthe socio-environmental good. Lastly, the Wear Out Model, which depends only on\nmaintaining current patterns of human expansion. The lack of investments on new\ntechnologies and new cultural habits, added to the current patterns of human\nniche evolution that are based on the massive exploitation of world resources,\nwill lead to a fearsome scenario with a precarious global health, biodiversity\nlosses and food scarcity. This theoretical models indicates some pathways and\ncan help us to choose a better future.\n",
        "query": "Human beings evolution",
        "docId": 1584628,
        "score": 7.191400527954102
    },
    {
        "title": "Spatial evolution of human dialects",
        "paperAbstract": "  The geographical pattern of human dialects is a result of history. Here, we\nformulate a simple spatial model of language change which shows that the final\nresult of this historical evolution may, to some extent, be predictable. The\nmodel shows that the boundaries of language dialect regions are controlled by a\nlength minimizing effect analogous to surface tension, mediated by variations\nin population density which can induce curvature, and by the shape of coastline\nor similar borders. The predictability of dialect regions arises because these\neffects will drive many complex, randomized early states toward one of a\nsmaller number of stable final configurations. The model is able to reproduce\nobservations and predictions of dialectologists. These include dialect\ncontinua, isogloss bundling, fanning, the wave-like spread of dialect features\nfrom cities, and the impact of human movement on the number of dialects that an\narea can support. The model also provides an analytical form for S\\\u0027{e}guy\u0027s\nCurve giving the relationship between geographical and linguistic distance, and\na generalisation of the curve to account for the presence of a population\ncentre. A simple modification allows us to analytically characterize the\nvariation of language use by age in an area undergoing linguistic change.\n",
        "query": "Human beings evolution",
        "docId": 824037,
        "score": 7.112453937530518
    },
    {
        "title": "HERD: Continuous Human-to-Robot Evolution for Learning from Human\n  Demonstration",
        "paperAbstract": "  The ability to learn from human demonstration endows robots with the ability\nto automate various tasks. However, directly learning from human demonstration\nis challenging since the structure of the human hand can be very different from\nthe desired robot gripper. In this work, we show that manipulation skills can\nbe transferred from a human to a robot through the use of micro-evolutionary\nreinforcement learning, where a five-finger human dexterous hand robot\ngradually evolves into a commercial robot, while repeated interacting in a\nphysics simulator to continuously update the policy that is first learned from\nhuman demonstration. To deal with the high dimensions of robot parameters, we\npropose an algorithm for multi-dimensional evolution path searching that allows\njoint optimization of both the robot evolution path and the policy. Through\nexperiments on human object manipulation datasets, we show that our framework\ncan efficiently transfer the expert human agent policy trained from human\ndemonstrations in diverse modalities to target commercial robots.\n",
        "query": "Human beings evolution",
        "docId": 1760536,
        "score": 6.937831878662109
    },
    {
        "title": "Cogniculture: Towards a Better Human-Machine Co-evolution",
        "paperAbstract": "  Research in Artificial Intelligence is breaking technology barriers every\nday. New algorithms and high performance computing are making things possible\nwhich we could only have imagined earlier. Though the enhancements in AI are\nmaking life easier for human beings day by day, there is constant fear that AI\nbased systems will pose a threat to humanity. People in AI community have\ndiverse set of opinions regarding the pros and cons of AI mimicking human\nbehavior. Instead of worrying about AI advancements, we propose a novel idea of\ncognitive agents, including both human and machines, living together in a\ncomplex adaptive ecosystem, collaborating on human computation for producing\nessential social goods while promoting sustenance, survival and evolution of\nthe agents\u0027 life cycle. We highlight several research challenges and technology\nbarriers in achieving this goal. We propose a governance mechanism around this\necosystem to ensure ethical behaviors of all cognitive agents. Along with a\nnovel set of use-cases of Cogniculture, we discuss the road map ahead for this\njourney.\n",
        "query": "Human beings evolution",
        "docId": 922323,
        "score": 6.739995956420898
    },
    {
        "title": "Eigen Evolution Pooling for Human Action Recognition",
        "paperAbstract": "  We introduce Eigen Evolution Pooling, an efficient method to aggregate a\nsequence of feature vectors. Eigen evolution pooling is designed to produce\ncompact feature representations for a sequence of feature vectors, while\nmaximally preserving as much information about the sequence as possible,\nespecially the temporal evolution of the features over time. Eigen evolution\npooling is a general pooling method that can be applied to any sequence of\nfeature vectors, from low-level RGB values to high-level Convolutional Neural\nNetwork (CNN) feature vectors. We show that eigen evolution pooling is more\neffective than average, max, and rank pooling for encoding the dynamics of\nhuman actions in video. We demonstrate the power of eigen evolution pooling on\nUCF101 and Hollywood2 datasets, two human action recognition benchmarks, and\nachieve state-of-the-art performance.\n",
        "query": "Human beings evolution",
        "docId": 880477,
        "score": 6.720312595367432
    },
    {
        "title": "The ABBE Corpus: Animate Beings Being Emotional",
        "paperAbstract": "  Emotion detection is an established NLP task of demonstrated utility for text\nunderstanding. However, basic emotion detection leaves out key information,\nnamely, who is experiencing the emotion in question. For example, it may be the\nauthor, the narrator, or a character; or the emotion may correspond to\nsomething the audience is supposed to feel, or even be unattributable to a\nspecific being, e.g., when emotions are being discussed per se. We provide the\nABBE corpus -- Animate Beings Being Emotional -- a new double-annotated corpus\nof texts that captures this key information for one class of emotion\nexperiencer, namely, animate beings in the world described by the text. Such a\ncorpus is useful for developing systems that seek to model or understand this\nspecific type of expressed emotion. Our corpus contains 30 chapters, comprising\n134,513 words, drawn from the Corpus of English Novels, and contains 2,010\nunique emotion expressions attributable to 2,227 animate beings. The emotion\nexpressions are categorized according to Plutchik\u0027s 8-category emotion model,\nand the overall inter-annotator agreement for the annotations was 0.83 Cohen\u0027s\nKappa, indicating excellent agreement. We describe in detail our annotation\nscheme and procedure, and also release the corpus for use by other researchers.\n",
        "query": "Human beings evolution",
        "docId": 1595990,
        "score": 6.600164413452148
    },
    {
        "title": "Understanding Human Intelligence through Human Limitations",
        "paperAbstract": "  Recent progress in artificial intelligence provides the opportunity to ask\nthe question of what is unique about human intelligence, but with a new\ncomparison class. I argue that we can understand human intelligence, and the\nways in which it may differ from artificial intelligence, by considering the\ncharacteristics of the kind of computational problems that human minds have to\nsolve. I claim that these problems acquire their structure from three\nfundamental limitations that apply to human beings: limited time, limited\ncomputation, and limited communication. From these limitations we can derive\nmany of the properties we associate with human intelligence, such as rapid\nlearning, the ability to break down problems into parts, and the capacity for\ncumulative cultural evolution.\n",
        "query": "Human beings evolution",
        "docId": 1355553,
        "score": 6.597179889678955
    },
    {
        "title": "The Falling Factorial Basis and Its Statistical Applications",
        "paperAbstract": "  We study a novel spline-like basis, which we name the \"falling factorial\nbasis\", bearing many similarities to the classic truncated power basis. The\nadvantage of the falling factorial basis is that it enables rapid, linear-time\ncomputations in basis matrix multiplication and basis matrix inversion. The\nfalling factorial functions are not actually splines, but are close enough to\nsplines that they provably retain some of the favorable properties of the\nlatter functions. We examine their application in two problems: trend filtering\nover arbitrary input points, and a higher-order variant of the two-sample\nKolmogorov-Smirnov test.\n",
        "query": "expansion of the falling factorial",
        "docId": 521466,
        "score": 11.402273178100586
    },
    {
        "title": "Some Explicit Formulas for Sums Involving the Binomial Coefficients with\n  the Falling Factorial",
        "paperAbstract": "  Spivey presented a new approach to evaluate combinatorial sums by using\nfinite differences. We present some closed forms for sums involving the\nbinomial coefficients, Fibonacci and Lucas numbers in terms of the falling\nfactorial.\n",
        "query": "expansion of the falling factorial",
        "docId": 731223,
        "score": 9.764642715454102
    },
    {
        "title": "Higher Derivatives of the Falling Factorial and Related Generalizations\n  of the Stirling and Harmonic Numbers",
        "paperAbstract": "  Through a brute-force approach to calculating the higher derivatives of the\nfalling factorial function, a number of interesting quantities were obtained\nand analyzed. In particular, it was found that a quantity that can be described\nas the \"elementary symmetric harmonic sum\" is a natural way to describe the\nsolutions to such higher derivatives. The relationship of this type of\ngeneralized harmonic number to other quantities discussed in the literature,\nsuch as the r-Stirling numbers, was described in detail.\n",
        "query": "expansion of the falling factorial",
        "docId": 491968,
        "score": 8.978975296020508
    },
    {
        "title": "Factorial hypersurfaces",
        "paperAbstract": "  In this paper the codimension of the complement to the set of factorial\nhypersurfaces of degree $d$ in ${\\mathbb P}^N$ is estimated for $d\\geqslant 4$,\n$N\\geqslant 7$.\n",
        "query": "expansion of the falling factorial",
        "docId": 766434,
        "score": 8.957878112792969
    },
    {
        "title": "Falling chains",
        "paperAbstract": "  The one-dimensional fall of a folded chain with one end suspended from a\nrigid support and a chain falling from a resting heap on a table is studied.\nBecause their Lagrangians contain no explicit time dependence, the falling\nchains are conservative systems. Their equations of motion are shown to contain\na term that enforces energy conservation when masses are transferred between\nsubchains. We show that Cayley\u0027s 1857 energy nonconserving solution for a chain\nfalling from a resting heap is incorrect because it neglects the energy gained\nwhen a transferred link leaves a subchain. The maximum chain tension measured\nby Calkin and March for the falling folded chain is given a simple if rough\ninterpretation. Other aspects of this falling folded chain are briefly\ndiscussed.\n",
        "query": "expansion of the falling factorial",
        "docId": 2195075,
        "score": 8.85546875
    },
    {
        "title": "A finite sum involving generalized falling factorial polynomials and\n  degenerate Eulerian polynomials",
        "paperAbstract": "  The aim of this paper is twofold. Firstly, we investigate a finite sum\ninvolving the generalized falling factorial polynomials, in some special cases\nof which we express it in terms of the degenerate Stirling numbers of the\nsecond kind, the degenerate Bernoulli polynomials and the degenerate\nFrobenius-Euler polynomials. Secondly, we consider the degenerate Eulerian\npolynomials and deduce the generating function and a recurrence relation for\nthem.\n",
        "query": "expansion of the falling factorial",
        "docId": 1580815,
        "score": 8.641632080078125
    },
    {
        "title": "Uniform Factorial Decay Estimate for the Remainder of Rough Taylor\n  Expansion",
        "paperAbstract": "  We establish an uniform factorial decay estimate for the Taylor approximation\nof solutions to controlled differential equations. Its proof requires a\nfactorial decay estimate for controlled paths which is interesting in its own\nright.\n",
        "query": "expansion of the falling factorial",
        "docId": 598776,
        "score": 8.269808769226074
    },
    {
        "title": "The asymptotic expansion for the factorial and Lagrange inversion\n  formula",
        "paperAbstract": "  We obtain an explicit simple formula for the coefficients of the asymptotic\nexpansion for the factorial of a natural number,in terms of derivatives of\npowers of an elementary function. The unique explicit expression for the\ncoefficients that appears to be known is that in the book by L. Comtet, which\nis given in terms of sums of associated Stirling numbers of the first kind. By\nconsidering the bivariate generating function of the associated Stirling\nnumbers of the second kind, another expression for the coefficients in terms of\nthem follows also from our analysis. Comparison with Comtet\u0027s expression yields\ncombinatorial identities between associated Stirling numbers of first and\nsecond kind. It suggests by analogy another possible formula for the\ncoefficients, in terms of a function involving the logarithm, that in fact\nproves to be true. The resulting coefficients, as well as the first ones are\nidentified via the Lagrange inversion formula as the odd coefficients of the\ninverse of a pair of formal series, which permits us to obtain also some\nrecurrences.\n",
        "query": "expansion of the falling factorial",
        "docId": 174653,
        "score": 8.144145965576172
    },
    {
        "title": "Factorial Grothendieck Polynomials",
        "paperAbstract": "  In this paper, we study Grothendieck polynomials from a combinatorial\nviewpoint. We introduce the factorial Grothendieck polynomials, analogues of\nthe factorial Schur functions and present some of their properties, and use\nthem to produce a generalisation of a Littlewood-Richardson rule for\nGrothendieck polynomials.\n",
        "query": "expansion of the falling factorial",
        "docId": 2142725,
        "score": 7.904405117034912
    },
    {
        "title": "Properties of Factorial Cumulant to Factorial Moment Ratio",
        "paperAbstract": "  It is shown that the ratio of factorial cumulant moments to factorial moments\nfor a multiplicity distribution truncated in the tail reveals oscillations in\nsign similar to those observed in experimental data. It is suggested that this\neffect be taken into account in the analysis of data in order to obtain correct\nphysical information on the multiplicity distributions.\n",
        "query": "expansion of the falling factorial",
        "docId": 2047998,
        "score": 7.798284530639648
    },
    {
        "title": "What is Quantum Computation?",
        "paperAbstract": "  Quantum computation is a rapidly progressing field today. What are its\nprinciples? In what sense is it distinct from conventional computation? What\nare its advantages and disadvantages? What type of problems can it address? How\npractical is it to make a quantum computer? I summarise some of the important\nconcepts of quantum computation, in an attempt to answer these questions. A\ndeeper understanding of them would pave the way for future development.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 2226132,
        "score": 8.76639175415039
    },
    {
        "title": "What is quantum in quantum randomness?",
        "paperAbstract": "  It is often said that quantum and classical randomness are of different\nnature, the former being ontological and the latter epistemological. However,\nso far the question of \"What is quantum in quantum randomness\", i.e. what is\nthe impact of quantization and discreteness on the nature of randomness,\nremains to answer. In a first part, we explicit the differences between quantum\nand classical randomness within a recently proposed ontology for quantum\nmechanics based on contextual objectivity. In this view, quantum randomness is\nthe result of contextuality and quantization. We show that this approach\nstrongly impacts the purposes of quantum theory as well as its areas of\napplication. In particular, it challenges current programs inspired by\nclassical reductionism, aiming at the emergence of the classical world from a\nlarge number of quantum systems. In a second part, we analyze quantum physics\nand thermodynamics as theories of randomness, unveiling their mutual\ninfluences. We finally consider new technological applications of quantum\nrandomness opened in the emerging field of quantum thermodynamics.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 966500,
        "score": 8.182929992675781
    },
    {
        "title": "A limitation on the KPT interpolation",
        "paperAbstract": "  We prove a limitation on a variant of the KPT theorem proposed for\npropositional proof systems by Pich and Santhanam (2020), for all proof systems\nthat prove the disjointness of two NP sets that are hard to distinguish.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 1267218,
        "score": 7.372323989868164
    },
    {
        "title": "What is a quantum simulator?",
        "paperAbstract": "  Quantum simulators are devices that actively use quantum effects to answer\nquestions about model systems and, through them, real systems. Here we expand\non this definition by answering several fundamental questions about the nature\nand use of quantum simulators. Our answers address two important areas. First,\nthe difference between an operation termed simulation and another termed\ncomputation. This distinction is related to the purpose of an operation, as\nwell as our confidence in and expectation of its accuracy. Second, the\nthreshold between quantum and classical simulations. Throughout, we provide a\nperspective on the achievements and directions of the field of quantum\nsimulation.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 523739,
        "score": 7.366393566131592
    },
    {
        "title": "Fundamental limitation on quantum broadcast networks",
        "paperAbstract": "  The ability to distribute entanglement over complex quantum networks is an\nimportant step towards a quantum internet. Recently, there has been significant\ntheoretical effort, mainly focusing on the distribution of bipartite\nentanglement via a simple quantum network composed only of bipartite quantum\nchannels. There are, however, a number of quantum information processing\nprotocols based on multipartite rather than bipartite entanglement. Whereas\nmultipartite entanglement can be distributed by means of a network of bipartite\nchannels, a more natural way is to use a more general network, that is, a\nquantum broadcast network including quantum broadcast channels. In this work,\nwe present a general frame- work for deriving upper bounds on the rates at\nwhich GHZ states or multipartite private states can be distributed among a\nnumber of different parties over an arbitrary quantum broadcast network. Our\nupper bounds are written in terms of the multipartite squashed entanglement,\ncorresponding to a generalisation of recently derived bounds [K. Azuma et al.,\nNat. Commun. 7, 13523 (2016)]. We also discuss how lower bounds can be obtained\nby combining a generalisation of an aggregated quantum repeater protocol with\ngraph theoretic concepts.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 769472,
        "score": 7.287355899810791
    },
    {
        "title": "Limitation to Quantum Measurements of Spacetime Distances",
        "paperAbstract": "  Inspired by the work of Wheeler among others, we have studied the problem of\nquantum measurements of space-time distances by applying the general principles\nof quantum mechanics as well as those of general relativity. Contrary to the\nfolklore, the minimum error in the measurement of a length is shown to be\nproportional to the one-third power of the length itself. This uncertainty in\nspace-time measurements implies an uncertainty of the space-time metric and\nyields quantum decoherence for particles heavier than the Planck mass. There is\nalso a corresponding minimum error in energy-momentum measurements.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 2094763,
        "score": 7.150677680969238
    },
    {
        "title": "Ghost Imaging: What is quantum, what is not",
        "paperAbstract": "  We provide a unified treatment of classical and quantum Gaussian-state\nsources that unambiguously identifies which features of ghost imaging are\nstrictly quantum mechanical. We show that ghost-image formation is\nfundamentally classical, with the image being expressible in terms of the\nphase-insensitive and phase-sensitive cross correlations between the detected\nfields. We then consider ghost-imaging scenarios with either phase-insensitive\nor phase-sensitive sources, where the former are always classical but the\nlatter may be classical or quantum mechanical. We show that if their\nauto-correlations are identical, then a quantum source provides resolution\nimprovement in its near-field and field-of-view improvement in its far field\nwhen compared to a classical source.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 2221768,
        "score": 7.091499328613281
    },
    {
        "title": "Negative probabilities, II: What they are and what they are for",
        "paperAbstract": "  A signed probability distribution may extend a given traditional probability\nfrom observable events to all events. We formalize and illustrate this\napproach. We also illustrate its limitation. We argue that the right question\nis not what negative probabilities are but what they are for.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 1007588,
        "score": 7.062631607055664
    },
    {
        "title": "An intrinsic limitation on the size of quantum database",
        "paperAbstract": "  It is found that Grover\u0027s quantum search algorithm is not robust against\nphase inversion and Hadmard transformation inaccuracies. Imperfect phase\ninversions and Hadmard-Walsh transformations in Grover\u0027s quantum search\nalgorithm lead to reductions in the maximum probability of the marked state and\naffect the efficiency of the algorithm. even in the absence of decoherence.\nGiven the degrees of inaccuracies, we find that to guarantee half rate of\nsuccess, the size of the database should be in the order of $O({1 \\over\n\\delta^2})$, where $\\delta$ is the uncertainty.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 2226220,
        "score": 7.048208236694336
    },
    {
        "title": "Limitation of capsule networks",
        "paperAbstract": "  A recently proposed method in deep learning groups multiple neurons to\ncapsules such that each capsule represents an object or part of an object.\nRouting algorithms route the output of capsules from lower-level layers to\nupper-level layers. In this paper, we prove that state-of-the-art routing\nprocedures decrease the expressivity of capsule networks. More precisely, it is\nshown that EM-routing and routing-by-agreement prevent capsule networks from\ndistinguishing inputs and their negative counterpart. Therefore, only symmetric\nfunctions can be expressed by capsule networks, and it can be concluded that\nthey are not universal approximators. We also theoretically motivate and\nempirically show that this limitation affects the training of deep capsule\nnetworks negatively. Therefore, we present an incremental improvement for\nstate-of-the-art routing algorithms that solves the aforementioned limitation\nand stabilizes the training of capsule networks.\n",
        "query": "What is the limitation of quantum mechanics?",
        "docId": 1127180,
        "score": 6.9885149002075195
    }
]