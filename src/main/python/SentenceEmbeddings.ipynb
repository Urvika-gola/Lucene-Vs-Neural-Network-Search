{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before running this file, you should use `DataPreprocessor.py` to remove stopwords from the Arxiv Dataset. \n",
        "Then upload the `stopwords-arxiv-metadata-oai-snapshot.json` file to the VM. This file was run\n",
        "with Google Drive enabled, and expect the json data to be found under\n",
        "`'/content/drive/MyDrive/data_resources/stopwords-arxiv-metadata-oai-snapshot.json'`\n",
        "\n",
        "When generating the Embeddings for each article, batches of 250 articles are processed at \n",
        "a time in order to managed available memory resources. Each processed batch is saved \n",
        "to `/content/drive/MyDrive/data_resources/batches'` with a file name formatted as `batchSize_batchNumber.batch`\n",
        "\n",
        "Once all embeddings are generated, the last cell in this notebook will generate a Zip file\n",
        "so the embeddings can be downloaded in the event you max out free Google Collab resources \n",
        "so you can continue building the Annoy Index with `SentenceEmbeddings_CPU.py`\n",
        "\n",
        "If you do use the Google Drive integration, make sure you have at least 9GB of free space available.\n",
        "If you don't you can modify the paths above to use ones local to the Collab Environment \n",
        "but this may result in the files getting removed if you get a Collab Timeout.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApM1vteQve2Y",
        "outputId": "1462406b-bc63-46ab-bf73-8c932270ccc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nvidia_smi\n",
            "  Downloading nvidia_smi-0.1.3-py36-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nvidia_smi) (1.24.2)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nvidia_smi) (1.16.0)\n",
            "Collecting sorcery>=0.1.0\n",
            "  Downloading sorcery-0.2.2-py3-none-any.whl (16 kB)\n",
            "Collecting pytest>=4.3.1\n",
            "  Downloading pytest-7.3.1-py3-none-any.whl (320 kB)\n",
            "     -------------------------------------- 320.5/320.5 kB 9.7 MB/s eta 0:00:00\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytest>=4.3.1->nvidia_smi) (23.0)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytest>=4.3.1->nvidia_smi) (0.4.6)\n",
            "Requirement already satisfied: executing in c:\\users\\sparticus37\\appdata\\roaming\\python\\python311\\site-packages (from sorcery>=0.1.0->nvidia_smi) (1.2.0)\n",
            "Collecting littleutils>=0.2.1\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: asttokens in c:\\users\\sparticus37\\appdata\\roaming\\python\\python311\\site-packages (from sorcery>=0.1.0->nvidia_smi) (2.2.1)\n",
            "Collecting wrapt\n",
            "  Downloading wrapt-1.15.0-cp311-cp311-win_amd64.whl (36 kB)\n",
            "Installing collected packages: littleutils, wrapt, pluggy, iniconfig, sorcery, pytest, nvidia_smi\n",
            "  Running setup.py install for littleutils: started\n",
            "  Running setup.py install for littleutils: finished with status 'done'\n",
            "Successfully installed iniconfig-2.0.0 littleutils-0.2.2 nvidia_smi-0.1.3 pluggy-1.0.0 pytest-7.3.1 sorcery-0.2.2 wrapt-1.15.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: littleutils is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Requirement already satisfied: psutil in c:\\users\\sparticus37\\appdata\\roaming\\python\\python311\\site-packages (5.9.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nvidia-ml-py3\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Installing collected packages: nvidia-ml-py3\n",
            "  Running setup.py install for nvidia-ml-py3: started\n",
            "  Running setup.py install for nvidia-ml-py3: finished with status 'done'\n",
            "Successfully installed nvidia-ml-py3-7.352.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: nvidia-ml-py3 is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.24.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (6.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.27.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.24.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.3.23)\n",
            "Requirement already satisfied: requests in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sparticus37\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install nvidia_smi\n",
        "! pip install psutil\n",
        "! pip install nvidia-ml-py3\n",
        "! pip install gensim\n",
        "! pip install transformers\n",
        "! pip install smart_open\n",
        "! pip install torch\n",
        "! pip install termcolor\n",
        "! pip install annoy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print out CPU, Memory, and GPU(if available) usages metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1FVF9IH3rPF",
        "outputId": "de7609ff-8a5b-41e4-d2fe-22413abffd48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU used\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import nvidia_smi\n",
        "info_gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(info_gpus) > 0:\n",
        "    nvidia_smi.nvmlInit()\n",
        "\n",
        "    device_count = nvidia_smi.nvmlDeviceGetCount()\n",
        "    for i in range(device_count):\n",
        "      handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
        "      info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "      print(f\"Device {i}: {nvidia_smi.nvmlDeviceGetName(handle).decode()}\")\n",
        "      print(f\"Memory : {round(100*info.free/info.total,2)}% free: {info.total}(total), {info.free} (free), {info.used} (used)\")\n",
        "    \n",
        "    nvidia_smi.nvmlShutdown()\n",
        "else:\n",
        "  print(\"No GPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ3q9l7Su9sd",
        "outputId": "761738ae-c3a6-4da5-8686-a3afcc67afd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Memory Usage ====================\n",
            "total 13616324608\n",
            "available 12115271680\n",
            "percent 11.0\n",
            "used 1159946240\n",
            "free 10664103936\n",
            "active 462086144\n",
            "inactive 2251771904\n",
            "buffers 142462976\n",
            "cached 1649811456\n",
            "shared 13709312\n",
            "slab 163209216\n",
            "==================== CPU Usage ====================\n",
            "CPU percent: 26.8%\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "split_bar = '='*20\n",
        "memory_info = psutil.virtual_memory()._asdict()\n",
        "print(f\"{split_bar} Memory Usage {split_bar}\")\n",
        "for k,v in memory_info.items():\n",
        "  print(k, v)\n",
        "print(f\"{split_bar} CPU Usage {split_bar}\")\n",
        "print(f\"CPU percent: {psutil.cpu_percent()}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check to see if you have GPU resources available for you in the current Google Collab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJGpztHzynsP",
        "outputId": "eddf90c2-16ef-4e30-a791-a6b50bb97b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# set to True to use the gpu (if there is one available)\n",
        "use_gpu = True\n",
        "\n",
        "# select device\n",
        "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
        "print(f'device: {device.type}')\n",
        "\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vR5Br7jx_Mv",
        "outputId": "41e3ffa8-0cfa-4cd9-de57-c82a26450f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last updated 2023-04-14T20:18:25.425798\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "import smart_open\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from termcolor import colored\n",
        "from annoy import AnnoyIndex\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "class NearestNeighborSearcher:\n",
        "  \"\"\"\n",
        "  Class that creates the vector of the documents, and builds an annoy index, parses the query\n",
        "  and returns resulting documents relevant to the query.\n",
        "  \"\"\"\n",
        "  def __init__(self,batchSize,  index_name):\n",
        "    \"\"\"\n",
        "    Initializes the NearestNeighborSearcher object with a pre-trained transformer model.\n",
        "    \"\"\"\n",
        "    self.annoy_index = None\n",
        "    self.index_name = index_name\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    self.model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    self.device ='cuda:0'\n",
        "    self.model = self.model.to(self.device)\n",
        "    self.vector_length = self.model.config.hidden_size  # setting the vectors used for the annoy index have the same\n",
        "    self.batchSize = batchSize\n",
        "    self.failedBatches =[]\n",
        "    self.batchOutDir ='/content/drive/MyDrive/data_resources/batches'\n",
        "    \n",
        "\n",
        "  def mean_pooling(self, model_output, attention_mask):\n",
        "    \"\"\"\n",
        "    Pool CLS Embedding Tensors to vectors so we can index them with Annoy. \n",
        "    Sourced from https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2 \n",
        "    \"\"\"\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\t\n",
        "  def _get_vectors(self, documents: List[str]) -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Tokenizes a list of documents, passes them through the transformer model, and returns their vectors.\n",
        "    :param documents: List[str] - A list of documents to convert to vector\n",
        "    :return: List[torch.Tensor] - A list of torch tensors containing the embeddings of the documents.\n",
        "    \"\"\"\n",
        "    tokens = self.tokenizer(documents,padding=True, truncation=True, return_tensors='pt').to(self.device)\n",
        "    with torch.no_grad():\n",
        "      vectors = self.model(**tokens)\n",
        "    ## shape of last hidden state (sentence, layer, embedding)\n",
        "    sentence_embeddings = self.mean_pooling(vectors, tokens['attention_mask'])\n",
        "    # Normalize embeddings\n",
        "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
        "\n",
        "    #cls_embedding_vector = [vector.last_hidden_state[0][0] for vector in vectors]\n",
        "    return sentence_embeddings\n",
        "  def build_index(self, documents: List[str],totalBatches = None):\n",
        "    \"\"\"\n",
        "    Builds an Annoy index based on the vectors of a list of documents.\n",
        "    :param documents: List[str] - A list of documents to index.\n",
        "    \"\"\"        \n",
        "    self.annoy_index = AnnoyIndex(self.vector_length, \"angular\")  # angular is the metric.\n",
        "    self.processDocsInBatches(documents,totalBatches)\n",
        "  def processDocsInBatches(self, documents, totalBatches = None):\n",
        "    \"\"\"\n",
        "    Process Embedding files saved to disk and load them into an Annoy Index\n",
        "    If totalBatches is specified, will only process that number of batches \n",
        "    to facilitate debugging\n",
        "    \"\"\" \n",
        "    batchOutDir =  self.batchOutDir\n",
        "    if totalBatches == None:\n",
        "        totalBatches = int((len(documents) / self.batchSize ) + 1    )\n",
        "\n",
        "    if os.path.exists(self.index_name):\n",
        "        self.annoy_index.load(self.index_name)\n",
        "    for batchNo in range(0, totalBatches):\n",
        "        batchFile = f'{batchOutDir}/{self.batchSize}__{batchNo}.batch'\n",
        "        if(os.path.exists(batchFile) == False):\n",
        "            print(colored(f'batch {batchNo+1} not found. Skipping', 'red'))\n",
        "            continue\n",
        "        print(f\"Processing batch {batchNo+1} of {int(totalBatches)}. ||   \" + datetime.datetime.now().isoformat())\n",
        "        batchStart = batchNo*self.batchSize\n",
        "        try:\n",
        "          vectors = torch.load(batchFile,map_location=torch.device('cpu'))\n",
        "          for i, embedding in enumerate(vectors) :\n",
        "              if(i ==0):\n",
        "                print(f'annoy index item starts at {batchStart+i}')\n",
        "              self.annoy_index.add_item(batchStart+i, embedding)\n",
        "          print(f\"Finished Processing batch {batchNo+1} of {int(totalBatches)}. ||   \" + datetime.datetime.now().isoformat())\n",
        "        except Exception as e: \n",
        "          print(colored(f\"Failed Processing batch {batchNo+1} of {int(totalBatches)} ||   \" + datetime.datetime.now().isoformat(), 'red'))\n",
        "          print(e)\n",
        "          self.failedBatches.append(batchNo)\n",
        "    self.annoy_index.build(totalBatches) \n",
        "    print(f\"saving index to {self.index_name}\")\n",
        "    self.annoy_index.save(self.index_name)\n",
        "  def processTokensToEmbeddings(self, documents, totalBatches):\n",
        "    \"\"\"\n",
        "    Convert a list of documents to Normalized CLS Embedding vectors in batches and save the \n",
        "    generated vectors to disk for later indexing in the event of a crash. If a batch\n",
        "    has already been save to disk, that batch will be skipped\n",
        "    \"\"\"\n",
        "\t\t#batchNo = 0 #Left off at batch one\n",
        "    batchOutDir = self.batchOutDir\n",
        "    #\n",
        "    if totalBatches == None:\n",
        "      totalBatches = int((len(documents) / self.batchSize ) + 1    )\n",
        "\n",
        "    for batchNo in range(0, totalBatches):\n",
        "      batchFile = f'{batchOutDir}/{self.batchSize}__{batchNo}.batch'\n",
        "      if(os.path.exists(batchFile)):\n",
        "        print(f'batch {batchNo+1} already processed. Skipping')\n",
        "        continue\n",
        "      batchStart = batchNo*self.batchSize\n",
        "      batchEnd = min(((batchNo+1) * self.batchSize), len(documents)) -1\n",
        "      if(batchStart >= len(documents)):\n",
        "        print(f\"{batchNo} exists on disk already\")\n",
        "        break\n",
        "      try:\n",
        "        print(f\"Processing batch {batchNo+1} of {int(totalBatches)}. Range {batchStart} to {batchEnd} ||   \" + datetime.datetime.now().isoformat())\n",
        "        batch = documents[batchStart:batchEnd  ]\n",
        "        vectors = self._get_vectors(batch)  # Convert docs to vectors, to represented in vector space.\n",
        "        print(f\"Writing batch {batchNo+1} to {batchFile} ||   \" + datetime.datetime.now().isoformat())\n",
        "        f = open(batchFile, \"x\")\n",
        "        torch.save(vectors,batchFile)\t\t\t\n",
        "        print(f\"Finished Processing batch {batchNo+1} of {int(totalBatches)}. Range {batchStart} to {batchEnd} ||   \" + datetime.datetime.now().isoformat())\n",
        "      except Exception as e: \n",
        "        print(colored(f\"Failed Processing batch {batchNo+1} of {int(totalBatches)}. Range {batchStart} to {batchEnd} ||   \" + datetime.datetime.now().isoformat(), 'red'))\n",
        "        print(e)\n",
        "        self.failedBatches.append(batchNo)\n",
        "    \n",
        "  def openFile(self, filePath, isPreProcessed=True, isTokenized = False):\n",
        "      with smart_open.open(filePath, encoding=\"utf-8\") as f:\n",
        "          jsonData = json.load(f)\n",
        "          if isPreProcessed:\n",
        "              for i, rawLine in enumerate(jsonData):\n",
        "                  if(isTokenized == False):\n",
        "                      tokens = gensim.utils.simple_preprocess(rawLine)\n",
        "                  else: tokens = rawLine\n",
        "                  yield tokens\n",
        "          else: \n",
        "              for i, rawLine in enumerate(f):\t\t\t\t\t\t\t\n",
        "                  yield remove_stopwords(rawLine)\n",
        "\n",
        "print(f'last updated {datetime.datetime.now().isoformat()}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the class object for processing the Arxive Data set. \n",
        "Note that you may run into memory issues if you increase batchSize beyond 250."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIU2riWClvW-",
        "outputId": "57ec04aa-3794-4b19-eaf5-0784368392b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last updated 2023-04-14T20:18:28.538287\n"
          ]
        }
      ],
      "source": [
        "tokenizedDataFile = '/content/drive/MyDrive/data_resources/stopwords-arxiv-metadata-oai-snapshot.json'\n",
        "nns = NearestNeighborSearcher(batchSize=250, index_name=\"/content/drive/MyDrive/data_resources/arxiv_transformer_index.bin\")\n",
        "print(f'last updated {datetime.datetime.now().isoformat()}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the Arxiv Data set  for processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9pEIAYj1WKt",
        "outputId": "9524f81c-1ea4-4bbe-c179-0a882355b001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading dataset from file - 2023-04-14T20:18:28.582642\n",
            "finished loading dataset from file - 2023-04-14T20:19:06.292463\n",
            "loaded 2227430 items\n"
          ]
        }
      ],
      "source": [
        "print(\"loading dataset from file - \"  + datetime.datetime.now().isoformat())\n",
        "documents = list(nns.openFile(tokenizedDataFile,isTokenized=True))    \n",
        "print(\"finished loading dataset from file - \"  + datetime.datetime.now().isoformat())\n",
        "print(\"loaded \" + str(len(documents))+ \" items\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Process the Arxiv data set and generate the CLS embeddings. Saves the CLS \n",
        "embeddings in batches so we don't have to re-process a batch if we get\n",
        "disconnected from Collab. If `totalBatches` is set to none, process the entire\n",
        "data set, or set it to a positive integer to process batch 0 to totalBatches. \n",
        "If a batch has been saved already to the file system, it will not be processed \n",
        "again unless you delete that saved batch file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-nL9FTnUvlF"
      },
      "outputs": [],
      "source": [
        "nns.processTokensToEmbeddings(documents, totalBatches= None) \n",
        "## Print the batch number of any batches that we may have failed to process \n",
        "print(nns.failedBatches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hl9i_ZKlwmH"
      },
      "outputs": [],
      "source": [
        "# Collab does not have enough memory to build the index, must download batches locally to desktop\n",
        "#nns.build_index(documents, totalBatches = None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create and download a ZIP file containing the Embedding batches\n",
        "for processing outside of Collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b044YrHMqqoH"
      },
      "outputs": [],
      "source": [
        "\n",
        "!zip -r /content/batches.zip /content/drive/MyDrive/data_resources/batches\n",
        "from google.colab import files\n",
        "files.download(\"/content/batches.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
