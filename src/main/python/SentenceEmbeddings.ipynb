{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApM1vteQve2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1462406b-bc63-46ab-bf73-8c932270ccc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nvidia_smi in /usr/local/lib/python3.9/dist-packages (0.1.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from nvidia_smi) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.9/dist-packages (from nvidia_smi) (1.22.4)\n",
            "Requirement already satisfied: pytest>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from nvidia_smi) (7.2.2)\n",
            "Requirement already satisfied: sorcery>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from nvidia_smi) (0.2.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=4.3.1->nvidia_smi) (22.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=4.3.1->nvidia_smi) (2.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest>=4.3.1->nvidia_smi) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest>=4.3.1->nvidia_smi) (1.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pytest>=4.3.1->nvidia_smi) (23.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest>=4.3.1->nvidia_smi) (1.1.1)\n",
            "Requirement already satisfied: littleutils>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from sorcery>=0.1.0->nvidia_smi) (0.2.2)\n",
            "Requirement already satisfied: executing in /usr/local/lib/python3.9/dist-packages (from sorcery>=0.1.0->nvidia_smi) (1.2.0)\n",
            "Requirement already satisfied: asttokens in /usr/local/lib/python3.9/dist-packages (from sorcery>=0.1.0->nvidia_smi) (2.2.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from sorcery>=0.1.0->nvidia_smi) (1.14.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (5.9.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.9/dist-packages (7.352.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.9/dist-packages (6.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (2.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: annoy in /usr/local/lib/python3.9/dist-packages (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install nvidia_smi\n",
        "! pip install psutil\n",
        "! pip install nvidia-ml-py3\n",
        "! pip install gensim\n",
        "! pip install transformers\n",
        "! pip install smart_open\n",
        "! pip install torch\n",
        "! pip install termcolor\n",
        "! pip install annoy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1FVF9IH3rPF",
        "outputId": "de7609ff-8a5b-41e4-d2fe-22413abffd48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU used\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import nvidia_smi\n",
        "info_gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(info_gpus) > 0:\n",
        "    nvidia_smi.nvmlInit()\n",
        "\n",
        "    device_count = nvidia_smi.nvmlDeviceGetCount()\n",
        "    for i in range(device_count):\n",
        "      handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
        "      info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "      print(f\"Device {i}: {nvidia_smi.nvmlDeviceGetName(handle).decode()}\")\n",
        "      print(f\"Memory : {round(100*info.free/info.total,2)}% free: {info.total}(total), {info.free} (free), {info.used} (used)\")\n",
        "    \n",
        "    nvidia_smi.nvmlShutdown()\n",
        "else:\n",
        "  print(\"No GPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ3q9l7Su9sd",
        "outputId": "761738ae-c3a6-4da5-8686-a3afcc67afd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Memory Usage ====================\n",
            "total 13616324608\n",
            "available 12115271680\n",
            "percent 11.0\n",
            "used 1159946240\n",
            "free 10664103936\n",
            "active 462086144\n",
            "inactive 2251771904\n",
            "buffers 142462976\n",
            "cached 1649811456\n",
            "shared 13709312\n",
            "slab 163209216\n",
            "==================== CPU Usage ====================\n",
            "CPU percent: 26.8%\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "split_bar = '='*20\n",
        "memory_info = psutil.virtual_memory()._asdict()\n",
        "print(f\"{split_bar} Memory Usage {split_bar}\")\n",
        "for k,v in memory_info.items():\n",
        "  print(k, v)\n",
        "print(f\"{split_bar} CPU Usage {split_bar}\")\n",
        "print(f\"CPU percent: {psutil.cpu_percent()}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJGpztHzynsP",
        "outputId": "eddf90c2-16ef-4e30-a791-a6b50bb97b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# set to True to use the gpu (if there is one available)\n",
        "use_gpu = True\n",
        "\n",
        "# select device\n",
        "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
        "print(f'device: {device.type}')\n",
        "\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vR5Br7jx_Mv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e3ffa8-0cfa-4cd9-de57-c82a26450f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last updated 2023-04-14T20:18:25.425798\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "import smart_open\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from termcolor import colored\n",
        "from annoy import AnnoyIndex\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "class NearestNeighborSearcher:\n",
        "  def __init__(self,batchSize,  index_name):\n",
        "    \"\"\"\n",
        "    Initializes the NearestNeighborSearcher object with a pre-trained transformer model.\n",
        "    \"\"\"\n",
        "    self.annoy_index = None\n",
        "    self.index_name = index_name\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    self.model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    self.device ='cuda:0'\n",
        "    self.model = self.model.to(self.device)\n",
        "    self.vector_length = self.model.config.hidden_size  # setting the vectors used for the annoy index have the same\n",
        "    self.batchSize = batchSize\n",
        "    self.failedBatches =[]\n",
        "    self.batchOutDir ='/content/drive/MyDrive/data_resources/batches'\n",
        "    \n",
        "\n",
        "  def mean_pooling(self, model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\t\n",
        "  def _get_vectors(self, documents: List[str]) -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Tokenizes a list of documents, passes them through the transformer model, and returns their vectors.\n",
        "    :param documents: List[str] - A list of documents to convert to vector\n",
        "    :return: List[torch.Tensor] - A list of torch tensors containing the embeddings of the documents.\n",
        "    \"\"\"\n",
        "    tokens = self.tokenizer(documents,padding=True, truncation=True, return_tensors='pt').to(self.device)\n",
        "    with torch.no_grad():\n",
        "      vectors = self.model(**tokens)\n",
        "    ## shape of last hidden state (sentence, layer, embedding)\n",
        "    sentence_embeddings = self.mean_pooling(vectors, tokens['attention_mask'])\n",
        "    # Normalize embeddings\n",
        "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
        "\n",
        "    #cls_embedding_vector = [vector.last_hidden_state[0][0] for vector in vectors]\n",
        "    return sentence_embeddings\n",
        "  def build_index(self, documents: List[str],totalBatches = None):\n",
        "    \"\"\"\n",
        "    Builds an Annoy index based on the vectors of a list of documents.\n",
        "    :param documents: List[str] - A list of documents to index.\n",
        "    \"\"\"        \n",
        "    self.annoy_index = AnnoyIndex(self.vector_length, \"angular\")  # angular is the metric.\n",
        "    self.processDocsInBatches(documents,totalBatches)\n",
        "  def processDocsInBatches(self, documents, totalBatches = None):\n",
        "               \n",
        "    batchOutDir =  self.batchOutDir\n",
        "    if totalBatches == None:\n",
        "        totalBatches = int((len(documents) / self.batchSize ) + 1    )\n",
        "\n",
        "    if os.path.exists(self.index_name):\n",
        "        self.annoy_index.load(self.index_name)\n",
        "    for batchNo in range(0, totalBatches):\n",
        "        batchFile = f'{batchOutDir}/{self.batchSize}__{batchNo}.batch'\n",
        "        if(os.path.exists(batchFile) == False):\n",
        "            print(colored(f'batch {batchNo+1} not found. Skipping', 'red'))\n",
        "            continue\n",
        "        print(f\"Processing batch {batchNo+1} of {int(totalBatches)}. ||   \" + datetime.datetime.now().isoformat())\n",
        "        batchStart = batchNo*self.batchSize\n",
        "        try:\n",
        "          vectors = torch.load(batchFile,map_location=torch.device('cpu'))\n",
        "          for i, embedding in enumerate(vectors) :\n",
        "              if(i ==0):\n",
        "                print(f'annoy index item starts at {batchStart+i}')\n",
        "              self.annoy_index.add_item(batchStart+i, embedding)\n",
        "          print(f\"Finished Processing batch {batchNo+1} of {int(totalBatches)}. ||   \" + datetime.datetime.now().isoformat())\n",
        "        except Exception as e: \n",
        "          print(colored(f\"Failed Processing batch {batchNo+1} of {int(totalBatches)} ||   \" + datetime.datetime.now().isoformat(), 'red'))\n",
        "          print(e)\n",
        "          self.failedBatches.append(batchNo)\n",
        "    self.annoy_index.build(totalBatches) \n",
        "    print(f\"saving index to {self.index_name}\")\n",
        "    self.annoy_index.save(self.index_name)\n",
        "  def processTokensToEmbeddings(self, documents, totalBatches):\n",
        "\t\t\n",
        "\t\t#batchNo = 0 #Left off at batch one\n",
        "    batchOutDir = self.batchOutDir\n",
        "    #\n",
        "    if totalBatches == None:\n",
        "      totalBatches = int((len(documents) / self.batchSize ) + 1    )\n",
        "\n",
        "    for batchNo in range(0, totalBatches):\n",
        "      batchFile = f'{batchOutDir}/{self.batchSize}__{batchNo}.batch'\n",
        "      if(os.path.exists(batchFile)):\n",
        "        print(f'batch {batchNo+1} already processed. Skipping')\n",
        "        continue\n",
        "      batchStart = batchNo*self.batchSize\n",
        "      batchEnd = min(((batchNo+1) * self.batchSize), len(documents)) -1\n",
        "      if(batchStart >= len(documents)):\n",
        "        print(f\"{batchNo} exists on disk already\")\n",
        "        break\n",
        "      try:\n",
        "        print(f\"Processing batch {batchNo+1} of {int(totalBatches)}. Range {batchStart} to {batchEnd} ||   \" + datetime.datetime.now().isoformat())\n",
        "        batch = documents[batchStart:batchEnd  ]\n",
        "        vectors = self._get_vectors(batch)  # Convert docs to vectors, to represented in vector space.\n",
        "        print(f\"Writing batch {batchNo+1} to {batchFile} ||   \" + datetime.datetime.now().isoformat())\n",
        "        f = open(batchFile, \"x\")\n",
        "        torch.save(vectors,batchFile)\t\t\t\n",
        "        print(f\"Finished Processing batch {batchNo+1} of {int(totalBatches)}. Range {batchStart} to {batchEnd} ||   \" + datetime.datetime.now().isoformat())\n",
        "      except Exception as e: \n",
        "        print(colored(f\"Failed Processing batch {batchNo+1} of {int(totalBatches)}. Range {batchStart} to {batchEnd} ||   \" + datetime.datetime.now().isoformat(), 'red'))\n",
        "        print(e)\n",
        "        self.failedBatches.append(batchNo)\n",
        "    \n",
        "  def openFile(self, filePath, isPreProcessed=True, isTokenized = False):\n",
        "      with smart_open.open(filePath, encoding=\"utf-8\") as f:\n",
        "          jsonData = json.load(f)\n",
        "          if isPreProcessed:\n",
        "              for i, rawLine in enumerate(jsonData):\n",
        "                  if(isTokenized == False):\n",
        "                      tokens = gensim.utils.simple_preprocess(rawLine)\n",
        "                  else: tokens = rawLine\n",
        "                  yield tokens\n",
        "          else: \n",
        "              for i, rawLine in enumerate(f):\t\t\t\t\t\t\t\n",
        "                  yield remove_stopwords(rawLine)\n",
        "\n",
        "print(f'last updated {datetime.datetime.now().isoformat()}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataFile = 'src/main/resources/arxiv-metadata-oai-snapshot.json'\n",
        "# queryFiles = 'src/main/resources/lucene-queries.txt'\n",
        "# resultsFile = 'src/main/resources/annoy-results_transformer.json'\n",
        "tokenizedDataFile = '/content/drive/MyDrive/data_resources/stopwords-arxiv-metadata-oai-snapshot.json'\n",
        "nns = NearestNeighborSearcher(batchSize=250, index_name=\"/content/drive/MyDrive/data_resources/arxiv_transformer_index.bin\")\n",
        "print(f'last updated {datetime.datetime.now().isoformat()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIU2riWClvW-",
        "outputId": "57ec04aa-3794-4b19-eaf5-0784368392b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last updated 2023-04-14T20:18:28.538287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9pEIAYj1WKt",
        "outputId": "9524f81c-1ea4-4bbe-c179-0a882355b001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dataset from file - 2023-04-14T20:18:28.582642\n",
            "finished loading dataset from file - 2023-04-14T20:19:06.292463\n",
            "loaded 2227430 items\n"
          ]
        }
      ],
      "source": [
        "print(\"loading dataset from file - \"  + datetime.datetime.now().isoformat())\n",
        "documents = list(nns.openFile(tokenizedDataFile,isTokenized=True))    \n",
        "print(\"finished loading dataset from file - \"  + datetime.datetime.now().isoformat())\n",
        "print(\"loaded \" + str(len(documents))+ \" items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-nL9FTnUvlF"
      },
      "outputs": [],
      "source": [
        "#nns.processTokensToEmbeddings(documents, totalBatches= None)  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collab does not have enough memory to build the index, must download batches locally to desktop\n",
        "#nns.build_index(documents, totalBatches = None)"
      ],
      "metadata": {
        "id": "0hl9i_ZKlwmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nns.failedBatches\n",
        "!zip -r /content/batches.zip /content/drive/MyDrive/data_resources/batches\n",
        "from google.colab import files\n",
        "files.download(\"/content/batches.zip\")"
      ],
      "metadata": {
        "id": "b044YrHMqqoH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}